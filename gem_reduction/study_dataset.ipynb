{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r1</th>\n",
       "      <th>r3</th>\n",
       "      <th>r2</th>\n",
       "      <th>r4</th>\n",
       "      <th>r5</th>\n",
       "      <th>r6</th>\n",
       "      <th>r7</th>\n",
       "      <th>r8</th>\n",
       "      <th>r9</th>\n",
       "      <th>r10</th>\n",
       "      <th>...</th>\n",
       "      <th>r15</th>\n",
       "      <th>r16</th>\n",
       "      <th>InputA</th>\n",
       "      <th>InputI</th>\n",
       "      <th>OutputX</th>\n",
       "      <th>OutputN</th>\n",
       "      <th>id</th>\n",
       "      <th>growth</th>\n",
       "      <th>status</th>\n",
       "      <th>strain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>r1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>infeasible</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>r3</td>\n",
       "      <td>9.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>r2</td>\n",
       "      <td>9.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>r4</td>\n",
       "      <td>9.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.20</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>r5</td>\n",
       "      <td>9.00</td>\n",
       "      <td>infeasible</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    r1   r3    r2    r4   r5   r6   r7   r8   r9   r10  ...  r15  r16  InputA  \\\n",
       "0 0.00 0.10 -0.10 -0.20 1.20 1.00 1.00 1.00 1.00 -0.00  ... 0.00 1.00    1.00   \n",
       "1 1.00 0.00  1.00  2.00 1.00 3.00 3.00 3.00 1.00  0.00  ... 0.00 2.00    1.00   \n",
       "2 1.00 1.00  0.00  0.00 3.00 3.00 3.00 3.00 1.00  0.00  ... 0.00 2.00    1.00   \n",
       "3 1.00 1.00  0.00  0.00 3.00 3.00 3.00 3.00 1.00  0.00  ... 0.00 2.00    1.00   \n",
       "4 1.00 0.10  0.90  1.80 1.20 3.00 3.00 3.00 1.00  0.00  ... 0.00 2.00    1.00   \n",
       "\n",
       "   InputI  OutputX  OutputN  id  growth      status  strain  \n",
       "0    1.00     3.00     1.00  r1    3.00  infeasible       1  \n",
       "1    1.00     9.00     1.00  r3    9.00     optimal       1  \n",
       "2    1.00     9.00     1.00  r2    9.00     optimal       1  \n",
       "3    1.00     9.00     1.00  r4    9.00     optimal       1  \n",
       "4    1.00     9.00     1.00  r5    9.00  infeasible       1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4046, 25)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ml_functions import *\n",
    "\n",
    "df = pd.read_csv('toy_dataset.csv', index_col=0)\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "df.drop('index', axis=1, inplace=True)\n",
    "\n",
    "display(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intial dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['rxn_a','rxn_b','rxn_c']] = df['id'].str.split(',', expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create `no_deletions` column keeping the number of deletions performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r1</th>\n",
       "      <th>r3</th>\n",
       "      <th>r2</th>\n",
       "      <th>r4</th>\n",
       "      <th>r5</th>\n",
       "      <th>r6</th>\n",
       "      <th>r7</th>\n",
       "      <th>r8</th>\n",
       "      <th>r9</th>\n",
       "      <th>r10</th>\n",
       "      <th>...</th>\n",
       "      <th>OutputX</th>\n",
       "      <th>OutputN</th>\n",
       "      <th>id</th>\n",
       "      <th>growth</th>\n",
       "      <th>status</th>\n",
       "      <th>strain</th>\n",
       "      <th>rxn_a</th>\n",
       "      <th>rxn_b</th>\n",
       "      <th>rxn_c</th>\n",
       "      <th>no_deletions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>r1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>infeasible</td>\n",
       "      <td>1</td>\n",
       "      <td>r1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>r3</td>\n",
       "      <td>9.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>1</td>\n",
       "      <td>r3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>r2</td>\n",
       "      <td>9.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>1</td>\n",
       "      <td>r2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>r4</td>\n",
       "      <td>9.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>1</td>\n",
       "      <td>r4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.20</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>r5</td>\n",
       "      <td>9.00</td>\n",
       "      <td>infeasible</td>\n",
       "      <td>1</td>\n",
       "      <td>r5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    r1   r3    r2    r4   r5   r6   r7   r8   r9   r10  ...  OutputX  OutputN  \\\n",
       "0 0.00 0.10 -0.10 -0.20 1.20 1.00 1.00 1.00 1.00 -0.00  ...     3.00     1.00   \n",
       "1 1.00 0.00  1.00  2.00 1.00 3.00 3.00 3.00 1.00  0.00  ...     9.00     1.00   \n",
       "2 1.00 1.00  0.00  0.00 3.00 3.00 3.00 3.00 1.00  0.00  ...     9.00     1.00   \n",
       "3 1.00 1.00  0.00  0.00 3.00 3.00 3.00 3.00 1.00  0.00  ...     9.00     1.00   \n",
       "4 1.00 0.10  0.90  1.80 1.20 3.00 3.00 3.00 1.00  0.00  ...     9.00     1.00   \n",
       "\n",
       "   id  growth      status  strain  rxn_a  rxn_b  rxn_c  no_deletions  \n",
       "0  r1    3.00  infeasible       1     r1   None   None             1  \n",
       "1  r3    9.00     optimal       1     r3   None   None             1  \n",
       "2  r2    9.00     optimal       1     r2   None   None             1  \n",
       "3  r4    9.00     optimal       1     r4   None   None             1  \n",
       "4  r5    9.00  infeasible       1     r5   None   None             1  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_deletions(x):\n",
    "\n",
    "    return len(x.split(','))\n",
    "\n",
    "no_delitions = []\n",
    "for row in range(len(df)):\n",
    "\n",
    "    num = count_deletions(df['id'].iloc[row])\n",
    "    no_delitions.append(num)\n",
    "\n",
    "df['no_deletions'] = no_delitions\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store reactions names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all reactions names\n",
    "gem_rxn = df[df['no_deletions'] == 1]['id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some statistical study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "infeasible    2802\n",
       "optimal       1244\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset of df containing only infeasible rows\n",
    "df_inf = df[df['status'] == 'infeasible']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Οι παρακάτω αντιδράσεις εάν κοπούν οδηγούν σε **infeasible** κατάσταση. Επομένως, ΔΕ θα πρέπει να περιλαμβάνονται στα deletions. Οι αντιδράσεις αυτές, δηλαδή, θα πρέπει να **προστατευτούν** από τα reaction deletions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['r1', 'r5', 'r6', 'r7', 'r8', 'r9', 'r11', 'r12', 'r13', 'outputK',\n",
       "       'r16', 'OutputX'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critical_rxn = df_inf[df_inf['no_deletions']==1]['id'].unique()\n",
    "critical_rxn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Οι αντιδράσεις που φαίνονται στο επόμενο κελί __ΔΕΝ__ οδήγησαν __ποτέ__ σε _infeasible_ status όταν κόπηκαν.\n",
    "\n",
    "Μια λογική είναι να κοπούν οι παρακάτω αντιδράσεις. Εξαίρεση, οι αντιδράσεις που αφορούν input/output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['r10', 'r3', 'InputA', 'r14', 'r2', 'OutputN', 'r4', 'InputI', 'r15']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rxn_deletable = list(set(df_inf[df_inf['no_deletions']==1]['id'].unique()) ^ set(gem_rxn))\n",
    "rxn_deletable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_del_rxn_a = df.loc[df['rxn_a'].isin(critical_rxn)].index\n",
    "df.drop(index_del_rxn_a, inplace=True)\n",
    "\n",
    "index_del_rxn_b = df.loc[df['rxn_b'].isin(critical_rxn)].index\n",
    "df.drop(index_del_rxn_b, inplace=True)\n",
    "\n",
    "index_del_rxn_c = df.loc[df['rxn_c'].isin(critical_rxn)].index\n",
    "df.drop(index_del_rxn_c, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(438, 29)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find and Delete Duplicated Rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258, 29)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_a = df[df['rxn_a'] == df['rxn_b']].index\n",
    "df.drop(index_a, axis=0, inplace=True)\n",
    "\n",
    "index_b = df[df['rxn_a'] == df['rxn_c']].index\n",
    "df.drop(index_b, axis=0, inplace=True)\n",
    "\n",
    "index_c = df[df['rxn_b'] == df['rxn_c']].index\n",
    "df.drop(index_c, axis=0, inplace=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r1</th>\n",
       "      <th>r3</th>\n",
       "      <th>r2</th>\n",
       "      <th>r4</th>\n",
       "      <th>r5</th>\n",
       "      <th>r6</th>\n",
       "      <th>r7</th>\n",
       "      <th>r8</th>\n",
       "      <th>r9</th>\n",
       "      <th>r10</th>\n",
       "      <th>...</th>\n",
       "      <th>OutputX</th>\n",
       "      <th>OutputN</th>\n",
       "      <th>id</th>\n",
       "      <th>growth</th>\n",
       "      <th>status</th>\n",
       "      <th>strain</th>\n",
       "      <th>rxn_a</th>\n",
       "      <th>rxn_b</th>\n",
       "      <th>rxn_c</th>\n",
       "      <th>no_deletions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>r3</td>\n",
       "      <td>9.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>1</td>\n",
       "      <td>r3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>r2</td>\n",
       "      <td>9.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>1</td>\n",
       "      <td>r2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>r4</td>\n",
       "      <td>9.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>1</td>\n",
       "      <td>r4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.20</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>r10</td>\n",
       "      <td>9.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>1</td>\n",
       "      <td>r10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.20</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>r14</td>\n",
       "      <td>9.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>1</td>\n",
       "      <td>r14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     r1   r3   r2   r4   r5   r6   r7   r8   r9  r10  ...  OutputX  OutputN  \\\n",
       "1  1.00 0.00 1.00 2.00 1.00 3.00 3.00 3.00 1.00 0.00  ...     9.00     1.00   \n",
       "2  1.00 1.00 0.00 0.00 3.00 3.00 3.00 3.00 1.00 0.00  ...     9.00     1.00   \n",
       "3  1.00 1.00 0.00 0.00 3.00 3.00 3.00 3.00 1.00 0.00  ...     9.00     1.00   \n",
       "9  1.00 0.10 0.90 1.80 1.20 3.00 3.00 3.00 1.00 0.00  ...     9.00     1.00   \n",
       "14 1.00 0.10 0.90 1.80 1.20 3.00 3.00 3.00 1.00 0.00  ...     9.00     1.00   \n",
       "\n",
       "     id  growth   status  strain  rxn_a  rxn_b  rxn_c  no_deletions  \n",
       "1    r3    9.00  optimal       1     r3   None   None             1  \n",
       "2    r2    9.00  optimal       1     r2   None   None             1  \n",
       "3    r4    9.00  optimal       1     r4   None   None             1  \n",
       "9   r10    9.00  optimal       1    r10   None   None             1  \n",
       "14  r14    9.00  optimal       1    r14   None   None             1  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deletions matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Binary\" matrix:\n",
    "    \n",
    "    -cols: reactions\n",
    "    \n",
    "    -values: 1 (reaction is deleted) - 0 (otherwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deletions = pd.DataFrame()\n",
    "\n",
    "# for rxn in rxn_deletable:\n",
    "#     deletions[rxn] = np.nan\n",
    "    \n",
    "# deletions['id'] = df['id']\n",
    "# deletions.tail()\n",
    "\n",
    "# for row in range(deletions.shape[0]):\n",
    "\n",
    "#     deleted_rxn = deletions.iloc[row]['id']\n",
    "    \n",
    "#     for col in deletions.columns:\n",
    "#         if(col in deleted_rxn): deletions[col].iloc[row] = 1\n",
    "\n",
    "# deletions.fillna(0, inplace=True)\n",
    "\n",
    "# new_names = []\n",
    "# for col in deletions.columns:\n",
    "#     new_names.append('del_'+col)\n",
    "    \n",
    "# deletions.columns = new_names\n",
    "# deletions.drop('del_id', axis=1, inplace=True)\n",
    "\n",
    "# df = pd.concat([df, deletions], axis=1)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)\n",
    "# df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258, 29)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r1</th>\n",
       "      <th>r3</th>\n",
       "      <th>r2</th>\n",
       "      <th>r4</th>\n",
       "      <th>r5</th>\n",
       "      <th>r6</th>\n",
       "      <th>r7</th>\n",
       "      <th>r8</th>\n",
       "      <th>r9</th>\n",
       "      <th>r10</th>\n",
       "      <th>...</th>\n",
       "      <th>OutputX</th>\n",
       "      <th>OutputN</th>\n",
       "      <th>id</th>\n",
       "      <th>growth</th>\n",
       "      <th>status</th>\n",
       "      <th>strain</th>\n",
       "      <th>rxn_a</th>\n",
       "      <th>rxn_b</th>\n",
       "      <th>rxn_c</th>\n",
       "      <th>no_deletions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>r3</td>\n",
       "      <td>9.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>1</td>\n",
       "      <td>r3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>r2</td>\n",
       "      <td>9.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>1</td>\n",
       "      <td>r2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>r4</td>\n",
       "      <td>9.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>1</td>\n",
       "      <td>r4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.20</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>r10</td>\n",
       "      <td>9.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>1</td>\n",
       "      <td>r10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.20</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>r14</td>\n",
       "      <td>9.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>1</td>\n",
       "      <td>r14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     r1   r3   r2   r4   r5   r6   r7   r8   r9  r10  ...  OutputX  OutputN  \\\n",
       "1  1.00 0.00 1.00 2.00 1.00 3.00 3.00 3.00 1.00 0.00  ...     9.00     1.00   \n",
       "2  1.00 1.00 0.00 0.00 3.00 3.00 3.00 3.00 1.00 0.00  ...     9.00     1.00   \n",
       "3  1.00 1.00 0.00 0.00 3.00 3.00 3.00 3.00 1.00 0.00  ...     9.00     1.00   \n",
       "9  1.00 0.10 0.90 1.80 1.20 3.00 3.00 3.00 1.00 0.00  ...     9.00     1.00   \n",
       "14 1.00 0.10 0.90 1.80 1.20 3.00 3.00 3.00 1.00 0.00  ...     9.00     1.00   \n",
       "\n",
       "     id  growth   status  strain  rxn_a  rxn_b  rxn_c  no_deletions  \n",
       "1    r3    9.00  optimal       1     r3   None   None             1  \n",
       "2    r2    9.00  optimal       1     r2   None   None             1  \n",
       "3    r4    9.00  optimal       1     r4   None   None             1  \n",
       "9   r10    9.00  optimal       1    r10   None   None             1  \n",
       "14  r14    9.00  optimal       1    r14   None   None             1  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Study dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>growth</th>\n",
       "      <td>258.00</td>\n",
       "      <td>4.94</td>\n",
       "      <td>3.37</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count  mean  std   min  25%  50%  75%   max\n",
       "growth 258.00  4.94 3.37 -3.00 3.00 6.00 6.00 10.00"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df[['growth']].describe()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=df, x=\"growth\", bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r1</th>\n",
       "      <th>r3</th>\n",
       "      <th>r2</th>\n",
       "      <th>r4</th>\n",
       "      <th>r5</th>\n",
       "      <th>r6</th>\n",
       "      <th>r7</th>\n",
       "      <th>r8</th>\n",
       "      <th>r9</th>\n",
       "      <th>r10</th>\n",
       "      <th>...</th>\n",
       "      <th>OutputX</th>\n",
       "      <th>OutputN</th>\n",
       "      <th>id</th>\n",
       "      <th>growth</th>\n",
       "      <th>status</th>\n",
       "      <th>strain</th>\n",
       "      <th>rxn_a</th>\n",
       "      <th>rxn_b</th>\n",
       "      <th>rxn_c</th>\n",
       "      <th>no_deletions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>-2.20</td>\n",
       "      <td>1.20</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>InputA,InputI</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>infeasible</td>\n",
       "      <td>1</td>\n",
       "      <td>InputA</td>\n",
       "      <td>InputI</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>r3,InputA,InputI</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>infeasible</td>\n",
       "      <td>1</td>\n",
       "      <td>r3</td>\n",
       "      <td>InputA</td>\n",
       "      <td>InputI</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>r2,InputA,InputI</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>infeasible</td>\n",
       "      <td>1</td>\n",
       "      <td>r2</td>\n",
       "      <td>InputA</td>\n",
       "      <td>InputI</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>r4,InputA,InputI</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>infeasible</td>\n",
       "      <td>1</td>\n",
       "      <td>r4</td>\n",
       "      <td>InputA</td>\n",
       "      <td>InputI</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>-2.20</td>\n",
       "      <td>1.20</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>r10,InputA,InputI</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>infeasible</td>\n",
       "      <td>1</td>\n",
       "      <td>r10</td>\n",
       "      <td>InputA</td>\n",
       "      <td>InputI</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>-2.20</td>\n",
       "      <td>1.20</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>r14,InputA,InputI</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>infeasible</td>\n",
       "      <td>1</td>\n",
       "      <td>r14</td>\n",
       "      <td>InputA</td>\n",
       "      <td>InputI</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>-2.20</td>\n",
       "      <td>1.20</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>r15,InputA,InputI</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>infeasible</td>\n",
       "      <td>1</td>\n",
       "      <td>r15</td>\n",
       "      <td>InputA</td>\n",
       "      <td>InputI</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>InputA,InputI,OutputN</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>infeasible</td>\n",
       "      <td>1</td>\n",
       "      <td>InputA</td>\n",
       "      <td>InputI</td>\n",
       "      <td>OutputN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2544</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>r3,r2,OutputN</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>2</td>\n",
       "      <td>r3</td>\n",
       "      <td>r2</td>\n",
       "      <td>OutputN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2562</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>r3,r4,OutputN</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>2</td>\n",
       "      <td>r3</td>\n",
       "      <td>r4</td>\n",
       "      <td>OutputN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>r2,r10,InputA</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>infeasible</td>\n",
       "      <td>2</td>\n",
       "      <td>r2</td>\n",
       "      <td>r10</td>\n",
       "      <td>InputA</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       r1    r3    r2    r4    r5    r6    r7    r8    r9  r10  ...  OutputX  \\\n",
       "243  0.00  0.10 -1.10 -2.20  1.20 -1.00 -1.00 -1.00  0.00 1.00  ...    -3.00   \n",
       "684  0.00  0.00 -1.00 -2.00  1.00 -1.00 -1.00 -1.00 -0.00 1.00  ...    -3.00   \n",
       "874  0.00 -1.00  0.00  0.00 -1.00 -1.00 -1.00 -1.00  0.00 1.00  ...    -3.00   \n",
       "1045 0.00 -1.00  0.00  0.00 -1.00 -1.00 -1.00 -1.00  0.00 1.00  ...    -3.00   \n",
       "1728 0.00  0.10 -1.10 -2.20  1.20 -1.00 -1.00 -1.00  0.00 1.00  ...    -3.00   \n",
       "1958 0.00  0.10 -1.10 -2.20  1.20 -1.00 -1.00 -1.00 -0.00 1.00  ...    -3.00   \n",
       "1979 0.00  0.10 -1.10 -2.20  1.20 -1.00 -1.00 -1.00 -0.00 1.00  ...    -3.00   \n",
       "2009 0.00  0.10 -0.43 -0.87  0.20 -0.67 -0.67 -1.00 -0.00 0.33  ...    -2.00   \n",
       "2544 1.00  0.00  0.00  0.00 -0.00 -0.00 -0.00 -1.00  0.00 1.00  ...    -0.00   \n",
       "2562 1.00  0.00  0.00  0.00 -0.00 -0.00 -0.00 -1.00  0.00 1.00  ...    -0.00   \n",
       "2836 0.00  0.00  0.00  0.00  0.00 -0.00 -0.00 -0.00  0.00 0.00  ...    -0.00   \n",
       "\n",
       "      OutputN                     id  growth      status  strain   rxn_a  \\\n",
       "243      1.00          InputA,InputI   -3.00  infeasible       1  InputA   \n",
       "684      1.00       r3,InputA,InputI   -3.00  infeasible       1      r3   \n",
       "874      1.00       r2,InputA,InputI   -3.00  infeasible       1      r2   \n",
       "1045     1.00       r4,InputA,InputI   -3.00  infeasible       1      r4   \n",
       "1728     1.00      r10,InputA,InputI   -3.00  infeasible       1     r10   \n",
       "1958     1.00      r14,InputA,InputI   -3.00  infeasible       1     r14   \n",
       "1979     1.00      r15,InputA,InputI   -3.00  infeasible       1     r15   \n",
       "2009     0.00  InputA,InputI,OutputN   -2.00  infeasible       1  InputA   \n",
       "2544     0.00          r3,r2,OutputN   -0.00     optimal       2      r3   \n",
       "2562     0.00          r3,r4,OutputN   -0.00     optimal       2      r3   \n",
       "2836     0.00          r2,r10,InputA   -0.00  infeasible       2      r2   \n",
       "\n",
       "       rxn_b    rxn_c  no_deletions  \n",
       "243   InputI     None             2  \n",
       "684   InputA   InputI             3  \n",
       "874   InputA   InputI             3  \n",
       "1045  InputA   InputI             3  \n",
       "1728  InputA   InputI             3  \n",
       "1958  InputA   InputI             3  \n",
       "1979  InputA   InputI             3  \n",
       "2009  InputI  OutputN             3  \n",
       "2544      r2  OutputN             3  \n",
       "2562      r4  OutputN             3  \n",
       "2836     r10   InputA             3  \n",
       "\n",
       "[11 rows x 29 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['growth'] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11 rows of __negative__ growth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace negative growth with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9869/766195947.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if(df['growth'].iloc[row] < 0): df['growth'].iloc[row] = 0\n"
     ]
    }
   ],
   "source": [
    "for row in range(len(df)):\n",
    "    if(df['growth'].iloc[row] < 0): df['growth'].iloc[row] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create _dummy variables_ for `status`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r1</th>\n",
       "      <th>r3</th>\n",
       "      <th>r2</th>\n",
       "      <th>r4</th>\n",
       "      <th>r5</th>\n",
       "      <th>r6</th>\n",
       "      <th>r7</th>\n",
       "      <th>r8</th>\n",
       "      <th>r9</th>\n",
       "      <th>r10</th>\n",
       "      <th>...</th>\n",
       "      <th>id</th>\n",
       "      <th>growth</th>\n",
       "      <th>status</th>\n",
       "      <th>strain</th>\n",
       "      <th>rxn_a</th>\n",
       "      <th>rxn_b</th>\n",
       "      <th>rxn_c</th>\n",
       "      <th>no_deletions</th>\n",
       "      <th>infeasible</th>\n",
       "      <th>optimal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>r3</td>\n",
       "      <td>9.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>1</td>\n",
       "      <td>r3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>r2</td>\n",
       "      <td>9.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>1</td>\n",
       "      <td>r2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>r4</td>\n",
       "      <td>9.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>1</td>\n",
       "      <td>r4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.20</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>r10</td>\n",
       "      <td>9.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>1</td>\n",
       "      <td>r10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.20</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>r14</td>\n",
       "      <td>9.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>1</td>\n",
       "      <td>r14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3986</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>r14,InputI,OutputN</td>\n",
       "      <td>6.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>2</td>\n",
       "      <td>r14</td>\n",
       "      <td>InputI</td>\n",
       "      <td>OutputN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>r15,InputA,InputI</td>\n",
       "      <td>0.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>2</td>\n",
       "      <td>r15</td>\n",
       "      <td>InputA</td>\n",
       "      <td>InputI</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4004</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>r15,InputA,OutputN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>2</td>\n",
       "      <td>r15</td>\n",
       "      <td>InputA</td>\n",
       "      <td>OutputN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>r15,InputI,OutputN</td>\n",
       "      <td>6.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>2</td>\n",
       "      <td>r15</td>\n",
       "      <td>InputI</td>\n",
       "      <td>OutputN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4032</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>InputA,InputI,OutputN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>2</td>\n",
       "      <td>InputA</td>\n",
       "      <td>InputI</td>\n",
       "      <td>OutputN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       r1   r3    r2    r4   r5   r6   r7   r8   r9   r10  ...  \\\n",
       "1    1.00 0.00  1.00  2.00 1.00 3.00 3.00 3.00 1.00  0.00  ...   \n",
       "2    1.00 1.00  0.00  0.00 3.00 3.00 3.00 3.00 1.00  0.00  ...   \n",
       "3    1.00 1.00  0.00  0.00 3.00 3.00 3.00 3.00 1.00  0.00  ...   \n",
       "9    1.00 0.10  0.90  1.80 1.20 3.00 3.00 3.00 1.00  0.00  ...   \n",
       "14   1.00 0.10  0.90  1.80 1.20 3.00 3.00 3.00 1.00  0.00  ...   \n",
       "...   ...  ...   ...   ...  ...  ...  ...  ...  ...   ...  ...   \n",
       "3986 1.00 1.00 -0.00 -0.00 2.00 2.00 2.00 2.00 0.00  0.00  ...   \n",
       "4002 0.00 0.10 -0.10 -0.20 0.20 0.00 0.00 0.00 0.00 -0.00  ...   \n",
       "4004 0.00 0.10 -0.10 -0.20 0.20 0.00 0.00 0.00 0.00 -0.00  ...   \n",
       "4007 1.00 1.00 -0.00  0.00 2.00 2.00 2.00 2.00 0.00  0.00  ...   \n",
       "4032 0.00 1.00 -1.00 -2.00 2.00 0.00 0.00 0.00 0.00  0.00  ...   \n",
       "\n",
       "                         id  growth   status  strain   rxn_a   rxn_b    rxn_c  \\\n",
       "1                        r3    9.00  optimal       1      r3    None     None   \n",
       "2                        r2    9.00  optimal       1      r2    None     None   \n",
       "3                        r4    9.00  optimal       1      r4    None     None   \n",
       "9                       r10    9.00  optimal       1     r10    None     None   \n",
       "14                      r14    9.00  optimal       1     r14    None     None   \n",
       "...                     ...     ...      ...     ...     ...     ...      ...   \n",
       "3986     r14,InputI,OutputN    6.00  optimal       2     r14  InputI  OutputN   \n",
       "4002      r15,InputA,InputI    0.00  optimal       2     r15  InputA   InputI   \n",
       "4004     r15,InputA,OutputN    0.00  optimal       2     r15  InputA  OutputN   \n",
       "4007     r15,InputI,OutputN    6.00  optimal       2     r15  InputI  OutputN   \n",
       "4032  InputA,InputI,OutputN    0.00  optimal       2  InputA  InputI  OutputN   \n",
       "\n",
       "      no_deletions  infeasible  optimal  \n",
       "1                1           0        1  \n",
       "2                1           0        1  \n",
       "3                1           0        1  \n",
       "9                1           0        1  \n",
       "14               1           0        1  \n",
       "...            ...         ...      ...  \n",
       "3986             3           0        1  \n",
       "4002             3           0        1  \n",
       "4004             3           0        1  \n",
       "4007             3           0        1  \n",
       "4032             3           0        1  \n",
       "\n",
       "[258 rows x 31 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_status = pd.get_dummies(df['status'])\n",
    "df = pd.concat([df, dummy_status], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Linear Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Point Biserial Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pearsons</th>\n",
       "      <th>spearman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>infeasible</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_deletions</th>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InputI</th>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r14</th>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r15</th>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OutputN</th>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r4</th>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r10</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>growth</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InputA</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r3</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strain</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimal</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pearsons  spearman\n",
       "infeasible       -1.00     -1.00\n",
       "no_deletions     -0.25     -0.24\n",
       "InputI           -0.22     -0.22\n",
       "r14              -0.21     -0.30\n",
       "r15              -0.21     -0.16\n",
       "OutputN          -0.13     -0.11\n",
       "r2               -0.07     -0.13\n",
       "r4               -0.07     -0.10\n",
       "r10               0.01      0.13\n",
       "growth            0.05      0.05\n",
       "InputA            0.19      0.19\n",
       "r3                0.22      0.17\n",
       "strain            0.42      0.42\n",
       "optimal           1.00      1.00"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsons = df.drop(columns=critical_rxn).corr(numeric_only=True)['optimal'].sort_values(ascending=False)\n",
    "spearman = df.drop(columns=critical_rxn).corr(numeric_only=True, method='spearman')['optimal'].sort_values(ascending=False)\n",
    "\n",
    "corr_matrix = pd.DataFrame({'pearsons':pearsons, 'spearman':spearman})\n",
    "corr_matrix.sort_values(by='pearsons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pearsons</th>\n",
       "      <th>spearman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>growth</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r10</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r4</th>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pearsons  spearman\n",
       "growth      0.05      0.05\n",
       "r10         0.01      0.13\n",
       "r2         -0.07     -0.13\n",
       "r4         -0.07     -0.10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix[abs(corr_matrix['pearsons']) < 0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI / ML Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create _training_ and _test_ sets and _data normalization_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `df` keeping only _non critical_ reactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=critical_rxn, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['r3', 'r2', 'r4', 'r10', 'r14', 'r15', 'InputA', 'InputI', 'OutputN',\n",
       "       'id', 'growth', 'status', 'strain', 'rxn_a', 'rxn_b', 'rxn_c',\n",
       "       'no_deletions', 'infeasible', 'optimal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r3</th>\n",
       "      <th>r2</th>\n",
       "      <th>r4</th>\n",
       "      <th>r10</th>\n",
       "      <th>r14</th>\n",
       "      <th>r15</th>\n",
       "      <th>InputA</th>\n",
       "      <th>InputI</th>\n",
       "      <th>OutputN</th>\n",
       "      <th>growth</th>\n",
       "      <th>strain</th>\n",
       "      <th>no_deletions</th>\n",
       "      <th>infeasible</th>\n",
       "      <th>optimal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     r3   r2   r4  r10  r14  r15  InputA  InputI  OutputN  growth  strain  \\\n",
       "1  0.00 1.00 2.00 0.00 0.00 0.00    1.00    1.00     1.00    9.00       1   \n",
       "2  1.00 0.00 0.00 0.00 0.00 0.00    1.00    1.00     1.00    9.00       1   \n",
       "3  1.00 0.00 0.00 0.00 0.00 0.00    1.00    1.00     1.00    9.00       1   \n",
       "9  0.10 0.90 1.80 0.00 0.00 0.00    1.00    1.00     1.00    9.00       1   \n",
       "14 0.10 0.90 1.80 0.00 0.00 0.00    1.00    1.00     1.00    9.00       1   \n",
       "\n",
       "    no_deletions  infeasible  optimal  \n",
       "1              1           0        1  \n",
       "2              1           0        1  \n",
       "3              1           0        1  \n",
       "9              1           0        1  \n",
       "14             1           0        1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_drop = ['id', 'rxn_a', 'rxn_b', 'rxn_c', 'status']\n",
    "df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258, 14)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9869/253647673.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['val_growth'].iloc[row] = 1\n",
      "/tmp/ipykernel_9869/253647673.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['val_growth'].iloc[row] = 0\n",
      "/tmp/ipykernel_9869/253647673.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['val_growth'].iloc[row] = 1\n",
      "/tmp/ipykernel_9869/253647673.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['val_growth'].iloc[row] = 0\n"
     ]
    }
   ],
   "source": [
    "df['val_growth'] = np.nan\n",
    "\n",
    "growth_strain_1 = 9\n",
    "growth_strain_2 = 6\n",
    "growth_threshold = 0.1\n",
    "\n",
    "for row in range(len(df)):\n",
    "    \n",
    "    if(df['strain'].iloc[row] == 1):\n",
    "        if (df['growth'].iloc[row] >  growth_strain_1 - growth_strain_1 * growth_threshold) and (df['growth'].iloc[row] >  growth_strain_1 - growth_strain_1 * growth_threshold):\n",
    "            df['val_growth'].iloc[row] = 1\n",
    "        else:\n",
    "            df['val_growth'].iloc[row] = 0\n",
    "    elif(df['strain'].iloc[row] == 2):\n",
    "        if (df['growth'].iloc[row] >  growth_strain_2 - growth_strain_2 * growth_threshold) and (df['growth'].iloc[row] >  growth_strain_2 - growth_strain_2 * growth_threshold):\n",
    "            df['val_growth'].iloc[row] = 1\n",
    "        else:\n",
    "            df['val_growth'].iloc[row] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic ML libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define **target** variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to better define the target that we want to predict!\n",
    "\n",
    "(The most simple and obvious answer is to predit **optimal** column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Θα *δοκιμάσω* να χρησιμοποιήσω ως στόχο την πρόβλεψη του αν πρόκειται για infeasible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00    207\n",
       "1.00     51\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'] = (1-df['val_growth']) * df['infeasible']\n",
    "# df['target'] = df['infeasible']\n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['r3', 'r2', 'r4', 'r10', 'r14', 'r15', 'InputA', 'InputI', 'OutputN',\n",
       "       'growth', 'strain', 'no_deletions', 'infeasible', 'optimal',\n",
       "       'val_growth', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(258, 9)\n",
      "(258,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['optimal', 'infeasible', 'growth', 'strain', 'no_deletions', 'target', 'val_growth'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.20, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['r3', 'r2', 'r4', 'r10', 'r14', 'r15', 'InputA', 'InputI', 'OutputN'], dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use of stratify sampling to get the same optimal/infeasible rates on train and test sets as to the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train\n",
    "X_test_scaled = X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC = 0.6523809523809524\n",
      "ACCURACY = 0.8076923076923077\n",
      "F1 = 0.4444444444444445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression().fit(X_train_scaled, y_train)\n",
    "\n",
    "validation_classification(lr_model, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comex/Desktop/python-envs/main-bio/lib/python3.9/site-packages/sklearn/model_selection/_search.py:306: UserWarning: The total space of parameters 36 is smaller than n_iter=50. Running 36 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/home/comex/Desktop/python-envs/main-bio/lib/python3.9/site-packages/sklearn/model_selection/_search.py:306: UserWarning: The total space of parameters 36 is smaller than n_iter=50. Running 36 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/home/comex/Desktop/python-envs/main-bio/lib/python3.9/site-packages/sklearn/model_selection/_search.py:306: UserWarning: The total space of parameters 36 is smaller than n_iter=50. Running 36 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "[CV 2/3; 2/36] START C=0.001, gamma=1, kernel=linear............................\n",
      "[CV 2/3; 2/36] END C=0.001, gamma=1, kernel=linear;, score=0.892 total time=   0.0s\n",
      "[CV 3/3; 3/36] START C=0.001, gamma=2, kernel=rbf...............................\n",
      "[CV 3/3; 3/36] END C=0.001, gamma=2, kernel=rbf;, score=0.854 total time=   0.0s\n",
      "[CV 1/3; 4/36] START C=0.001, gamma=2, kernel=linear............................\n",
      "[CV 1/3; 4/36] END C=0.001, gamma=2, kernel=linear;, score=0.677 total time=   0.0s\n",
      "[CV 3/3; 4/36] START C=0.001, gamma=2, kernel=linear............................\n",
      "[CV 3/3; 4/36] END C=0.001, gamma=2, kernel=linear;, score=0.903 total time=   0.0s\n",
      "[CV 2/3; 5/36] START C=0.001, gamma=3, kernel=rbf...............................\n",
      "[CV 2/3; 5/36] END C=0.001, gamma=3, kernel=rbf;, score=0.841 total time=   0.0s\n",
      "[CV 2/3; 6/36] START C=0.001, gamma=3, kernel=linear............................\n",
      "[CV 2/3; 6/36] END C=0.001, gamma=3, kernel=linear;, score=0.892 total time=   0.0s\n",
      "[CV 2/3; 7/36] START C=0.005, gamma=1, kernel=rbf...............................\n",
      "[CV 2/3; 7/36] END C=0.005, gamma=1, kernel=rbf;, score=0.870 total time=   0.0s\n",
      "[CV 2/3; 8/36] START C=0.005, gamma=1, kernel=linear............................\n",
      "[CV 2/3; 8/36] END C=0.005, gamma=1, kernel=linear;, score=0.895 total time=   0.0s\n",
      "[CV 3/3; 8/36] START C=0.005, gamma=1, kernel=linear............................\n",
      "[CV 3/3; 8/36] END C=0.005, gamma=1, kernel=linear;, score=0.854 total time=   0.0s\n",
      "[CV 2/3; 10/36] START C=0.005, gamma=2, kernel=linear...........................\n",
      "[CV 2/3; 10/36] END C=0.005, gamma=2, kernel=linear;, score=0.895 total time=   0.0s\n",
      "[CV 1/3; 12/36] START C=0.005, gamma=3, kernel=linear...........................\n",
      "[CV 1/3; 12/36] END C=0.005, gamma=3, kernel=linear;, score=0.677 total time=   0.0s\n",
      "[CV 2/3; 14/36] START C=0.01, gamma=1, kernel=linear............................\n",
      "[CV 2/3; 14/36] END C=0.01, gamma=1, kernel=linear;, score=0.890 total time=   0.0s\n",
      "[CV 1/3; 17/36] START C=0.01, gamma=3, kernel=rbf...............................\n",
      "[CV 1/3; 17/36] END C=0.01, gamma=3, kernel=rbf;, score=0.838 total time=   0.0s\n",
      "[CV 2/3; 17/36] START C=0.01, gamma=3, kernel=rbf...............................\n",
      "[CV 2/3; 17/36] END C=0.01, gamma=3, kernel=rbf;, score=0.844 total time=   0.0s\n",
      "[CV 1/3; 21/36] START C=0.02, gamma=2, kernel=rbf...............................\n",
      "[CV 1/3; 21/36] END C=0.02, gamma=2, kernel=rbf;, score=0.819 total time=   0.0s\n",
      "[CV 2/3; 21/36] START C=0.02, gamma=2, kernel=rbf...............................\n",
      "[CV 2/3; 21/36] END C=0.02, gamma=2, kernel=rbf;, score=0.814 total time=   0.0s\n",
      "[CV 1/3; 25/36] START C=0.05, gamma=1, kernel=rbf...............................\n",
      "[CV 1/3; 25/36] END C=0.05, gamma=1, kernel=rbf;, score=0.844 total time=   0.0s\n",
      "[CV 2/3; 25/36] START C=0.05, gamma=1, kernel=rbf...............................\n",
      "[CV 2/3; 25/36] END C=0.05, gamma=1, kernel=rbf;, score=0.824 total time=   0.0s\n",
      "[CV 2/3; 29/36] START C=0.05, gamma=3, kernel=rbf...............................\n",
      "[CV 2/3; 29/36] END C=0.05, gamma=3, kernel=rbf;, score=0.861 total time=   0.0s\n",
      "[CV 3/3; 31/36] START C=0.1, gamma=1, kernel=rbf................................\n",
      "[CV 3/3; 31/36] END .C=0.1, gamma=1, kernel=rbf;, score=0.837 total time=   0.0s\n",
      "[CV 1/3; 34/36] START C=0.1, gamma=2, kernel=linear.............................\n",
      "[CV 1/3; 34/36] END C=0.1, gamma=2, kernel=linear;, score=0.675 total time=   0.0s\n",
      "[CV 2/3; 36/36] START C=0.1, gamma=3, kernel=linear.............................\n",
      "[CV 2/3; 36/36] END C=0.1, gamma=3, kernel=linear;, score=0.894 total time=   0.0s\n",
      "[CV 1/3; 3/36] START C=0.001, gamma=2, kernel=rbf...............................\n",
      "[CV 1/3; 3/36] END C=0.001, gamma=2, kernel=rbf;, score=0.881 total time=   0.0s\n",
      "[CV 2/3; 5/36] START C=0.001, gamma=3, kernel=rbf...............................\n",
      "[CV 2/3; 5/36] END C=0.001, gamma=3, kernel=rbf;, score=0.851 total time=   0.0s\n",
      "[CV 1/3; 9/36] START C=0.005, gamma=2, kernel=rbf...............................\n",
      "[CV 1/3; 9/36] END C=0.005, gamma=2, kernel=rbf;, score=0.888 total time=   0.0s\n",
      "[CV 2/3; 9/36] START C=0.005, gamma=2, kernel=rbf...............................\n",
      "[CV 2/3; 9/36] END C=0.005, gamma=2, kernel=rbf;, score=0.787 total time=   0.0s\n",
      "[CV 2/3; 14/36] START C=0.01, gamma=1, kernel=linear............................\n",
      "[CV 2/3; 14/36] END C=0.01, gamma=1, kernel=linear;, score=0.888 total time=   0.0s\n",
      "[CV 3/3; 14/36] START C=0.01, gamma=1, kernel=linear............................\n",
      "[CV 3/3; 14/36] END C=0.01, gamma=1, kernel=linear;, score=0.647 total time=   0.0s\n",
      "[CV 2/3; 22/36] START C=0.02, gamma=2, kernel=linear............................\n",
      "[CV 2/3; 22/36] END C=0.02, gamma=2, kernel=linear;, score=0.887 total time=   0.0s\n",
      "[CV 3/3; 22/36] START C=0.02, gamma=2, kernel=linear............................\n",
      "[CV 3/3; 22/36] END C=0.02, gamma=2, kernel=linear;, score=0.840 total time=   0.0s\n",
      "[CV 1/3; 23/36] START C=0.02, gamma=3, kernel=rbf...............................\n",
      "[CV 1/3; 23/36] END C=0.02, gamma=3, kernel=rbf;, score=0.877 total time=   0.0s\n",
      "[CV 2/3; 23/36] START C=0.02, gamma=3, kernel=rbf...............................\n",
      "[CV 2/3; 23/36] END C=0.02, gamma=3, kernel=rbf;, score=0.782 total time=   0.0s\n",
      "[CV 2/3; 29/36] START C=0.05, gamma=3, kernel=rbf...............................\n",
      "[CV 2/3; 29/36] END C=0.05, gamma=3, kernel=rbf;, score=0.640 total time=   0.0s\n",
      "[CV 2/3; 31/36] START C=0.1, gamma=1, kernel=rbf................................\n",
      "[CV 2/3; 31/36] END .C=0.1, gamma=1, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 1/3; 34/36] START C=0.1, gamma=2, kernel=linear.............................\n",
      "[CV 1/3; 34/36] END C=0.1, gamma=2, kernel=linear;, score=0.879 total time=   0.0s\n",
      "[CV 2/3; 36/36] START C=0.1, gamma=3, kernel=linear.............................\n",
      "[CV 2/3; 36/36] END C=0.1, gamma=3, kernel=linear;, score=0.887 total time=   0.0s\n",
      "[CV 1/3; 3/36] START C=0.001, gamma=2, kernel=rbf...............................\n",
      "[CV 1/3; 3/36] END C=0.001, gamma=2, kernel=rbf;, score=0.554 total time=   0.0s\n",
      "[CV 3/3; 5/36] START C=0.001, gamma=3, kernel=rbf...............................\n",
      "[CV 3/3; 5/36] END C=0.001, gamma=3, kernel=rbf;, score=0.553 total time=   0.0s\n",
      "[CV 2/3; 8/36] START C=0.005, gamma=1, kernel=linear............................\n",
      "[CV 2/3; 8/36] END C=0.005, gamma=1, kernel=linear;, score=0.853 total time=   0.0s\n",
      "[CV 3/3; 8/36] START C=0.005, gamma=1, kernel=linear............................\n",
      "[CV 3/3; 8/36] END C=0.005, gamma=1, kernel=linear;, score=0.709 total time=   0.0s\n",
      "[CV 2/3; 12/36] START C=0.005, gamma=3, kernel=linear...........................\n",
      "[CV 2/3; 12/36] END C=0.005, gamma=3, kernel=linear;, score=0.853 total time=   0.0s\n",
      "[CV 3/3; 12/36] START C=0.005, gamma=3, kernel=linear...........................\n",
      "[CV 3/3; 12/36] END C=0.005, gamma=3, kernel=linear;, score=0.709 total time=   0.0s\n",
      "[CV 3/3; 15/36] START C=0.01, gamma=2, kernel=rbf...............................\n",
      "[CV 3/3; 15/36] END C=0.01, gamma=2, kernel=rbf;, score=0.774 total time=   0.0s\n",
      "[CV 1/3; 16/36] START C=0.01, gamma=2, kernel=linear............................\n",
      "[CV 1/3; 16/36] END C=0.01, gamma=2, kernel=linear;, score=0.812 total time=   0.0s\n",
      "[CV 1/3; 25/36] START C=0.05, gamma=1, kernel=rbf...............................\n",
      "[CV 1/3; 25/36] END C=0.05, gamma=1, kernel=rbf;, score=0.797 total time=   0.0s\n",
      "[CV 2/3; 25/36] START C=0.05, gamma=1, kernel=rbf...............................\n",
      "[CV 2/3; 25/36] END C=0.05, gamma=1, kernel=rbf;, score=0.771 total time=   0.0s\n",
      "[CV 3/3; 25/36] START C=0.05, gamma=1, kernel=rbf...............................\n",
      "[CV 3/3; 25/36] END C=0.05, gamma=1, kernel=rbf;, score=0.733 total time=   0.0s\n",
      "[CV 1/3; 26/36] START C=0.05, gamma=1, kernel=linear............................\n",
      "[CV 1/3; 26/36] END C=0.05, gamma=1, kernel=linear;, score=0.920 total time=   0.0s\n",
      "[CV 1/3; 29/36] START C=0.05, gamma=3, kernel=rbf...............................\n",
      "[CV 1/3; 29/36] END C=0.05, gamma=3, kernel=rbf;, score=0.848 total time=   0.0s\n",
      "[CV 2/3; 31/36] START C=0.1, gamma=1, kernel=rbf................................\n",
      "[CV 2/3; 31/36] END .C=0.1, gamma=1, kernel=rbf;, score=0.791 total time=   0.0s\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "[CV 2/3; 1/36] START C=0.001, gamma=1, kernel=rbf...............................\n",
      "[CV 2/3; 1/36] END C=0.001, gamma=1, kernel=rbf;, score=0.827 total time=   0.0s\n",
      "[CV 2/3; 4/36] START C=0.001, gamma=2, kernel=linear............................\n",
      "[CV 2/3; 4/36] END C=0.001, gamma=2, kernel=linear;, score=0.892 total time=   0.0s\n",
      "[CV 1/3; 5/36] START C=0.001, gamma=3, kernel=rbf...............................\n",
      "[CV 1/3; 5/36] END C=0.001, gamma=3, kernel=rbf;, score=0.693 total time=   0.0s\n",
      "[CV 3/3; 5/36] START C=0.001, gamma=3, kernel=rbf...............................\n",
      "[CV 3/3; 5/36] END C=0.001, gamma=3, kernel=rbf;, score=0.884 total time=   0.0s\n",
      "[CV 3/3; 6/36] START C=0.001, gamma=3, kernel=linear............................\n",
      "[CV 3/3; 6/36] END C=0.001, gamma=3, kernel=linear;, score=0.903 total time=   0.0s\n",
      "[CV 3/3; 7/36] START C=0.005, gamma=1, kernel=rbf...............................\n",
      "[CV 3/3; 7/36] END C=0.005, gamma=1, kernel=rbf;, score=0.793 total time=   0.0s\n",
      "[CV 1/3; 9/36] START C=0.005, gamma=2, kernel=rbf...............................\n",
      "[CV 1/3; 9/36] END C=0.005, gamma=2, kernel=rbf;, score=0.804 total time=   0.0s\n",
      "[CV 1/3; 11/36] START C=0.005, gamma=3, kernel=rbf..............................\n",
      "[CV 1/3; 11/36] END C=0.005, gamma=3, kernel=rbf;, score=0.841 total time=   0.0s\n",
      "[CV 3/3; 12/36] START C=0.005, gamma=3, kernel=linear...........................\n",
      "[CV 3/3; 12/36] END C=0.005, gamma=3, kernel=linear;, score=0.854 total time=   0.0s\n",
      "[CV 3/3; 16/36] START C=0.01, gamma=2, kernel=linear............................\n",
      "[CV 3/3; 16/36] END C=0.01, gamma=2, kernel=linear;, score=0.881 total time=   0.0s\n",
      "[CV 2/3; 20/36] START C=0.02, gamma=1, kernel=linear............................\n",
      "[CV 2/3; 20/36] END C=0.02, gamma=1, kernel=linear;, score=0.887 total time=   0.0s\n",
      "[CV 3/3; 20/36] START C=0.02, gamma=1, kernel=linear............................\n",
      "[CV 3/3; 20/36] END C=0.02, gamma=1, kernel=linear;, score=0.841 total time=   0.0s\n",
      "[CV 2/3; 24/36] START C=0.02, gamma=3, kernel=linear............................\n",
      "[CV 2/3; 24/36] END C=0.02, gamma=3, kernel=linear;, score=0.887 total time=   0.0s\n",
      "[CV 3/3; 24/36] START C=0.02, gamma=3, kernel=linear............................\n",
      "[CV 3/3; 24/36] END C=0.02, gamma=3, kernel=linear;, score=0.841 total time=   0.0s\n",
      "[CV 3/3; 28/36] START C=0.05, gamma=2, kernel=linear............................\n",
      "[CV 3/3; 28/36] END C=0.05, gamma=2, kernel=linear;, score=0.848 total time=   0.0s\n",
      "[CV 1/3; 31/36] START C=0.1, gamma=1, kernel=rbf................................\n",
      "[CV 1/3; 31/36] END .C=0.1, gamma=1, kernel=rbf;, score=0.843 total time=   0.0s\n",
      "[CV 2/3; 33/36] START C=0.1, gamma=2, kernel=rbf................................\n",
      "[CV 2/3; 33/36] END .C=0.1, gamma=2, kernel=rbf;, score=0.847 total time=   0.0s\n",
      "[CV 3/3; 35/36] START C=0.1, gamma=3, kernel=rbf................................\n",
      "[CV 3/3; 35/36] END .C=0.1, gamma=3, kernel=rbf;, score=0.640 total time=   0.0s\n",
      "[CV 1/3; 2/36] START C=0.001, gamma=1, kernel=linear............................\n",
      "[CV 1/3; 2/36] END C=0.001, gamma=1, kernel=linear;, score=0.859 total time=   0.0s\n",
      "[CV 2/3; 4/36] START C=0.001, gamma=2, kernel=linear............................\n",
      "[CV 2/3; 4/36] END C=0.001, gamma=2, kernel=linear;, score=0.904 total time=   0.0s\n",
      "[CV 3/3; 7/36] START C=0.005, gamma=1, kernel=rbf...............................\n",
      "[CV 3/3; 7/36] END C=0.005, gamma=1, kernel=rbf;, score=0.539 total time=   0.0s\n",
      "[CV 1/3; 8/36] START C=0.005, gamma=1, kernel=linear............................\n",
      "[CV 1/3; 8/36] END C=0.005, gamma=1, kernel=linear;, score=0.859 total time=   0.0s\n",
      "[CV 3/3; 11/36] START C=0.005, gamma=3, kernel=rbf..............................\n",
      "[CV 3/3; 11/36] END C=0.005, gamma=3, kernel=rbf;, score=0.690 total time=   0.0s\n",
      "[CV 1/3; 12/36] START C=0.005, gamma=3, kernel=linear...........................\n",
      "[CV 1/3; 12/36] END C=0.005, gamma=3, kernel=linear;, score=0.859 total time=   0.0s\n",
      "[CV 1/3; 17/36] START C=0.01, gamma=3, kernel=rbf...............................\n",
      "[CV 1/3; 17/36] END C=0.01, gamma=3, kernel=rbf;, score=0.877 total time=   0.0s\n",
      "[CV 2/3; 17/36] START C=0.01, gamma=3, kernel=rbf...............................\n",
      "[CV 2/3; 17/36] END C=0.01, gamma=3, kernel=rbf;, score=0.865 total time=   0.0s\n",
      "[CV 3/3; 17/36] START C=0.01, gamma=3, kernel=rbf...............................\n",
      "[CV 3/3; 17/36] END C=0.01, gamma=3, kernel=rbf;, score=0.540 total time=   0.0s\n",
      "[CV 1/3; 18/36] START C=0.01, gamma=3, kernel=linear............................\n",
      "[CV 1/3; 18/36] END C=0.01, gamma=3, kernel=linear;, score=0.864 total time=   0.0s\n",
      "[CV 3/3; 27/36] START C=0.05, gamma=2, kernel=rbf...............................\n",
      "[CV 3/3; 27/36] END C=0.05, gamma=2, kernel=rbf;, score=0.620 total time=   0.0s\n",
      "[CV 3/3; 28/36] START C=0.05, gamma=2, kernel=linear............................\n",
      "[CV 3/3; 28/36] END C=0.05, gamma=2, kernel=linear;, score=0.685 total time=   0.0s\n",
      "[CV 1/3; 30/36] START C=0.05, gamma=3, kernel=linear............................\n",
      "[CV 1/3; 30/36] END C=0.05, gamma=3, kernel=linear;, score=0.864 total time=   0.0s\n",
      "[CV 2/3; 32/36] START C=0.1, gamma=1, kernel=linear.............................\n",
      "[CV 2/3; 32/36] END C=0.1, gamma=1, kernel=linear;, score=0.887 total time=   0.0s\n",
      "[CV 3/3; 36/36] START C=0.1, gamma=3, kernel=linear.............................\n",
      "[CV 3/3; 36/36] END C=0.1, gamma=3, kernel=linear;, score=0.841 total time=   0.0s\n",
      "[CV 2/3; 3/36] START C=0.001, gamma=2, kernel=rbf...............................\n",
      "[CV 2/3; 3/36] END C=0.001, gamma=2, kernel=rbf;, score=0.864 total time=   0.0s\n",
      "[CV 2/3; 6/36] START C=0.001, gamma=3, kernel=linear............................\n",
      "[CV 2/3; 6/36] END C=0.001, gamma=3, kernel=linear;, score=0.853 total time=   0.0s\n",
      "[CV 3/3; 6/36] START C=0.001, gamma=3, kernel=linear............................\n",
      "[CV 3/3; 6/36] END C=0.001, gamma=3, kernel=linear;, score=0.714 total time=   0.0s\n",
      "[CV 3/3; 11/36] START C=0.005, gamma=3, kernel=rbf..............................\n",
      "[CV 3/3; 11/36] END C=0.005, gamma=3, kernel=rbf;, score=0.776 total time=   0.0s\n",
      "[CV 1/3; 12/36] START C=0.005, gamma=3, kernel=linear...........................\n",
      "[CV 1/3; 12/36] END C=0.005, gamma=3, kernel=linear;, score=0.698 total time=   0.0s\n",
      "[CV 1/3; 17/36] START C=0.01, gamma=3, kernel=rbf...............................\n",
      "[CV 1/3; 17/36] END C=0.01, gamma=3, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 2/3; 17/36] START C=0.01, gamma=3, kernel=rbf...............................\n",
      "[CV 2/3; 17/36] END C=0.01, gamma=3, kernel=rbf;, score=0.850 total time=   0.0s\n",
      "[CV 3/3; 17/36] START C=0.01, gamma=3, kernel=rbf...............................\n",
      "[CV 3/3; 17/36] END C=0.01, gamma=3, kernel=rbf;, score=0.832 total time=   0.0s\n",
      "[CV 1/3; 18/36] START C=0.01, gamma=3, kernel=linear............................\n",
      "[CV 1/3; 18/36] END C=0.01, gamma=3, kernel=linear;, score=0.812 total time=   0.0s\n",
      "[CV 3/3; 27/36] START C=0.05, gamma=2, kernel=rbf...............................\n",
      "[CV 3/3; 27/36] END C=0.05, gamma=2, kernel=rbf;, score=0.661 total time=   0.0s\n",
      "[CV 3/3; 29/36] START C=0.05, gamma=3, kernel=rbf...............................\n",
      "[CV 3/3; 29/36] END C=0.05, gamma=3, kernel=rbf;, score=0.810 total time=   0.0s\n",
      "[CV 2/3; 32/36] START C=0.1, gamma=1, kernel=linear.............................\n",
      "[CV 2/3; 32/36] END C=0.1, gamma=1, kernel=linear;, score=0.853 total time=   0.0s\n",
      "[CV 3/3; 34/36] START C=0.1, gamma=2, kernel=linear.............................\n",
      "[CV 3/3; 34/36] END C=0.1, gamma=2, kernel=linear;, score=0.673 total time=   0.0s\n",
      "[CV 1/3; 1/36] START C=0.001, gamma=1, kernel=rbf...............................\n",
      "[CV 1/3; 1/36] END C=0.001, gamma=1, kernel=rbf;, score=0.688 total time=   0.0s\n",
      "[CV 3/3; 3/36] START C=0.001, gamma=2, kernel=rbf...............................\n",
      "[CV 3/3; 3/36] END C=0.001, gamma=2, kernel=rbf;, score=0.893 total time=   0.0s\n",
      "[CV 2/3; 6/36] START C=0.001, gamma=3, kernel=linear............................\n",
      "[CV 2/3; 6/36] END C=0.001, gamma=3, kernel=linear;, score=0.629 total time=   0.0s\n",
      "[CV 3/3; 6/36] START C=0.001, gamma=3, kernel=linear............................\n",
      "[CV 3/3; 6/36] END C=0.001, gamma=3, kernel=linear;, score=0.913 total time=   0.0s\n",
      "[CV 1/3; 3/36] START C=0.001, gamma=2, kernel=rbf...............................\n",
      "[CV 1/3; 3/36] END C=0.001, gamma=2, kernel=rbf;, score=0.715 total time=   0.0s\n",
      "[CV 1/3; 6/36] START C=0.001, gamma=3, kernel=linear............................\n",
      "[CV 1/3; 6/36] END C=0.001, gamma=3, kernel=linear;, score=0.677 total time=   0.0s\n",
      "[CV 1/3; 7/36] START C=0.005, gamma=1, kernel=rbf...............................\n",
      "[CV 1/3; 7/36] END C=0.005, gamma=1, kernel=rbf;, score=0.836 total time=   0.0s\n",
      "[CV 1/3; 8/36] START C=0.005, gamma=1, kernel=linear............................\n",
      "[CV 1/3; 8/36] END C=0.005, gamma=1, kernel=linear;, score=0.677 total time=   0.0s\n",
      "[CV 2/3; 9/36] START C=0.005, gamma=2, kernel=rbf...............................\n",
      "[CV 2/3; 9/36] END C=0.005, gamma=2, kernel=rbf;, score=0.861 total time=   0.0s\n",
      "[CV 3/3; 13/36] START C=0.01, gamma=1, kernel=rbf...............................\n",
      "[CV 3/3; 13/36] END C=0.01, gamma=1, kernel=rbf;, score=0.646 total time=   0.0s\n",
      "[CV 3/3; 15/36] START C=0.01, gamma=2, kernel=rbf...............................\n",
      "[CV 3/3; 15/36] END C=0.01, gamma=2, kernel=rbf;, score=0.630 total time=   0.0s\n",
      "[CV 2/3; 18/36] START C=0.01, gamma=3, kernel=linear............................\n",
      "[CV 2/3; 18/36] END C=0.01, gamma=3, kernel=linear;, score=0.890 total time=   0.0s\n",
      "[CV 3/3; 18/36] START C=0.01, gamma=3, kernel=linear............................\n",
      "[CV 3/3; 18/36] END C=0.01, gamma=3, kernel=linear;, score=0.881 total time=   0.0s\n",
      "[CV 2/3; 22/36] START C=0.02, gamma=2, kernel=linear............................\n",
      "[CV 2/3; 22/36] END C=0.02, gamma=2, kernel=linear;, score=0.887 total time=   0.0s\n",
      "[CV 3/3; 22/36] START C=0.02, gamma=2, kernel=linear............................\n",
      "[CV 3/3; 22/36] END C=0.02, gamma=2, kernel=linear;, score=0.841 total time=   0.0s\n",
      "[CV 1/3; 27/36] START C=0.05, gamma=2, kernel=rbf...............................\n",
      "[CV 1/3; 27/36] END C=0.05, gamma=2, kernel=rbf;, score=0.821 total time=   0.0s\n",
      "[CV 2/3; 27/36] START C=0.05, gamma=2, kernel=rbf...............................\n",
      "[CV 2/3; 27/36] END C=0.05, gamma=2, kernel=rbf;, score=0.807 total time=   0.0s\n",
      "[CV 3/3; 30/36] START C=0.05, gamma=3, kernel=linear............................\n",
      "[CV 3/3; 30/36] END C=0.05, gamma=3, kernel=linear;, score=0.848 total time=   0.0s\n",
      "[CV 3/3; 32/36] START C=0.1, gamma=1, kernel=linear.............................\n",
      "[CV 3/3; 32/36] END C=0.1, gamma=1, kernel=linear;, score=0.875 total time=   0.0s\n",
      "[CV 3/3; 1/36] START C=0.001, gamma=1, kernel=rbf...............................\n",
      "[CV 3/3; 1/36] END C=0.001, gamma=1, kernel=rbf;, score=0.727 total time=   0.0s\n",
      "[CV 1/3; 4/36] START C=0.001, gamma=2, kernel=linear............................\n",
      "[CV 1/3; 4/36] END C=0.001, gamma=2, kernel=linear;, score=0.859 total time=   0.0s\n",
      "[CV 1/3; 7/36] START C=0.005, gamma=1, kernel=rbf...............................\n",
      "[CV 1/3; 7/36] END C=0.005, gamma=1, kernel=rbf;, score=0.881 total time=   0.0s\n",
      "[CV 2/3; 7/36] START C=0.005, gamma=1, kernel=rbf...............................\n",
      "[CV 2/3; 7/36] END C=0.005, gamma=1, kernel=rbf;, score=0.574 total time=   0.0s\n",
      "[CV 1/3; 13/36] START C=0.01, gamma=1, kernel=rbf...............................\n",
      "[CV 1/3; 13/36] END C=0.01, gamma=1, kernel=rbf;, score=0.881 total time=   0.0s\n",
      "[CV 2/3; 13/36] START C=0.01, gamma=1, kernel=rbf...............................\n",
      "[CV 2/3; 13/36] END C=0.01, gamma=1, kernel=rbf;, score=0.682 total time=   0.0s\n",
      "[CV 2/3; 18/36] START C=0.01, gamma=3, kernel=linear............................\n",
      "[CV 2/3; 18/36] END C=0.01, gamma=3, kernel=linear;, score=0.888 total time=   0.0s\n",
      "[CV 3/3; 18/36] START C=0.01, gamma=3, kernel=linear............................\n",
      "[CV 3/3; 18/36] END C=0.01, gamma=3, kernel=linear;, score=0.647 total time=   0.0s\n",
      "[CV 1/3; 19/36] START C=0.02, gamma=1, kernel=rbf...............................\n",
      "[CV 1/3; 19/36] END C=0.02, gamma=1, kernel=rbf;, score=0.881 total time=   0.0s\n",
      "[CV 2/3; 19/36] START C=0.02, gamma=1, kernel=rbf...............................\n",
      "[CV 2/3; 19/36] END C=0.02, gamma=1, kernel=rbf;, score=0.768 total time=   0.0s\n",
      "[CV 1/3; 28/36] START C=0.05, gamma=2, kernel=linear............................\n",
      "[CV 1/3; 28/36] END C=0.05, gamma=2, kernel=linear;, score=0.864 total time=   0.0s\n",
      "[CV 1/3; 33/36] START C=0.1, gamma=2, kernel=rbf................................\n",
      "[CV 1/3; 33/36] END .C=0.1, gamma=2, kernel=rbf;, score=0.894 total time=   0.0s\n",
      "[CV 2/3; 35/36] START C=0.1, gamma=3, kernel=rbf................................\n",
      "[CV 2/3; 35/36] END .C=0.1, gamma=3, kernel=rbf;, score=0.635 total time=   0.0s\n",
      "[CV 1/3; 2/36] START C=0.001, gamma=1, kernel=linear............................\n",
      "[CV 1/3; 2/36] END C=0.001, gamma=1, kernel=linear;, score=0.893 total time=   0.0s\n",
      "[CV 2/3; 4/36] START C=0.001, gamma=2, kernel=linear............................\n",
      "[CV 2/3; 4/36] END C=0.001, gamma=2, kernel=linear;, score=0.853 total time=   0.0s\n",
      "[CV 1/3; 9/36] START C=0.005, gamma=2, kernel=rbf...............................\n",
      "[CV 1/3; 9/36] END C=0.005, gamma=2, kernel=rbf;, score=0.785 total time=   0.0s\n",
      "[CV 2/3; 9/36] START C=0.005, gamma=2, kernel=rbf...............................\n",
      "[CV 2/3; 9/36] END C=0.005, gamma=2, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 3/3; 13/36] START C=0.01, gamma=1, kernel=rbf...............................\n",
      "[CV 3/3; 13/36] END C=0.01, gamma=1, kernel=rbf;, score=0.505 total time=   0.0s\n",
      "[CV 1/3; 14/36] START C=0.01, gamma=1, kernel=linear............................\n",
      "[CV 1/3; 14/36] END C=0.01, gamma=1, kernel=linear;, score=0.812 total time=   0.0s\n",
      "[CV 2/3; 22/36] START C=0.02, gamma=2, kernel=linear............................\n",
      "[CV 2/3; 22/36] END C=0.02, gamma=2, kernel=linear;, score=0.850 total time=   0.0s\n",
      "[CV 3/3; 22/36] START C=0.02, gamma=2, kernel=linear............................\n",
      "[CV 3/3; 22/36] END C=0.02, gamma=2, kernel=linear;, score=0.677 total time=   0.0s\n",
      "[CV 1/3; 23/36] START C=0.02, gamma=3, kernel=rbf...............................\n",
      "[CV 1/3; 23/36] END C=0.02, gamma=3, kernel=rbf;, score=0.848 total time=   0.0s\n",
      "[CV 2/3; 23/36] START C=0.02, gamma=3, kernel=rbf...............................\n",
      "[CV 2/3; 23/36] END C=0.02, gamma=3, kernel=rbf;, score=0.791 total time=   0.0s\n",
      "[CV 3/3; 31/36] START C=0.1, gamma=1, kernel=rbf................................\n",
      "[CV 3/3; 31/36] END .C=0.1, gamma=1, kernel=rbf;, score=0.626 total time=   0.0s\n",
      "[CV 1/3; 35/36] START C=0.1, gamma=3, kernel=rbf................................\n",
      "[CV 1/3; 35/36] END .C=0.1, gamma=3, kernel=rbf;, score=0.911 total time=   0.0s\n",
      "[CV 3/3; 1/36] START C=0.001, gamma=1, kernel=rbf...............................\n",
      "[CV 3/3; 1/36] END C=0.001, gamma=1, kernel=rbf;, score=0.357 total time=   0.0s\n",
      "[CV 2/3; 4/36] START C=0.001, gamma=2, kernel=linear............................\n",
      "[CV 2/3; 4/36] END C=0.001, gamma=2, kernel=linear;, score=0.629 total time=   0.0s\n",
      "[CV 3/3; 7/36] START C=0.005, gamma=1, kernel=rbf...............................\n",
      "[CV 3/3; 7/36] END C=0.005, gamma=1, kernel=rbf;, score=0.827 total time=   0.0s\n",
      "[CV 1/3; 8/36] START C=0.005, gamma=1, kernel=linear............................\n",
      "[CV 1/3; 8/36] END C=0.005, gamma=1, kernel=linear;, score=0.834 total time=   0.0s\n",
      "[CV 1/3; 13/36] START C=0.01, gamma=1, kernel=rbf...............................\n",
      "[CV 1/3; 13/36] END C=0.01, gamma=1, kernel=rbf;, score=0.747 total time=   0.0s\n",
      "[CV 2/3; 13/36] START C=0.01, gamma=1, kernel=rbf...............................\n",
      "[CV 2/3; 13/36] END C=0.01, gamma=1, kernel=rbf;, score=0.764 total time=   0.0s\n",
      "[CV 1/3; 21/36] START C=0.02, gamma=2, kernel=rbf...............................\n",
      "[CV 1/3; 21/36] END C=0.02, gamma=2, kernel=rbf;, score=0.809 total time=   0.0s\n",
      "[CV 2/3; 21/36] START C=0.02, gamma=2, kernel=rbf...............................\n",
      "[CV 2/3; 21/36] END C=0.02, gamma=2, kernel=rbf;, score=0.829 total time=   0.0s\n",
      "[CV 3/3; 21/36] START C=0.02, gamma=2, kernel=rbf...............................\n",
      "[CV 3/3; 21/36] END C=0.02, gamma=2, kernel=rbf;, score=0.847 total time=   0.0s\n",
      "[CV 1/3; 22/36] START C=0.02, gamma=2, kernel=linear............................\n",
      "[CV 1/3; 22/36] END C=0.02, gamma=2, kernel=linear;, score=0.717 total time=   0.0s\n",
      "[CV 1/3; 1/36] START C=0.001, gamma=1, kernel=rbf...............................\n",
      "[CV 1/3; 1/36] END C=0.001, gamma=1, kernel=rbf;, score=0.664 total time=   0.0s\n",
      "[CV 2/3; 13/36] START C=0.01, gamma=1, kernel=rbf...............................\n",
      "[CV 2/3; 13/36] END C=0.01, gamma=1, kernel=rbf;, score=0.844 total time=   0.0s\n",
      "[CV 2/3; 15/36] START C=0.01, gamma=2, kernel=rbf...............................\n",
      "[CV 2/3; 15/36] END C=0.01, gamma=2, kernel=rbf;, score=0.870 total time=   0.0s\n",
      "[CV 3/3; 17/36] START C=0.01, gamma=3, kernel=rbf...............................\n",
      "[CV 3/3; 17/36] END C=0.01, gamma=3, kernel=rbf;, score=0.651 total time=   0.0s\n",
      "[CV 1/3; 18/36] START C=0.01, gamma=3, kernel=linear............................\n",
      "[CV 1/3; 18/36] END C=0.01, gamma=3, kernel=linear;, score=0.677 total time=   0.0s\n",
      "[CV 3/3; 21/36] START C=0.02, gamma=2, kernel=rbf...............................\n",
      "[CV 3/3; 21/36] END C=0.02, gamma=2, kernel=rbf;, score=0.586 total time=   0.0s\n",
      "[CV 1/3; 22/36] START C=0.02, gamma=2, kernel=linear............................\n",
      "[CV 1/3; 22/36] END C=0.02, gamma=2, kernel=linear;, score=0.677 total time=   0.0s\n",
      "[CV 3/3; 25/36] START C=0.05, gamma=1, kernel=rbf...............................\n",
      "[CV 3/3; 25/36] END C=0.05, gamma=1, kernel=rbf;, score=0.626 total time=   0.0s\n",
      "[CV 1/3; 26/36] START C=0.05, gamma=1, kernel=linear............................\n",
      "[CV 1/3; 26/36] END C=0.05, gamma=1, kernel=linear;, score=0.675 total time=   0.0s\n",
      "[CV 3/3; 29/36] START C=0.05, gamma=3, kernel=rbf...............................\n",
      "[CV 3/3; 29/36] END C=0.05, gamma=3, kernel=rbf;, score=0.741 total time=   0.0s\n",
      "[CV 2/3; 32/36] START C=0.1, gamma=1, kernel=linear.............................\n",
      "[CV 2/3; 32/36] END C=0.1, gamma=1, kernel=linear;, score=0.894 total time=   0.0s\n",
      "[CV 1/3; 35/36] START C=0.1, gamma=3, kernel=rbf................................\n",
      "[CV 1/3; 35/36] END .C=0.1, gamma=3, kernel=rbf;, score=0.858 total time=   0.0s\n",
      "[CV 2/3; 1/36] START C=0.001, gamma=1, kernel=rbf...............................\n",
      "[CV 2/3; 1/36] END C=0.001, gamma=1, kernel=rbf;, score=0.674 total time=   0.0s\n",
      "[CV 3/3; 3/36] START C=0.001, gamma=2, kernel=rbf...............................\n",
      "[CV 3/3; 3/36] END C=0.001, gamma=2, kernel=rbf;, score=0.804 total time=   0.0s\n",
      "[CV 2/3; 6/36] START C=0.001, gamma=3, kernel=linear............................\n",
      "[CV 2/3; 6/36] END C=0.001, gamma=3, kernel=linear;, score=0.904 total time=   0.0s\n",
      "[CV 3/3; 6/36] START C=0.001, gamma=3, kernel=linear............................\n",
      "[CV 3/3; 6/36] END C=0.001, gamma=3, kernel=linear;, score=0.653 total time=   0.0s\n",
      "[CV 2/3; 12/36] START C=0.005, gamma=3, kernel=linear...........................\n",
      "[CV 2/3; 12/36] END C=0.005, gamma=3, kernel=linear;, score=0.888 total time=   0.0s\n",
      "[CV 3/3; 12/36] START C=0.005, gamma=3, kernel=linear...........................\n",
      "[CV 3/3; 12/36] END C=0.005, gamma=3, kernel=linear;, score=0.832 total time=   0.0s\n",
      "[CV 1/3; 21/36] START C=0.02, gamma=2, kernel=rbf...............................\n",
      "[CV 1/3; 21/36] END C=0.02, gamma=2, kernel=rbf;, score=0.888 total time=   0.0s\n",
      "[CV 2/3; 21/36] START C=0.02, gamma=2, kernel=rbf...............................\n",
      "[CV 2/3; 21/36] END C=0.02, gamma=2, kernel=rbf;, score=0.840 total time=   0.0s\n",
      "[CV 3/3; 21/36] START C=0.02, gamma=2, kernel=rbf...............................\n",
      "[CV 3/3; 21/36] END C=0.02, gamma=2, kernel=rbf;, score=0.728 total time=   0.0s\n",
      "[CV 1/3; 22/36] START C=0.02, gamma=2, kernel=linear............................\n",
      "[CV 1/3; 22/36] END C=0.02, gamma=2, kernel=linear;, score=0.853 total time=   0.0s\n",
      "[CV 1/3; 29/36] START C=0.05, gamma=3, kernel=rbf...............................\n",
      "[CV 1/3; 29/36] END C=0.05, gamma=3, kernel=rbf;, score=0.877 total time=   0.0s\n",
      "[CV 1/3; 31/36] START C=0.1, gamma=1, kernel=rbf................................\n",
      "[CV 1/3; 31/36] END .C=0.1, gamma=1, kernel=rbf;, score=0.881 total time=   0.0s\n",
      "[CV 3/3; 33/36] START C=0.1, gamma=2, kernel=rbf................................\n",
      "[CV 3/3; 33/36] END .C=0.1, gamma=2, kernel=rbf;, score=0.860 total time=   0.0s\n",
      "[CV 1/3; 36/36] START C=0.1, gamma=3, kernel=linear.............................\n",
      "[CV 1/3; 36/36] END C=0.1, gamma=3, kernel=linear;, score=0.879 total time=   0.0s\n",
      "[CV 3/3; 2/36] START C=0.001, gamma=1, kernel=linear............................\n",
      "[CV 3/3; 2/36] END C=0.001, gamma=1, kernel=linear;, score=0.714 total time=   0.0s\n",
      "[CV 1/3; 5/36] START C=0.001, gamma=3, kernel=rbf...............................\n",
      "[CV 1/3; 5/36] END C=0.001, gamma=3, kernel=rbf;, score=0.554 total time=   0.0s\n",
      "[CV 3/3; 9/36] START C=0.005, gamma=2, kernel=rbf...............................\n",
      "[CV 3/3; 9/36] END C=0.005, gamma=2, kernel=rbf;, score=0.736 total time=   0.0s\n",
      "[CV 1/3; 10/36] START C=0.005, gamma=2, kernel=linear...........................\n",
      "[CV 1/3; 10/36] END C=0.005, gamma=2, kernel=linear;, score=0.698 total time=   0.0s\n",
      "[CV 1/3; 15/36] START C=0.01, gamma=2, kernel=rbf...............................\n",
      "[CV 1/3; 15/36] END C=0.01, gamma=2, kernel=rbf;, score=0.785 total time=   0.0s\n",
      "[CV 2/3; 15/36] START C=0.01, gamma=2, kernel=rbf...............................\n",
      "[CV 2/3; 15/36] END C=0.01, gamma=2, kernel=rbf;, score=0.810 total time=   0.0s\n",
      "[CV 2/3; 26/36] START C=0.05, gamma=1, kernel=linear............................\n",
      "[CV 2/3; 26/36] END C=0.05, gamma=1, kernel=linear;, score=0.853 total time=   0.0s\n",
      "[CV 3/3; 26/36] START C=0.05, gamma=1, kernel=linear............................\n",
      "[CV 3/3; 26/36] END C=0.05, gamma=1, kernel=linear;, score=0.673 total time=   0.0s\n",
      "[CV 1/3; 27/36] START C=0.05, gamma=2, kernel=rbf...............................\n",
      "[CV 1/3; 27/36] END C=0.05, gamma=2, kernel=rbf;, score=0.737 total time=   0.0s\n",
      "[CV 2/3; 27/36] START C=0.05, gamma=2, kernel=rbf...............................\n",
      "[CV 2/3; 27/36] END C=0.05, gamma=2, kernel=rbf;, score=0.788 total time=   0.0s\n",
      "[CV 3/3; 30/36] START C=0.05, gamma=3, kernel=linear............................\n",
      "[CV 3/3; 30/36] END C=0.05, gamma=3, kernel=linear;, score=0.673 total time=   0.0s\n",
      "[CV 1/3; 33/36] START C=0.1, gamma=2, kernel=rbf................................\n",
      "[CV 1/3; 33/36] END .C=0.1, gamma=2, kernel=rbf;, score=0.821 total time=   0.0s\n",
      "[CV 3/3; 35/36] START C=0.1, gamma=3, kernel=rbf................................\n",
      "[CV 3/3; 35/36] END .C=0.1, gamma=3, kernel=rbf;, score=0.806 total time=   0.0s\n",
      "[CV 2/3; 2/36] START C=0.001, gamma=1, kernel=linear............................\n",
      "[CV 2/3; 2/36] END C=0.001, gamma=1, kernel=linear;, score=0.629 total time=   0.0s\n",
      "[CV 1/3; 5/36] START C=0.001, gamma=3, kernel=rbf...............................\n",
      "[CV 1/3; 5/36] END C=0.001, gamma=3, kernel=rbf;, score=0.668 total time=   0.0s\n",
      "[CV 1/3; 9/36] START C=0.005, gamma=2, kernel=rbf...............................\n",
      "[CV 1/3; 9/36] END C=0.005, gamma=2, kernel=rbf;, score=0.586 total time=   0.0s\n",
      "[CV 2/3; 9/36] START C=0.005, gamma=2, kernel=rbf...............................\n",
      "[CV 2/3; 9/36] END C=0.005, gamma=2, kernel=rbf;, score=0.764 total time=   0.0s\n",
      "[CV 2/3; 14/36] START C=0.01, gamma=1, kernel=linear............................\n",
      "[CV 2/3; 14/36] END C=0.01, gamma=1, kernel=linear;, score=0.577 total time=   0.0s\n",
      "[CV 3/3; 14/36] START C=0.01, gamma=1, kernel=linear............................\n",
      "[CV 3/3; 14/36] END C=0.01, gamma=1, kernel=linear;, score=0.663 total time=   0.0s\n",
      "[CV 2/3; 22/36] START C=0.02, gamma=2, kernel=linear............................\n",
      "[CV 2/3; 22/36] END C=0.02, gamma=2, kernel=linear;, score=0.578 total time=   0.0s\n",
      "[CV 3/3; 22/36] START C=0.02, gamma=2, kernel=linear............................\n",
      "[CV 3/3; 22/36] END C=0.02, gamma=2, kernel=linear;, score=0.752 total time=   0.0s\n",
      "[CV 1/3; 23/36] START C=0.02, gamma=3, kernel=rbf...............................\n",
      "[CV 1/3; 23/36] END C=0.02, gamma=3, kernel=rbf;, score=0.796 total time=   0.0s\n",
      "[CV 2/3; 23/36] START C=0.02, gamma=3, kernel=rbf...............................\n",
      "[CV 2/3; 23/36] END C=0.02, gamma=3, kernel=rbf;, score=0.803 total time=   0.0s\n",
      "[CV 3/3; 28/36] START C=0.05, gamma=2, kernel=linear............................\n",
      "[CV 3/3; 28/36] END C=0.05, gamma=2, kernel=linear;, score=0.719 total time=   0.0s\n",
      "[CV 3/3; 2/36] START C=0.001, gamma=1, kernel=linear............................\n",
      "[CV 3/3; 2/36] END C=0.001, gamma=1, kernel=linear;, score=0.903 total time=   0.0s\n",
      "[CV 3/3; 10/36] START C=0.005, gamma=2, kernel=linear...........................\n",
      "[CV 3/3; 10/36] END C=0.005, gamma=2, kernel=linear;, score=0.854 total time=   0.0s\n",
      "[CV 2/3; 12/36] START C=0.005, gamma=3, kernel=linear...........................\n",
      "[CV 2/3; 12/36] END C=0.005, gamma=3, kernel=linear;, score=0.895 total time=   0.0s\n",
      "[CV 3/3; 14/36] START C=0.01, gamma=1, kernel=linear............................\n",
      "[CV 3/3; 14/36] END C=0.01, gamma=1, kernel=linear;, score=0.881 total time=   0.0s\n",
      "[CV 2/3; 16/36] START C=0.01, gamma=2, kernel=linear............................\n",
      "[CV 2/3; 16/36] END C=0.01, gamma=2, kernel=linear;, score=0.890 total time=   0.0s\n",
      "[CV 3/3; 19/36] START C=0.02, gamma=1, kernel=rbf...............................\n",
      "[CV 3/3; 19/36] END C=0.02, gamma=1, kernel=rbf;, score=0.758 total time=   0.0s\n",
      "[CV 1/3; 20/36] START C=0.02, gamma=1, kernel=linear............................\n",
      "[CV 1/3; 20/36] END C=0.02, gamma=1, kernel=linear;, score=0.677 total time=   0.0s\n",
      "[CV 3/3; 23/36] START C=0.02, gamma=3, kernel=rbf...............................\n",
      "[CV 3/3; 23/36] END C=0.02, gamma=3, kernel=rbf;, score=0.903 total time=   0.0s\n",
      "[CV 1/3; 24/36] START C=0.02, gamma=3, kernel=linear............................\n",
      "[CV 1/3; 24/36] END C=0.02, gamma=3, kernel=linear;, score=0.677 total time=   0.0s\n",
      "[CV 2/3; 28/36] START C=0.05, gamma=2, kernel=linear............................\n",
      "[CV 2/3; 28/36] END C=0.05, gamma=2, kernel=linear;, score=0.895 total time=   0.0s\n",
      "[CV 1/3; 32/36] START C=0.1, gamma=1, kernel=linear.............................\n",
      "[CV 1/3; 32/36] END C=0.1, gamma=1, kernel=linear;, score=0.675 total time=   0.0s\n",
      "[CV 3/3; 34/36] START C=0.1, gamma=2, kernel=linear.............................\n",
      "[CV 3/3; 34/36] END C=0.1, gamma=2, kernel=linear;, score=0.875 total time=   0.0s\n",
      "[CV 1/3; 1/36] START C=0.001, gamma=1, kernel=rbf...............................\n",
      "[CV 1/3; 1/36] END C=0.001, gamma=1, kernel=rbf;, score=0.877 total time=   0.0s\n",
      "[CV 2/3; 3/36] START C=0.001, gamma=2, kernel=rbf...............................\n",
      "[CV 2/3; 3/36] END C=0.001, gamma=2, kernel=rbf;, score=0.851 total time=   0.0s\n",
      "[CV 1/3; 6/36] START C=0.001, gamma=3, kernel=linear............................\n",
      "[CV 1/3; 6/36] END C=0.001, gamma=3, kernel=linear;, score=0.859 total time=   0.0s\n",
      "[CV 2/3; 10/36] START C=0.005, gamma=2, kernel=linear...........................\n",
      "[CV 2/3; 10/36] END C=0.005, gamma=2, kernel=linear;, score=0.888 total time=   0.0s\n",
      "[CV 3/3; 10/36] START C=0.005, gamma=2, kernel=linear...........................\n",
      "[CV 3/3; 10/36] END C=0.005, gamma=2, kernel=linear;, score=0.832 total time=   0.0s\n",
      "[CV 3/3; 15/36] START C=0.01, gamma=2, kernel=rbf...............................\n",
      "[CV 3/3; 15/36] END C=0.01, gamma=2, kernel=rbf;, score=0.776 total time=   0.0s\n",
      "[CV 1/3; 16/36] START C=0.01, gamma=2, kernel=linear............................\n",
      "[CV 1/3; 16/36] END C=0.01, gamma=2, kernel=linear;, score=0.864 total time=   0.0s\n",
      "[CV 1/3; 25/36] START C=0.05, gamma=1, kernel=rbf...............................\n",
      "[CV 1/3; 25/36] END C=0.05, gamma=1, kernel=rbf;, score=0.881 total time=   0.0s\n",
      "[CV 2/3; 25/36] START C=0.05, gamma=1, kernel=rbf...............................\n",
      "[CV 2/3; 25/36] END C=0.05, gamma=1, kernel=rbf;, score=0.874 total time=   0.0s\n",
      "[CV 3/3; 25/36] START C=0.05, gamma=1, kernel=rbf...............................\n",
      "[CV 3/3; 25/36] END C=0.05, gamma=1, kernel=rbf;, score=0.847 total time=   0.0s\n",
      "[CV 1/3; 26/36] START C=0.05, gamma=1, kernel=linear............................\n",
      "[CV 1/3; 26/36] END C=0.05, gamma=1, kernel=linear;, score=0.864 total time=   0.0s\n",
      "[CV 2/3; 30/36] START C=0.05, gamma=3, kernel=linear............................\n",
      "[CV 2/3; 30/36] END C=0.05, gamma=3, kernel=linear;, score=0.888 total time=   0.0s\n",
      "[CV 2/3; 33/36] START C=0.1, gamma=2, kernel=rbf................................\n",
      "[CV 2/3; 33/36] END .C=0.1, gamma=2, kernel=rbf;, score=0.887 total time=   0.0s\n",
      "[CV 3/3; 35/36] START C=0.1, gamma=3, kernel=rbf................................\n",
      "[CV 3/3; 35/36] END .C=0.1, gamma=3, kernel=rbf;, score=0.866 total time=   0.0s\n",
      "[CV 2/3; 2/36] START C=0.001, gamma=1, kernel=linear............................\n",
      "[CV 2/3; 2/36] END C=0.001, gamma=1, kernel=linear;, score=0.853 total time=   0.0s\n",
      "[CV 2/3; 5/36] START C=0.001, gamma=3, kernel=rbf...............................\n",
      "[CV 2/3; 5/36] END C=0.001, gamma=3, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 2/3; 10/36] START C=0.005, gamma=2, kernel=linear...........................\n",
      "[CV 2/3; 10/36] END C=0.005, gamma=2, kernel=linear;, score=0.853 total time=   0.0s\n",
      "[CV 3/3; 10/36] START C=0.005, gamma=2, kernel=linear...........................\n",
      "[CV 3/3; 10/36] END C=0.005, gamma=2, kernel=linear;, score=0.709 total time=   0.0s\n",
      "[CV 2/3; 18/36] START C=0.01, gamma=3, kernel=linear............................\n",
      "[CV 2/3; 18/36] END C=0.01, gamma=3, kernel=linear;, score=0.852 total time=   0.0s\n",
      "[CV 3/3; 18/36] START C=0.01, gamma=3, kernel=linear............................\n",
      "[CV 3/3; 18/36] END C=0.01, gamma=3, kernel=linear;, score=0.675 total time=   0.0s\n",
      "[CV 1/3; 19/36] START C=0.02, gamma=1, kernel=rbf...............................\n",
      "[CV 1/3; 19/36] END C=0.02, gamma=1, kernel=rbf;, score=0.893 total time=   0.0s\n",
      "[CV 2/3; 19/36] START C=0.02, gamma=1, kernel=rbf...............................\n",
      "[CV 2/3; 19/36] END C=0.02, gamma=1, kernel=rbf;, score=0.755 total time=   0.0s\n",
      "[CV 1/3; 28/36] START C=0.05, gamma=2, kernel=linear............................\n",
      "[CV 1/3; 28/36] END C=0.05, gamma=2, kernel=linear;, score=0.920 total time=   0.0s\n",
      "[CV 1/3; 31/36] START C=0.1, gamma=1, kernel=rbf................................\n",
      "[CV 1/3; 31/36] END .C=0.1, gamma=1, kernel=rbf;, score=0.922 total time=   0.0s\n",
      "[CV 2/3; 33/36] START C=0.1, gamma=2, kernel=rbf................................\n",
      "[CV 2/3; 33/36] END .C=0.1, gamma=2, kernel=rbf;, score=0.789 total time=   0.0s\n",
      "[CV 2/3; 35/36] START C=0.1, gamma=3, kernel=rbf................................\n",
      "[CV 2/3; 35/36] END .C=0.1, gamma=3, kernel=rbf;, score=0.780 total time=   0.0s\n",
      "[CV 1/3; 2/36] START C=0.001, gamma=1, kernel=linear............................\n",
      "[CV 1/3; 2/36] END C=0.001, gamma=1, kernel=linear;, score=0.622 total time=   0.0s\n",
      "[CV 3/3; 4/36] START C=0.001, gamma=2, kernel=linear............................\n",
      "[CV 3/3; 4/36] END C=0.001, gamma=2, kernel=linear;, score=0.913 total time=   0.0s\n",
      "[CV 2/3; 8/36] START C=0.005, gamma=1, kernel=linear............................\n",
      "[CV 2/3; 8/36] END C=0.005, gamma=1, kernel=linear;, score=0.590 total time=   0.0s\n",
      "[CV 3/3; 8/36] START C=0.005, gamma=1, kernel=linear............................\n",
      "[CV 3/3; 8/36] END C=0.005, gamma=1, kernel=linear;, score=0.893 total time=   0.0s\n",
      "[CV 3/3; 13/36] START C=0.01, gamma=1, kernel=rbf...............................\n",
      "[CV 3/3; 13/36] END C=0.01, gamma=1, kernel=rbf;, score=0.827 total time=   0.0s\n",
      "[CV 1/3; 14/36] START C=0.01, gamma=1, kernel=linear............................\n",
      "[CV 1/3; 14/36] END C=0.01, gamma=1, kernel=linear;, score=0.729 total time=   0.0s\n",
      "[CV 3/3; 19/36] START C=0.02, gamma=1, kernel=rbf...............................\n",
      "[CV 3/3; 19/36] END C=0.02, gamma=1, kernel=rbf;, score=0.847 total time=   0.0s\n",
      "[CV 1/3; 20/36] START C=0.02, gamma=1, kernel=linear............................\n",
      "[CV 1/3; 20/36] END C=0.02, gamma=1, kernel=linear;, score=0.717 total time=   0.0s\n",
      "[CV 2/3; 20/36] START C=0.02, gamma=1, kernel=linear............................\n",
      "[CV 2/3; 20/36] END C=0.02, gamma=1, kernel=linear;, score=0.578 total time=   0.0s\n",
      "[CV 3/3; 20/36] START C=0.02, gamma=1, kernel=linear............................\n",
      "[CV 3/3; 20/36] END C=0.02, gamma=1, kernel=linear;, score=0.752 total time=   0.0s\n",
      "[CV 2/3; 28/36] START C=0.05, gamma=2, kernel=linear............................\n",
      "[CV 2/3; 28/36] END C=0.05, gamma=2, kernel=linear;, score=0.561 total time=   0.0s\n",
      "[CV 1/3; 30/36] START C=0.05, gamma=3, kernel=linear............................\n",
      "[CV 3/3; 1/36] START C=0.001, gamma=1, kernel=rbf...............................\n",
      "[CV 3/3; 1/36] END C=0.001, gamma=1, kernel=rbf;, score=0.886 total time=   0.0s\n",
      "[CV 1/3; 10/36] START C=0.005, gamma=2, kernel=linear...........................\n",
      "[CV 1/3; 10/36] END C=0.005, gamma=2, kernel=linear;, score=0.677 total time=   0.0s\n",
      "[CV 3/3; 11/36] START C=0.005, gamma=3, kernel=rbf..............................\n",
      "[CV 3/3; 11/36] END C=0.005, gamma=3, kernel=rbf;, score=0.626 total time=   0.0s\n",
      "[CV 1/3; 14/36] START C=0.01, gamma=1, kernel=linear............................\n",
      "[CV 1/3; 14/36] END C=0.01, gamma=1, kernel=linear;, score=0.677 total time=   0.0s\n",
      "[CV 1/3; 16/36] START C=0.01, gamma=2, kernel=linear............................\n",
      "[CV 1/3; 16/36] END C=0.01, gamma=2, kernel=linear;, score=0.677 total time=   0.0s\n",
      "[CV 1/3; 19/36] START C=0.02, gamma=1, kernel=rbf...............................\n",
      "[CV 1/3; 19/36] END C=0.02, gamma=1, kernel=rbf;, score=0.846 total time=   0.0s\n",
      "[CV 2/3; 19/36] START C=0.02, gamma=1, kernel=rbf...............................\n",
      "[CV 2/3; 19/36] END C=0.02, gamma=1, kernel=rbf;, score=0.808 total time=   0.0s\n",
      "[CV 2/3; 26/36] START C=0.05, gamma=1, kernel=linear............................\n",
      "[CV 2/3; 26/36] END C=0.05, gamma=1, kernel=linear;, score=0.895 total time=   0.0s\n",
      "[CV 3/3; 26/36] START C=0.05, gamma=1, kernel=linear............................\n",
      "[CV 3/3; 26/36] END C=0.05, gamma=1, kernel=linear;, score=0.848 total time=   0.0s\n",
      "[CV 2/3; 30/36] START C=0.05, gamma=3, kernel=linear............................\n",
      "[CV 2/3; 30/36] END C=0.05, gamma=3, kernel=linear;, score=0.895 total time=   0.0s\n",
      "[CV 1/3; 33/36] START C=0.1, gamma=2, kernel=rbf................................\n",
      "[CV 1/3; 33/36] END .C=0.1, gamma=2, kernel=rbf;, score=0.768 total time=   0.0s\n",
      "[CV 2/3; 35/36] START C=0.1, gamma=3, kernel=rbf................................\n",
      "[CV 2/3; 35/36] END .C=0.1, gamma=3, kernel=rbf;, score=0.841 total time=   0.0s\n",
      "[CV 2/3; 2/36] START C=0.001, gamma=1, kernel=linear............................\n",
      "[CV 2/3; 2/36] END C=0.001, gamma=1, kernel=linear;, score=0.904 total time=   0.0s\n",
      "[CV 1/3; 5/36] START C=0.001, gamma=3, kernel=rbf...............................\n",
      "[CV 1/3; 5/36] END C=0.001, gamma=3, kernel=rbf;, score=0.863 total time=   0.0s\n",
      "[CV 2/3; 8/36] START C=0.005, gamma=1, kernel=linear............................\n",
      "[CV 2/3; 8/36] END C=0.005, gamma=1, kernel=linear;, score=0.888 total time=   0.0s\n",
      "[CV 3/3; 8/36] START C=0.005, gamma=1, kernel=linear............................\n",
      "[CV 3/3; 8/36] END C=0.005, gamma=1, kernel=linear;, score=0.832 total time=   0.0s\n",
      "[CV 3/3; 13/36] START C=0.01, gamma=1, kernel=rbf...............................\n",
      "[CV 3/3; 13/36] END C=0.01, gamma=1, kernel=rbf;, score=0.681 total time=   0.0s\n",
      "[CV 1/3; 14/36] START C=0.01, gamma=1, kernel=linear............................\n",
      "[CV 1/3; 14/36] END C=0.01, gamma=1, kernel=linear;, score=0.864 total time=   0.0s\n",
      "[CV 3/3; 19/36] START C=0.02, gamma=1, kernel=rbf...............................\n",
      "[CV 3/3; 19/36] END C=0.02, gamma=1, kernel=rbf;, score=0.886 total time=   0.0s\n",
      "[CV 1/3; 20/36] START C=0.02, gamma=1, kernel=linear............................\n",
      "[CV 1/3; 20/36] END C=0.02, gamma=1, kernel=linear;, score=0.853 total time=   0.0s\n",
      "[CV 2/3; 20/36] START C=0.02, gamma=1, kernel=linear............................\n",
      "[CV 2/3; 20/36] END C=0.02, gamma=1, kernel=linear;, score=0.887 total time=   0.0s\n",
      "[CV 3/3; 20/36] START C=0.02, gamma=1, kernel=linear............................\n",
      "[CV 3/3; 20/36] END C=0.02, gamma=1, kernel=linear;, score=0.840 total time=   0.0s\n",
      "[CV 2/3; 28/36] START C=0.05, gamma=2, kernel=linear............................\n",
      "[CV 2/3; 28/36] END C=0.05, gamma=2, kernel=linear;, score=0.888 total time=   0.0s\n",
      "[CV 3/3; 30/36] START C=0.05, gamma=3, kernel=linear............................\n",
      "[CV 3/3; 30/36] END C=0.05, gamma=3, kernel=linear;, score=0.685 total time=   0.0s\n",
      "[CV 3/3; 32/36] START C=0.1, gamma=1, kernel=linear.............................\n",
      "[CV 3/3; 32/36] END C=0.1, gamma=1, kernel=linear;, score=0.841 total time=   0.0s\n",
      "[CV 1/3; 35/36] START C=0.1, gamma=3, kernel=rbf................................\n",
      "[CV 1/3; 35/36] END .C=0.1, gamma=3, kernel=rbf;, score=0.872 total time=   0.0s\n",
      "[CV 3/3; 1/36] START C=0.001, gamma=1, kernel=rbf...............................\n",
      "[CV 3/3; 1/36] END C=0.001, gamma=1, kernel=rbf;, score=0.505 total time=   0.0s\n",
      "[CV 1/3; 4/36] START C=0.001, gamma=2, kernel=linear............................\n",
      "[CV 1/3; 4/36] END C=0.001, gamma=2, kernel=linear;, score=0.893 total time=   0.0s\n",
      "[CV 1/3; 7/36] START C=0.005, gamma=1, kernel=rbf...............................\n",
      "[CV 1/3; 7/36] END C=0.005, gamma=1, kernel=rbf;, score=0.899 total time=   0.0s\n",
      "[CV 2/3; 7/36] START C=0.005, gamma=1, kernel=rbf...............................\n",
      "[CV 2/3; 7/36] END C=0.005, gamma=1, kernel=rbf;, score=0.810 total time=   0.0s\n",
      "[CV 2/3; 14/36] START C=0.01, gamma=1, kernel=linear............................\n",
      "[CV 2/3; 14/36] END C=0.01, gamma=1, kernel=linear;, score=0.852 total time=   0.0s\n",
      "[CV 3/3; 14/36] START C=0.01, gamma=1, kernel=linear............................\n",
      "[CV 3/3; 14/36] END C=0.01, gamma=1, kernel=linear;, score=0.675 total time=   0.0s\n",
      "[CV 1/3; 21/36] START C=0.02, gamma=2, kernel=rbf...............................\n",
      "[CV 1/3; 21/36] END C=0.02, gamma=2, kernel=rbf;, score=0.749 total time=   0.0s\n",
      "[CV 2/3; 21/36] START C=0.02, gamma=2, kernel=rbf...............................\n",
      "[CV 2/3; 21/36] END C=0.02, gamma=2, kernel=rbf;, score=0.810 total time=   0.0s\n",
      "[CV 3/3; 21/36] START C=0.02, gamma=2, kernel=rbf...............................\n",
      "[CV 3/3; 21/36] END C=0.02, gamma=2, kernel=rbf;, score=0.749 total time=   0.0s\n",
      "[CV 1/3; 22/36] START C=0.02, gamma=2, kernel=linear............................\n",
      "[CV 1/3; 22/36] END C=0.02, gamma=2, kernel=linear;, score=0.920 total time=   0.0s\n",
      "[CV 3/3; 28/36] START C=0.05, gamma=2, kernel=linear............................\n",
      "[CV 3/3; 28/36] END C=0.05, gamma=2, kernel=linear;, score=0.673 total time=   0.0s\n",
      "[CV 2/3; 30/36] START C=0.05, gamma=3, kernel=linear............................\n",
      "[CV 2/3; 30/36] END C=0.05, gamma=3, kernel=linear;, score=0.853 total time=   0.0s\n",
      "[CV 3/3; 32/36] START C=0.1, gamma=1, kernel=linear.............................\n",
      "[CV 3/3; 32/36] END C=0.1, gamma=1, kernel=linear;, score=0.673 total time=   0.0s\n",
      "[CV 1/3; 36/36] START C=0.1, gamma=3, kernel=linear.............................\n",
      "[CV 1/3; 36/36] END C=0.1, gamma=3, kernel=linear;, score=0.673 total time=   0.0s\n",
      "[CV 3/3; 2/36] START C=0.001, gamma=1, kernel=linear............................\n",
      "[CV 3/3; 2/36] END C=0.001, gamma=1, kernel=linear;, score=0.913 total time=   0.0s\n",
      "[CV 2/3; 5/36] START C=0.001, gamma=3, kernel=rbf...............................\n",
      "[CV 2/3; 5/36] END C=0.001, gamma=3, kernel=rbf;, score=0.862 total time=   0.0s\n",
      "[CV 2/3; 10/36] START C=0.005, gamma=2, kernel=linear...........................\n",
      "[CV 2/3; 10/36] END C=0.005, gamma=2, kernel=linear;, score=0.590 total time=   0.0s\n",
      "[CV 3/3; 10/36] START C=0.005, gamma=2, kernel=linear...........................\n",
      "[CV 3/3; 10/36] END C=0.005, gamma=2, kernel=linear;, score=0.893 total time=   0.0s\n",
      "[CV 1/3; 17/36] START C=0.01, gamma=3, kernel=rbf...............................\n",
      "[CV 1/3; 17/36] END C=0.01, gamma=3, kernel=rbf;, score=0.766 total time=   0.0s\n",
      "[CV 2/3; 17/36] START C=0.01, gamma=3, kernel=rbf...............................\n",
      "[CV 2/3; 17/36] END C=0.01, gamma=3, kernel=rbf;, score=0.899 total time=   0.0s\n",
      "[CV 3/3; 17/36] START C=0.01, gamma=3, kernel=rbf...............................\n",
      "[CV 3/3; 17/36] END C=0.01, gamma=3, kernel=rbf;, score=0.969 total time=   0.0s\n",
      "[CV 1/3; 18/36] START C=0.01, gamma=3, kernel=linear............................\n",
      "[CV 1/3; 18/36] END C=0.01, gamma=3, kernel=linear;, score=0.729 total time=   0.0s\n",
      "[CV 1/3; 28/36] START C=0.05, gamma=2, kernel=linear............................\n",
      "[CV 1/3; 28/36] END C=0.05, gamma=2, kernel=linear;, score=0.715 total time=   0.0s\n",
      "[CV 3/3; 29/36] START C=0.05, gamma=3, kernel=rbf...............................\n",
      "[CV 3/3; 29/36] END C=0.05, gamma=3, kernel=rbf;, score=0.969 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comex/Desktop/python-envs/main-bio/lib/python3.9/site-packages/sklearn/model_selection/_search.py:306: UserWarning: The total space of parameters 36 is smaller than n_iter=50. Running 36 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "svc_model, svc_scores = train_svm(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC = 0.5\n",
      "ACCURACY = 0.8076923076923077\n",
      "F1 = 0.0\n"
     ]
    }
   ],
   "source": [
    "validation_classification(svc_model, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV 2/3; 3/36] START C=0.001, gamma=2, kernel=rbf...............................\n",
      "[CV 2/3; 3/36] END C=0.001, gamma=2, kernel=rbf;, score=0.841 total time=   0.0s\n",
      "[CV 3/3; 9/36] START C=0.005, gamma=2, kernel=rbf...............................\n",
      "[CV 3/3; 9/36] END C=0.005, gamma=2, kernel=rbf;, score=0.761 total time=   0.0s\n",
      "[CV 2/3; 11/36] START C=0.005, gamma=3, kernel=rbf..............................\n",
      "[CV 2/3; 11/36] END C=0.005, gamma=3, kernel=rbf;, score=0.844 total time=   0.0s\n",
      "[CV 1/3; 13/36] START C=0.01, gamma=1, kernel=rbf...............................\n",
      "[CV 1/3; 13/36] END C=0.01, gamma=1, kernel=rbf;, score=0.860 total time=   0.0s\n",
      "[CV 1/3; 15/36] START C=0.01, gamma=2, kernel=rbf...............................\n",
      "[CV 1/3; 15/36] END C=0.01, gamma=2, kernel=rbf;, score=0.863 total time=   0.0s\n",
      "[CV 1/3; 23/36] START C=0.02, gamma=3, kernel=rbf...............................\n",
      "[CV 1/3; 23/36] END C=0.02, gamma=3, kernel=rbf;, score=0.865 total time=   0.0s\n",
      "[CV 2/3; 23/36] START C=0.02, gamma=3, kernel=rbf...............................\n",
      "[CV 2/3; 23/36] END C=0.02, gamma=3, kernel=rbf;, score=0.826 total time=   0.0s\n",
      "[CV 1/3; 28/36] START C=0.05, gamma=2, kernel=linear............................\n",
      "[CV 1/3; 28/36] END C=0.05, gamma=2, kernel=linear;, score=0.675 total time=   0.0s\n",
      "[CV 1/3; 30/36] START C=0.05, gamma=3, kernel=linear............................\n",
      "[CV 1/3; 30/36] END C=0.05, gamma=3, kernel=linear;, score=0.675 total time=   0.0s\n",
      "[CV 2/3; 34/36] START C=0.1, gamma=2, kernel=linear.............................\n",
      "[CV 2/3; 34/36] END C=0.1, gamma=2, kernel=linear;, score=0.894 total time=   0.0s\n",
      "[CV 3/3; 36/36] START C=0.1, gamma=3, kernel=linear.............................\n",
      "[CV 3/3; 36/36] END C=0.1, gamma=3, kernel=linear;, score=0.875 total time=   0.0s\n",
      "[CV 3/3; 4/36] START C=0.001, gamma=2, kernel=linear............................\n",
      "[CV 3/3; 4/36] END C=0.001, gamma=2, kernel=linear;, score=0.653 total time=   0.0s\n",
      "[CV 3/3; 9/36] START C=0.005, gamma=2, kernel=rbf...............................\n",
      "[CV 3/3; 9/36] END C=0.005, gamma=2, kernel=rbf;, score=0.625 total time=   0.0s\n",
      "[CV 1/3; 10/36] START C=0.005, gamma=2, kernel=linear...........................\n",
      "[CV 1/3; 10/36] END C=0.005, gamma=2, kernel=linear;, score=0.859 total time=   0.0s\n",
      "[CV 1/3; 15/36] START C=0.01, gamma=2, kernel=rbf...............................\n",
      "[CV 1/3; 15/36] END C=0.01, gamma=2, kernel=rbf;, score=0.888 total time=   0.0s\n",
      "[CV 2/3; 15/36] START C=0.01, gamma=2, kernel=rbf...............................\n",
      "[CV 2/3; 15/36] END C=0.01, gamma=2, kernel=rbf;, score=0.787 total time=   0.0s\n",
      "[CV 3/3; 23/36] START C=0.02, gamma=3, kernel=rbf...............................\n",
      "[CV 3/3; 23/36] END C=0.02, gamma=3, kernel=rbf;, score=0.606 total time=   0.0s\n",
      "[CV 1/3; 24/36] START C=0.02, gamma=3, kernel=linear............................\n",
      "[CV 1/3; 24/36] END C=0.02, gamma=3, kernel=linear;, score=0.853 total time=   0.0s\n",
      "[CV 2/3; 24/36] START C=0.02, gamma=3, kernel=linear............................\n",
      "[CV 2/3; 24/36] END C=0.02, gamma=3, kernel=linear;, score=0.887 total time=   0.0s\n",
      "[CV 3/3; 24/36] START C=0.02, gamma=3, kernel=linear............................\n",
      "[CV 3/3; 24/36] END C=0.02, gamma=3, kernel=linear;, score=0.840 total time=   0.0s\n",
      "[CV 3/3; 29/36] START C=0.05, gamma=3, kernel=rbf...............................\n",
      "[CV 3/3; 29/36] END C=0.05, gamma=3, kernel=rbf;, score=0.628 total time=   0.0s\n",
      "[CV 3/3; 31/36] START C=0.1, gamma=1, kernel=rbf................................\n",
      "[CV 3/3; 31/36] END .C=0.1, gamma=1, kernel=rbf;, score=0.853 total time=   0.0s\n",
      "[CV 2/3; 34/36] START C=0.1, gamma=2, kernel=linear.............................\n",
      "[CV 2/3; 34/36] END C=0.1, gamma=2, kernel=linear;, score=0.887 total time=   0.0s\n",
      "[CV 2/3; 1/36] START C=0.001, gamma=1, kernel=rbf...............................\n",
      "[CV 2/3; 1/36] END C=0.001, gamma=1, kernel=rbf;, score=0.769 total time=   0.0s\n",
      "[CV 3/3; 4/36] START C=0.001, gamma=2, kernel=linear............................\n",
      "[CV 3/3; 4/36] END C=0.001, gamma=2, kernel=linear;, score=0.714 total time=   0.0s\n",
      "[CV 3/3; 7/36] START C=0.005, gamma=1, kernel=rbf...............................\n",
      "[CV 3/3; 7/36] END C=0.005, gamma=1, kernel=rbf;, score=0.697 total time=   0.0s\n",
      "[CV 1/3; 8/36] START C=0.005, gamma=1, kernel=linear............................\n",
      "[CV 1/3; 8/36] END C=0.005, gamma=1, kernel=linear;, score=0.698 total time=   0.0s\n",
      "[CV 1/3; 13/36] START C=0.01, gamma=1, kernel=rbf...............................\n",
      "[CV 1/3; 13/36] END C=0.01, gamma=1, kernel=rbf;, score=0.827 total time=   0.0s\n",
      "[CV 2/3; 13/36] START C=0.01, gamma=1, kernel=rbf...............................\n",
      "[CV 2/3; 13/36] END C=0.01, gamma=1, kernel=rbf;, score=0.861 total time=   0.0s\n",
      "[CV 3/3; 19/36] START C=0.02, gamma=1, kernel=rbf...............................\n",
      "[CV 3/3; 19/36] END C=0.02, gamma=1, kernel=rbf;, score=0.488 total time=   0.0s\n",
      "[CV 1/3; 20/36] START C=0.02, gamma=1, kernel=linear............................\n",
      "[CV 1/3; 20/36] END C=0.02, gamma=1, kernel=linear;, score=0.920 total time=   0.0s\n",
      "[CV 2/3; 20/36] START C=0.02, gamma=1, kernel=linear............................\n",
      "[CV 2/3; 20/36] END C=0.02, gamma=1, kernel=linear;, score=0.850 total time=   0.0s\n",
      "[CV 3/3; 20/36] START C=0.02, gamma=1, kernel=linear............................\n",
      "[CV 3/3; 20/36] END C=0.02, gamma=1, kernel=linear;, score=0.677 total time=   0.0s\n",
      "[CV 2/3; 28/36] START C=0.05, gamma=2, kernel=linear............................\n",
      "[CV 2/3; 28/36] END C=0.05, gamma=2, kernel=linear;, score=0.853 total time=   0.0s\n",
      "[CV 1/3; 30/36] START C=0.05, gamma=3, kernel=linear............................\n",
      "[CV 1/3; 30/36] END C=0.05, gamma=3, kernel=linear;, score=0.920 total time=   0.0s\n",
      "[CV 3/3; 33/36] START C=0.1, gamma=2, kernel=rbf................................\n",
      "[CV 3/3; 33/36] END .C=0.1, gamma=2, kernel=rbf;, score=0.661 total time=   0.0s\n",
      "[CV 2/3; 1/36] START C=0.001, gamma=1, kernel=rbf...............................\n",
      "[CV 2/3; 1/36] END C=0.001, gamma=1, kernel=rbf;, score=0.426 total time=   0.0s\n",
      "[CV 1/3; 4/36] START C=0.001, gamma=2, kernel=linear............................\n",
      "[CV 1/3; 4/36] END C=0.001, gamma=2, kernel=linear;, score=0.622 total time=   0.0s\n",
      "[CV 1/3; 7/36] START C=0.005, gamma=1, kernel=rbf...............................\n",
      "[CV 1/3; 7/36] END C=0.005, gamma=1, kernel=rbf;, score=0.747 total time=   0.0s\n",
      "[CV 2/3; 7/36] START C=0.005, gamma=1, kernel=rbf...............................\n",
      "[CV 2/3; 7/36] END C=0.005, gamma=1, kernel=rbf;, score=0.626 total time=   0.0s\n",
      "[CV 2/3; 12/36] START C=0.005, gamma=3, kernel=linear...........................\n",
      "[CV 2/3; 12/36] END C=0.005, gamma=3, kernel=linear;, score=0.590 total time=   0.0s\n",
      "[CV 3/3; 12/36] START C=0.005, gamma=3, kernel=linear...........................\n",
      "[CV 3/3; 12/36] END C=0.005, gamma=3, kernel=linear;, score=0.893 total time=   0.0s\n",
      "[CV 2/3; 18/36] START C=0.01, gamma=3, kernel=linear............................\n",
      "[CV 2/3; 18/36] END C=0.01, gamma=3, kernel=linear;, score=0.577 total time=   0.0s\n",
      "[CV 3/3; 18/36] START C=0.01, gamma=3, kernel=linear............................\n",
      "[CV 3/3; 18/36] END C=0.01, gamma=3, kernel=linear;, score=0.663 total time=   0.0s\n",
      "[CV 1/3; 19/36] START C=0.02, gamma=1, kernel=rbf...............................\n",
      "[CV 1/3; 19/36] END C=0.02, gamma=1, kernel=rbf;, score=0.602 total time=   0.0s\n",
      "[CV 2/3; 19/36] START C=0.02, gamma=1, kernel=rbf...............................\n",
      "[CV 2/3; 19/36] END C=0.02, gamma=1, kernel=rbf;, score=0.722 total time=   0.0s\n",
      "[CV 3/3; 27/36] START C=0.05, gamma=2, kernel=rbf...............................\n",
      "[CV 3/3; 27/36] END C=0.05, gamma=2, kernel=rbf;, score=0.847 total time=   0.0s\n",
      "[CV 2/3; 29/36] START C=0.05, gamma=3, kernel=rbf...............................\n",
      "[CV 2/3; 29/36] END C=0.05, gamma=3, kernel=rbf;, score=0.797 total time=   0.0s\n",
      "[CV 3/3; 31/36] START C=0.1, gamma=1, kernel=rbf................................\n",
      "[CV 3/3; 31/36] END .C=0.1, gamma=1, kernel=rbf;, score=0.854 total time=   0.0s\n",
      "[CV 2/3; 35/36] START C=0.1, gamma=3, kernel=rbf................................\n",
      "[CV 2/3; 35/36] END .C=0.1, gamma=3, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 1/3; 2/36] START C=0.001, gamma=1, kernel=linear............................\n",
      "[CV 1/3; 2/36] END C=0.001, gamma=1, kernel=linear;, score=0.677 total time=   0.0s\n",
      "[CV 3/3; 27/36] START C=0.05, gamma=2, kernel=rbf...............................\n",
      "[CV 3/3; 27/36] END C=0.05, gamma=2, kernel=rbf;, score=0.681 total time=   0.0s\n",
      "[CV 1/3; 29/36] START C=0.05, gamma=3, kernel=rbf...............................\n",
      "[CV 1/3; 29/36] END C=0.05, gamma=3, kernel=rbf;, score=0.784 total time=   0.0s\n",
      "[CV 2/3; 31/36] START C=0.1, gamma=1, kernel=rbf................................\n",
      "[CV 2/3; 31/36] END .C=0.1, gamma=1, kernel=rbf;, score=0.807 total time=   0.0s\n",
      "[CV 3/3; 33/36] START C=0.1, gamma=2, kernel=rbf................................\n",
      "[CV 3/3; 33/36] END .C=0.1, gamma=2, kernel=rbf;, score=0.908 total time=   0.0s\n",
      "[CV 1/3; 36/36] START C=0.1, gamma=3, kernel=linear.............................\n",
      "[CV 1/3; 36/36] END C=0.1, gamma=3, kernel=linear;, score=0.675 total time=   0.0s\n",
      "[CV 3/3; 2/36] START C=0.001, gamma=1, kernel=linear............................\n",
      "[CV 3/3; 2/36] END C=0.001, gamma=1, kernel=linear;, score=0.653 total time=   0.0s\n",
      "[CV 3/3; 5/36] START C=0.001, gamma=3, kernel=rbf...............................\n",
      "[CV 3/3; 5/36] END C=0.001, gamma=3, kernel=rbf;, score=0.844 total time=   0.0s\n",
      "[CV 1/3; 11/36] START C=0.005, gamma=3, kernel=rbf..............................\n",
      "[CV 1/3; 11/36] END C=0.005, gamma=3, kernel=rbf;, score=0.877 total time=   0.0s\n",
      "[CV 2/3; 11/36] START C=0.005, gamma=3, kernel=rbf..............................\n",
      "[CV 2/3; 11/36] END C=0.005, gamma=3, kernel=rbf;, score=0.696 total time=   0.0s\n",
      "[CV 2/3; 16/36] START C=0.01, gamma=2, kernel=linear............................\n",
      "[CV 2/3; 16/36] END C=0.01, gamma=2, kernel=linear;, score=0.888 total time=   0.0s\n",
      "[CV 3/3; 16/36] START C=0.01, gamma=2, kernel=linear............................\n",
      "[CV 3/3; 16/36] END C=0.01, gamma=2, kernel=linear;, score=0.647 total time=   0.0s\n",
      "[CV 2/3; 26/36] START C=0.05, gamma=1, kernel=linear............................\n",
      "[CV 2/3; 26/36] END C=0.05, gamma=1, kernel=linear;, score=0.888 total time=   0.0s\n",
      "[CV 3/3; 26/36] START C=0.05, gamma=1, kernel=linear............................\n",
      "[CV 3/3; 26/36] END C=0.05, gamma=1, kernel=linear;, score=0.685 total time=   0.0s\n",
      "[CV 1/3; 27/36] START C=0.05, gamma=2, kernel=rbf...............................\n",
      "[CV 1/3; 27/36] END C=0.05, gamma=2, kernel=rbf;, score=0.888 total time=   0.0s\n",
      "[CV 2/3; 27/36] START C=0.05, gamma=2, kernel=rbf...............................\n",
      "[CV 2/3; 27/36] END C=0.05, gamma=2, kernel=rbf;, score=0.851 total time=   0.0s\n",
      "[CV 1/3; 32/36] START C=0.1, gamma=1, kernel=linear.............................\n",
      "[CV 1/3; 32/36] END C=0.1, gamma=1, kernel=linear;, score=0.879 total time=   0.0s\n",
      "[CV 3/3; 34/36] START C=0.1, gamma=2, kernel=linear.............................\n",
      "[CV 3/3; 34/36] END C=0.1, gamma=2, kernel=linear;, score=0.841 total time=   0.0s\n",
      "[CV 1/3; 1/36] START C=0.001, gamma=1, kernel=rbf...............................\n",
      "[CV 1/3; 1/36] END C=0.001, gamma=1, kernel=rbf;, score=0.590 total time=   0.0s\n",
      "[CV 3/3; 3/36] START C=0.001, gamma=2, kernel=rbf...............................\n",
      "[CV 3/3; 3/36] END C=0.001, gamma=2, kernel=rbf;, score=0.572 total time=   0.0s\n",
      "[CV 1/3; 6/36] START C=0.001, gamma=3, kernel=linear............................\n",
      "[CV 1/3; 6/36] END C=0.001, gamma=3, kernel=linear;, score=0.893 total time=   0.0s\n",
      "[CV 1/3; 11/36] START C=0.005, gamma=3, kernel=rbf..............................\n",
      "[CV 1/3; 11/36] END C=0.005, gamma=3, kernel=rbf;, score=0.707 total time=   0.0s\n",
      "[CV 2/3; 11/36] START C=0.005, gamma=3, kernel=rbf..............................\n",
      "[CV 2/3; 11/36] END C=0.005, gamma=3, kernel=rbf;, score=0.872 total time=   0.0s\n",
      "[CV 2/3; 16/36] START C=0.01, gamma=2, kernel=linear............................\n",
      "[CV 2/3; 16/36] END C=0.01, gamma=2, kernel=linear;, score=0.852 total time=   0.0s\n",
      "[CV 3/3; 16/36] START C=0.01, gamma=2, kernel=linear............................\n",
      "[CV 3/3; 16/36] END C=0.01, gamma=2, kernel=linear;, score=0.675 total time=   0.0s\n",
      "[CV 3/3; 23/36] START C=0.02, gamma=3, kernel=rbf...............................\n",
      "[CV 3/3; 23/36] END C=0.02, gamma=3, kernel=rbf;, score=0.810 total time=   0.0s\n",
      "[CV 1/3; 24/36] START C=0.02, gamma=3, kernel=linear............................\n",
      "[CV 1/3; 24/36] END C=0.02, gamma=3, kernel=linear;, score=0.920 total time=   0.0s\n",
      "[CV 2/3; 24/36] START C=0.02, gamma=3, kernel=linear............................\n",
      "[CV 2/3; 24/36] END C=0.02, gamma=3, kernel=linear;, score=0.850 total time=   0.0s\n",
      "[CV 3/3; 24/36] START C=0.02, gamma=3, kernel=linear............................\n",
      "[CV 3/3; 24/36] END C=0.02, gamma=3, kernel=linear;, score=0.677 total time=   0.0s\n",
      "[CV 2/3; 29/36] START C=0.05, gamma=3, kernel=rbf...............................\n",
      "[CV 2/3; 29/36] END C=0.05, gamma=3, kernel=rbf;, score=0.791 total time=   0.0s\n",
      "[CV 1/3; 32/36] START C=0.1, gamma=1, kernel=linear.............................\n",
      "[CV 1/3; 32/36] END C=0.1, gamma=1, kernel=linear;, score=0.673 total time=   0.0s\n",
      "[CV 2/3; 34/36] START C=0.1, gamma=2, kernel=linear.............................\n",
      "[CV 2/3; 34/36] END C=0.1, gamma=2, kernel=linear;, score=0.853 total time=   0.0s\n",
      "[CV 3/3; 36/36] START C=0.1, gamma=3, kernel=linear.............................\n",
      "[CV 3/3; 36/36] END C=0.1, gamma=3, kernel=linear;, score=0.673 total time=   0.0s\n",
      "[CV 2/3; 3/36] START C=0.001, gamma=2, kernel=rbf...............................\n",
      "[CV 2/3; 3/36] END C=0.001, gamma=2, kernel=rbf;, score=0.426 total time=   0.0s\n",
      "[CV 1/3; 6/36] START C=0.001, gamma=3, kernel=linear............................\n",
      "[CV 1/3; 6/36] END C=0.001, gamma=3, kernel=linear;, score=0.622 total time=   0.0s\n",
      "[CV 3/3; 9/36] START C=0.005, gamma=2, kernel=rbf...............................\n",
      "[CV 3/3; 9/36] END C=0.005, gamma=2, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 1/3; 10/36] START C=0.005, gamma=2, kernel=linear...........................\n",
      "[CV 1/3; 10/36] END C=0.005, gamma=2, kernel=linear;, score=0.834 total time=   0.0s\n",
      "[CV 1/3; 15/36] START C=0.01, gamma=2, kernel=rbf...............................\n",
      "[CV 1/3; 15/36] END C=0.01, gamma=2, kernel=rbf;, score=0.681 total time=   0.0s\n",
      "[CV 2/3; 15/36] START C=0.01, gamma=2, kernel=rbf...............................\n",
      "[CV 2/3; 15/36] END C=0.01, gamma=2, kernel=rbf;, score=0.782 total time=   0.0s\n",
      "[CV 3/3; 23/36] START C=0.02, gamma=3, kernel=rbf...............................\n",
      "[CV 3/3; 23/36] END C=0.02, gamma=3, kernel=rbf;, score=0.969 total time=   0.0s\n",
      "[CV 1/3; 24/36] START C=0.02, gamma=3, kernel=linear............................\n",
      "[CV 1/3; 24/36] END C=0.02, gamma=3, kernel=linear;, score=0.717 total time=   0.0s\n",
      "[CV 2/3; 24/36] START C=0.02, gamma=3, kernel=linear............................\n",
      "[CV 2/3; 24/36] END C=0.02, gamma=3, kernel=linear;, score=0.578 total time=   0.0s\n",
      "[CV 3/3; 24/36] START C=0.02, gamma=3, kernel=linear............................\n",
      "[CV 3/3; 24/36] END C=0.02, gamma=3, kernel=linear;, score=0.752 total time=   0.0s\n",
      "[CV 1/3; 29/36] START C=0.05, gamma=3, kernel=rbf...............................\n",
      "[CV 1/3; 29/36] END C=0.05, gamma=3, kernel=rbf;, score=0.732 total time=   0.0s\n",
      "[CV 3/3; 30/36] START C=0.05, gamma=3, kernel=linear............................\n",
      "[CV 3/3; 30/36] END C=0.05, gamma=3, kernel=linear;, score=0.719 total time=   0.0s\n",
      "[CV 2/3; 33/36] START C=0.1, gamma=2, kernel=rbf................................\n",
      "[CV 2/3; 33/36] END .C=0.1, gamma=2, kernel=rbf;, score=0.840 total time=   0.0s\n",
      "[CV 3/3; 35/36] START C=0.1, gamma=3, kernel=rbf................................\n",
      "[CV 3/3; 35/36] END .C=0.1, gamma=3, kernel=rbf;, score=0.969 total time=   0.0s\n",
      "[CV 2/3; 2/50] START colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=3\n",
      "[CV 2/3; 2/50] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=3;, score=0.963 total time=   0.0s\n",
      "[CV 1/3; 4/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=15, min_child_weight=7\n",
      "[CV 1/3; 4/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=15, min_child_weight=7;, score=0.754 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV 1/3; 34/36] START C=0.1, gamma=2, kernel=linear.............................\n",
      "[CV 1/3; 34/36] END C=0.1, gamma=2, kernel=linear;, score=0.673 total time=   0.0s\n",
      "[CV 2/3; 36/36] START C=0.1, gamma=3, kernel=linear.............................\n",
      "[CV 2/3; 36/36] END C=0.1, gamma=3, kernel=linear;, score=0.853 total time=   0.0s\n",
      "[CV 1/3; 3/36] START C=0.001, gamma=2, kernel=rbf...............................\n",
      "[CV 1/3; 3/36] END C=0.001, gamma=2, kernel=rbf;, score=0.645 total time=   0.0s\n",
      "[CV 3/3; 5/36] START C=0.001, gamma=3, kernel=rbf...............................\n",
      "[CV 3/3; 5/36] END C=0.001, gamma=3, kernel=rbf;, score=0.896 total time=   0.0s\n",
      "[CV 1/3; 11/36] START C=0.005, gamma=3, kernel=rbf..............................\n",
      "[CV 1/3; 11/36] END C=0.005, gamma=3, kernel=rbf;, score=0.599 total time=   0.0s\n",
      "[CV 2/3; 11/36] START C=0.005, gamma=3, kernel=rbf..............................\n",
      "[CV 2/3; 11/36] END C=0.005, gamma=3, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 3/3; 15/36] START C=0.01, gamma=2, kernel=rbf...............................\n",
      "[CV 3/3; 15/36] END C=0.01, gamma=2, kernel=rbf;, score=0.847 total time=   0.0s\n",
      "[CV 1/3; 16/36] START C=0.01, gamma=2, kernel=linear............................\n",
      "[CV 1/3; 16/36] END C=0.01, gamma=2, kernel=linear;, score=0.729 total time=   0.0s\n",
      "[CV 1/3; 25/36] START C=0.05, gamma=1, kernel=rbf...............................\n",
      "[CV 1/3; 25/36] END C=0.05, gamma=1, kernel=rbf;, score=0.658 total time=   0.0s\n",
      "[CV 2/3; 25/36] START C=0.05, gamma=1, kernel=rbf...............................\n",
      "[CV 2/3; 25/36] END C=0.05, gamma=1, kernel=rbf;, score=0.705 total time=   0.0s\n",
      "[CV 3/3; 25/36] START C=0.05, gamma=1, kernel=rbf...............................\n",
      "[CV 3/3; 25/36] END C=0.05, gamma=1, kernel=rbf;, score=0.854 total time=   0.0s\n",
      "[CV 1/3; 26/36] START C=0.05, gamma=1, kernel=linear............................\n",
      "[CV 1/3; 26/36] END C=0.05, gamma=1, kernel=linear;, score=0.715 total time=   0.0s\n",
      "[CV 2/3; 32/36] START C=0.1, gamma=1, kernel=linear.............................\n",
      "[CV 2/3; 32/36] END C=0.1, gamma=1, kernel=linear;, score=0.561 total time=   0.0s\n",
      "[CV 3/3; 34/36] START C=0.1, gamma=2, kernel=linear.............................\n",
      "[CV 3/3; 34/36] END C=0.1, gamma=2, kernel=linear;, score=0.719 total time=   0.0s\n",
      "[CV 3/3; 1/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=5, min_child_weight=7\n",
      "[CV 3/3; 1/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=5, min_child_weight=7;, score=0.905 total time=   0.1s\n",
      "[CV 1/3; 5/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=7\n",
      "[CV 1/3; 5/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=7;, score=0.772 total time=   0.0s\n",
      "[CV 3/3; 9/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1\n",
      "[CV 3/3; 9/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1;, score=0.965 total time=   0.1s\n",
      "[CV 1/3; 10/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=12, min_child_weight=7\n",
      "[CV 1/3; 10/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=12, min_child_weight=7;, score=0.754 total time=   0.1s\n",
      "[CV 3/3; 15/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=5\n",
      "[CV 3/3; 15/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=5;, score=0.968 total time=   0.1s\n",
      "[CV 1/3; 16/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.2, max_depth=12, min_child_weight=1\n",
      "[CV 1/3; 16/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.2, max_depth=12, min_child_weight=1;, score=0.978 total time=   0.1s\n",
      "[CV 1/3; 25/50] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.3, max_depth=3, min_child_weight=3\n",
      "[CV 1/3; 25/50] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.3, max_depth=3, min_child_weight=3;, score=0.958 total time=   0.0s\n",
      "[CV 2/3; 25/50] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.3, max_depth=3, min_child_weight=3\n",
      "[CV 2/3; 25/50] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.3, max_depth=3, min_child_weight=3;, score=0.966 total time=   0.1s\n",
      "[CV 3/3; 25/50] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.3, max_depth=3, min_child_weight=3\n",
      "[CV 3/3; 25/50] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.3, max_depth=3, min_child_weight=3;, score=0.972 total time=   0.1s\n",
      "[CV 1/3; 26/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=8, min_child_weight=1\n",
      "[CV 1/3; 26/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=8, min_child_weight=1;, score=0.978 total time=   0.1s\n",
      "[CV 2/3; 30/50] START colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=5\n",
      "[CV 2/3; 30/50] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=5;, score=0.950 total time=   0.1s\n",
      "[CV 3/3; 30/50] START colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=5\n",
      "[CV 3/3; 30/50] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=5;, score=0.939 total time=   0.0s\n",
      "[CV 1/3; 31/50] START colsample_bytree=0.3, gamma=0.2, learning_rate=0.25, max_depth=12, min_child_weight=3\n",
      "[CV 1/3; 31/50] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.25, max_depth=12, min_child_weight=3;, score=0.972 total time=   0.1s\n",
      "[CV 2/3; 31/50] START colsample_bytree=0.3, gamma=0.2, learning_rate=0.25, max_depth=12, min_child_weight=3\n",
      "[CV 2/3; 31/50] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.25, max_depth=12, min_child_weight=3;, score=0.960 total time=   0.1s\n",
      "[CV 3/3; 39/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.25, max_depth=3, min_child_weight=1\n",
      "[CV 3/3; 39/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.25, max_depth=3, min_child_weight=1;, score=0.962 total time=   0.1s\n",
      "[CV 1/3; 40/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.1, max_depth=15, min_child_weight=5\n",
      "[CV 1/3; 40/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.1, max_depth=15, min_child_weight=5;, score=0.898 total time=   0.1s\n",
      "[CV 2/3; 40/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.1, max_depth=15, min_child_weight=5\n",
      "[CV 2/3; 40/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.1, max_depth=15, min_child_weight=5;, score=0.950 total time=   0.0s\n",
      "[CV 3/3; 40/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.1, max_depth=15, min_child_weight=5\n",
      "[CV 3/3; 40/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.1, max_depth=15, min_child_weight=5;, score=0.939 total time=   0.1s\n",
      "[CV 1/3; 49/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=7\n",
      "[CV 1/3; 49/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=7;, score=0.820 total time=   0.0s\n",
      "[CV 2/3; 50/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.2, max_depth=6, min_child_weight=1\n",
      "[CV 2/3; 50/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.2, max_depth=6, min_child_weight=1;, score=0.954 total time=   0.0s\n",
      "[CV 2/3; 3/50] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.1, max_depth=8, min_child_weight=1\n",
      "[CV 2/3; 3/50] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.1, max_depth=8, min_child_weight=1;, score=0.896 total time=   0.0s\n",
      "[CV 1/3; 6/50] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=7\n",
      "[CV 1/3; 6/50] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=7;, score=0.855 total time=   0.1s\n",
      "[CV 3/3; 9/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1\n",
      "[CV 3/3; 9/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1;, score=0.944 total time=   0.1s\n",
      "[CV 1/3; 10/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=12, min_child_weight=7\n",
      "[CV 1/3; 10/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=12, min_child_weight=7;, score=0.810 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 11/36] START C=0.005, gamma=3, kernel=rbf..............................\n",
      "[CV 3/3; 11/36] END C=0.005, gamma=3, kernel=rbf;, score=0.969 total time=   0.0s\n",
      "[CV 1/3; 12/36] START C=0.005, gamma=3, kernel=linear...........................\n",
      "[CV 1/3; 12/36] END C=0.005, gamma=3, kernel=linear;, score=0.834 total time=   0.0s\n",
      "[CV 2/3; 16/36] START C=0.01, gamma=2, kernel=linear............................\n",
      "[CV 2/3; 16/36] END C=0.01, gamma=2, kernel=linear;, score=0.577 total time=   0.0s\n",
      "[CV 3/3; 16/36] START C=0.01, gamma=2, kernel=linear............................\n",
      "[CV 3/3; 16/36] END C=0.01, gamma=2, kernel=linear;, score=0.663 total time=   0.0s\n",
      "[CV 2/3; 26/36] START C=0.05, gamma=1, kernel=linear............................\n",
      "[CV 2/3; 26/36] END C=0.05, gamma=1, kernel=linear;, score=0.561 total time=   0.0s\n",
      "[CV 3/3; 26/36] START C=0.05, gamma=1, kernel=linear............................\n",
      "[CV 3/3; 26/36] END C=0.05, gamma=1, kernel=linear;, score=0.719 total time=   0.0s\n",
      "[CV 1/3; 27/36] START C=0.05, gamma=2, kernel=rbf...............................\n",
      "[CV 1/3; 27/36] END C=0.05, gamma=2, kernel=rbf;, score=0.809 total time=   0.0s\n",
      "[CV 2/3; 27/36] START C=0.05, gamma=2, kernel=rbf...............................\n",
      "[CV 2/3; 27/36] END C=0.05, gamma=2, kernel=rbf;, score=0.783 total time=   0.0s\n",
      "[CV 3/3; 32/36] START C=0.1, gamma=1, kernel=linear.............................\n",
      "[CV 3/3; 32/36] END C=0.1, gamma=1, kernel=linear;, score=0.719 total time=   0.0s\n",
      "[CV 1/3; 35/36] START C=0.1, gamma=3, kernel=rbf................................\n",
      "[CV 1/3; 35/36] END .C=0.1, gamma=3, kernel=rbf;, score=0.715 total time=   0.0s\n",
      "[CV 2/3; 1/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=5, min_child_weight=7\n",
      "[CV 2/3; 1/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=5, min_child_weight=7;, score=0.940 total time=   0.0s\n",
      "[CV 3/3; 4/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=15, min_child_weight=7\n",
      "[CV 3/3; 4/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=15, min_child_weight=7;, score=0.915 total time=   0.1s\n",
      "[CV 2/3; 8/50] START colsample_bytree=0.4, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=3\n",
      "[CV 2/3; 8/50] END colsample_bytree=0.4, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=3;, score=0.958 total time=   0.1s\n",
      "[CV 3/3; 8/50] START colsample_bytree=0.4, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=3\n",
      "[CV 3/3; 8/50] END colsample_bytree=0.4, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=3;, score=0.964 total time=   0.1s\n",
      "[CV 1/3; 13/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.05, max_depth=8, min_child_weight=3\n",
      "[CV 1/3; 13/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.05, max_depth=8, min_child_weight=3;, score=0.958 total time=   0.1s\n",
      "[CV 2/3; 13/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.05, max_depth=8, min_child_weight=3\n",
      "[CV 2/3; 13/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.05, max_depth=8, min_child_weight=3;, score=0.950 total time=   0.1s\n",
      "[CV 3/3; 19/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=1\n",
      "[CV 3/3; 19/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=1;, score=0.962 total time=   0.1s\n",
      "[CV 1/3; 20/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1\n",
      "[CV 1/3; 20/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1;, score=0.970 total time=   0.1s\n",
      "[CV 2/3; 20/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1\n",
      "[CV 2/3; 20/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1;, score=0.963 total time=   0.1s\n",
      "[CV 3/3; 20/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1\n",
      "[CV 3/3; 20/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1;, score=0.961 total time=   0.1s\n",
      "[CV 2/3; 34/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=8, min_child_weight=3\n",
      "[CV 2/3; 34/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=8, min_child_weight=3;, score=0.952 total time=   0.1s\n",
      "[CV 3/3; 34/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=8, min_child_weight=3\n",
      "[CV 3/3; 34/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=8, min_child_weight=3;, score=0.965 total time=   0.1s\n",
      "[CV 1/3; 35/50] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.2, max_depth=3, min_child_weight=5\n",
      "[CV 1/3; 35/50] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.2, max_depth=3, min_child_weight=5;, score=0.904 total time=   0.0s\n",
      "[CV 2/3; 35/50] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.2, max_depth=3, min_child_weight=5\n",
      "[CV 2/3; 35/50] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.2, max_depth=3, min_child_weight=5;, score=0.955 total time=   0.1s\n",
      "[CV 3/3; 43/50] START colsample_bytree=0.4, gamma=0.0, learning_rate=0.2, max_depth=12, min_child_weight=1\n",
      "[CV 3/3; 43/50] END colsample_bytree=0.4, gamma=0.0, learning_rate=0.2, max_depth=12, min_child_weight=1;, score=0.960 total time=   0.1s\n",
      "[CV 1/3; 44/50] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.15, max_depth=3, min_child_weight=1\n",
      "[CV 1/3; 44/50] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.15, max_depth=3, min_child_weight=1;, score=0.979 total time=   0.1s\n",
      "[CV 2/3; 44/50] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.15, max_depth=3, min_child_weight=1\n",
      "[CV 2/3; 44/50] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.15, max_depth=3, min_child_weight=1;, score=0.958 total time=   0.1s\n",
      "[CV 3/3; 44/50] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.15, max_depth=3, min_child_weight=1\n",
      "[CV 3/3; 44/50] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.15, max_depth=3, min_child_weight=1;, score=0.965 total time=   0.0s\n",
      "[CV 1/3; 50/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.2, max_depth=6, min_child_weight=1\n",
      "[CV 1/3; 50/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.2, max_depth=6, min_child_weight=1;, score=0.967 total time=   0.0s\n",
      "[CV 3/3; 2/50] START colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=3\n",
      "[CV 3/3; 2/50] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=3;, score=0.969 total time=   0.1s\n",
      "[CV 3/3; 5/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=7\n",
      "[CV 3/3; 5/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=7;, score=0.869 total time=   0.1s\n",
      "[CV 2/3; 10/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=12, min_child_weight=7\n",
      "[CV 2/3; 10/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=12, min_child_weight=7;, score=0.889 total time=   0.1s\n",
      "[CV 3/3; 10/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=12, min_child_weight=7\n",
      "[CV 3/3; 10/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=12, min_child_weight=7;, score=0.807 total time=   0.1s\n",
      "[CV 3/3; 15/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=5\n",
      "[CV 3/3; 15/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=5;, score=0.895 total time=   0.1s\n",
      "[CV 1/3; 16/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.2, max_depth=12, min_child_weight=1\n",
      "[CV 1/3; 16/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.2, max_depth=12, min_child_weight=1;, score=0.949 total time=   0.1s\n",
      "[CV 2/3; 26/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=8, min_child_weight=1\n",
      "[CV 2/3; 26/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=8, min_child_weight=1;, score=0.846 total time=   0.0s\n",
      "[CV 3/3; 26/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=8, min_child_weight=1\n",
      "[CV 1/3; 30/36] END C=0.05, gamma=3, kernel=linear;, score=0.715 total time=   0.0s\n",
      "[CV 1/3; 32/36] START C=0.1, gamma=1, kernel=linear.............................\n",
      "[CV 1/3; 32/36] END C=0.1, gamma=1, kernel=linear;, score=0.717 total time=   0.0s\n",
      "[CV 2/3; 34/36] START C=0.1, gamma=2, kernel=linear.............................\n",
      "[CV 2/3; 34/36] END C=0.1, gamma=2, kernel=linear;, score=0.561 total time=   0.0s\n",
      "[CV 3/3; 36/36] START C=0.1, gamma=3, kernel=linear.............................\n",
      "[CV 3/3; 36/36] END C=0.1, gamma=3, kernel=linear;, score=0.719 total time=   0.0s\n",
      "[CV 2/3; 3/50] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.1, max_depth=8, min_child_weight=1\n",
      "[CV 2/3; 3/50] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.1, max_depth=8, min_child_weight=1;, score=0.964 total time=   0.1s\n",
      "[CV 3/3; 5/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=7\n",
      "[CV 3/3; 5/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=7;, score=0.938 total time=   0.0s\n",
      "[CV 2/3; 10/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=12, min_child_weight=7\n",
      "[CV 2/3; 10/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=12, min_child_weight=7;, score=0.925 total time=   0.1s\n",
      "[CV 3/3; 10/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=12, min_child_weight=7\n",
      "[CV 3/3; 10/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=12, min_child_weight=7;, score=0.915 total time=   0.1s\n",
      "[CV 2/3; 16/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.2, max_depth=12, min_child_weight=1\n",
      "[CV 2/3; 16/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.2, max_depth=12, min_child_weight=1;, score=0.955 total time=   0.1s\n",
      "[CV 3/3; 16/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.2, max_depth=12, min_child_weight=1\n",
      "[CV 3/3; 16/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.2, max_depth=12, min_child_weight=1;, score=0.965 total time=   0.1s\n",
      "[CV 2/3; 26/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=8, min_child_weight=1\n",
      "[CV 2/3; 26/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=8, min_child_weight=1;, score=0.956 total time=   0.1s\n",
      "[CV 3/3; 26/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=8, min_child_weight=1\n",
      "[CV 3/3; 26/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=8, min_child_weight=1;, score=0.962 total time=   0.1s\n",
      "[CV 1/3; 27/50] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.2, max_depth=5, min_child_weight=7\n",
      "[CV 1/3; 27/50] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.2, max_depth=5, min_child_weight=7;, score=0.743 total time=   0.1s\n",
      "[CV 2/3; 27/50] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.2, max_depth=5, min_child_weight=7\n",
      "[CV 2/3; 27/50] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.2, max_depth=5, min_child_weight=7;, score=0.920 total time=   0.0s\n",
      "[CV 1/3; 37/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=12, min_child_weight=1\n",
      "[CV 1/3; 37/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=12, min_child_weight=1;, score=0.975 total time=   0.1s\n",
      "[CV 2/3; 37/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=12, min_child_weight=1\n",
      "[CV 2/3; 37/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=12, min_child_weight=1;, score=0.963 total time=   0.1s\n",
      "[CV 3/3; 37/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=12, min_child_weight=1\n",
      "[CV 3/3; 37/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=12, min_child_weight=1;, score=0.965 total time=   0.1s\n",
      "[CV 1/3; 38/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.15, max_depth=6, min_child_weight=1\n",
      "[CV 1/3; 38/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.15, max_depth=6, min_child_weight=1;, score=0.953 total time=   0.1s\n",
      "[CV 3/3; 47/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.2, max_depth=4, min_child_weight=3\n",
      "[CV 3/3; 47/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.2, max_depth=4, min_child_weight=3;, score=0.973 total time=   0.1s\n",
      "[CV 1/3; 48/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=4, min_child_weight=1\n",
      "[CV 1/3; 48/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=4, min_child_weight=1;, score=0.942 total time=   0.1s\n",
      "[CV 2/3; 48/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=4, min_child_weight=1\n",
      "[CV 2/3; 48/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=4, min_child_weight=1;, score=0.961 total time=   0.1s\n",
      "[CV 3/3; 48/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=4, min_child_weight=1\n",
      "[CV 3/3; 48/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=4, min_child_weight=1;, score=0.952 total time=   0.0s\n",
      "[CV 1/3; 2/50] START colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=3\n",
      "[CV 1/3; 2/50] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=3;, score=0.930 total time=   0.1s\n",
      "[CV 1/3; 4/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=15, min_child_weight=7\n",
      "[CV 1/3; 4/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=15, min_child_weight=7;, score=0.810 total time=   0.1s\n",
      "[CV 3/3; 7/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=1\n",
      "[CV 3/3; 7/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=1;, score=0.938 total time=   0.1s\n",
      "[CV 1/3; 8/50] START colsample_bytree=0.4, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=3\n",
      "[CV 1/3; 8/50] END colsample_bytree=0.4, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=3;, score=0.932 total time=   0.0s\n",
      "[CV 1/3; 13/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.05, max_depth=8, min_child_weight=3\n",
      "[CV 1/3; 13/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.05, max_depth=8, min_child_weight=3;, score=0.940 total time=   0.1s\n",
      "[CV 2/3; 13/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.05, max_depth=8, min_child_weight=3\n",
      "[CV 2/3; 13/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.05, max_depth=8, min_child_weight=3;, score=0.919 total time=   0.1s\n",
      "[CV 1/3; 25/50] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.3, max_depth=3, min_child_weight=3\n",
      "[CV 1/3; 25/50] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.3, max_depth=3, min_child_weight=3;, score=0.925 total time=   0.0s\n",
      "[CV 2/3; 25/50] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.3, max_depth=3, min_child_weight=3\n",
      "[CV 2/3; 25/50] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.3, max_depth=3, min_child_weight=3;, score=0.925 total time=   0.1s\n",
      "[CV 3/3; 25/50] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.3, max_depth=3, min_child_weight=3\n",
      "[CV 3/3; 25/50] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.3, max_depth=3, min_child_weight=3;, score=0.969 total time=   0.1s\n",
      "[CV 1/3; 26/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=8, min_child_weight=1\n",
      "[CV 1/3; 26/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=8, min_child_weight=1;, score=0.982 total time=   0.0s\n",
      "[CV 1/3; 33/50] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5\n",
      "[CV 1/3; 33/50] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5;, score=0.930 total time=   0.1s\n",
      "[CV 2/3; 33/50] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5\n",
      "[CV 2/3; 33/50] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5;, score=0.904 total time=   0.1s\n",
      "[CV 3/3; 33/50] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5\n",
      "[CV 3/3; 33/50] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5;, score=0.867 total time=   0.1s\n",
      "[CV 2/3; 31/36] START C=0.1, gamma=1, kernel=rbf................................\n",
      "[CV 2/3; 31/36] END .C=0.1, gamma=1, kernel=rbf;, score=0.717 total time=   0.0s\n",
      "[CV 1/3; 34/36] START C=0.1, gamma=2, kernel=linear.............................\n",
      "[CV 1/3; 34/36] END C=0.1, gamma=2, kernel=linear;, score=0.717 total time=   0.0s\n",
      "[CV 2/3; 36/36] START C=0.1, gamma=3, kernel=linear.............................\n",
      "[CV 2/3; 36/36] END C=0.1, gamma=3, kernel=linear;, score=0.561 total time=   0.0s\n",
      "[CV 1/3; 3/50] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.1, max_depth=8, min_child_weight=1\n",
      "[CV 1/3; 3/50] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.1, max_depth=8, min_child_weight=1;, score=0.975 total time=   0.1s\n",
      "[CV 2/3; 5/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=7\n",
      "[CV 2/3; 5/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=7;, score=0.952 total time=   0.0s\n",
      "[CV 1/3; 9/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1\n",
      "[CV 1/3; 9/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1;, score=0.974 total time=   0.1s\n",
      "[CV 2/3; 9/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1\n",
      "[CV 2/3; 9/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1;, score=0.947 total time=   0.1s\n",
      "[CV 3/3; 13/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.05, max_depth=8, min_child_weight=3\n",
      "[CV 3/3; 13/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.05, max_depth=8, min_child_weight=3;, score=0.955 total time=   0.1s\n",
      "[CV 1/3; 14/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1\n",
      "[CV 1/3; 14/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1;, score=0.973 total time=   0.1s\n",
      "[CV 1/3; 21/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.15, max_depth=3, min_child_weight=5\n",
      "[CV 1/3; 21/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.15, max_depth=3, min_child_weight=5;, score=0.898 total time=   0.0s\n",
      "[CV 2/3; 21/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.15, max_depth=3, min_child_weight=5\n",
      "[CV 2/3; 21/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.15, max_depth=3, min_child_weight=5;, score=0.958 total time=   0.1s\n",
      "[CV 3/3; 21/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.15, max_depth=3, min_child_weight=5\n",
      "[CV 3/3; 21/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.15, max_depth=3, min_child_weight=5;, score=0.968 total time=   0.1s\n",
      "[CV 1/3; 22/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=5\n",
      "[CV 1/3; 22/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=5;, score=0.899 total time=   0.1s\n",
      "[CV 3/3; 27/50] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.2, max_depth=5, min_child_weight=7\n",
      "[CV 3/3; 27/50] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.2, max_depth=5, min_child_weight=7;, score=0.903 total time=   0.1s\n",
      "[CV 1/3; 28/50] START colsample_bytree=0.3, gamma=0.1, learning_rate=0.15, max_depth=4, min_child_weight=7\n",
      "[CV 1/3; 28/50] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.15, max_depth=4, min_child_weight=7;, score=0.762 total time=   0.0s\n",
      "[CV 2/3; 28/50] START colsample_bytree=0.3, gamma=0.1, learning_rate=0.15, max_depth=4, min_child_weight=7\n",
      "[CV 2/3; 28/50] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.15, max_depth=4, min_child_weight=7;, score=0.914 total time=   0.1s\n",
      "[CV 3/3; 28/50] START colsample_bytree=0.3, gamma=0.1, learning_rate=0.15, max_depth=4, min_child_weight=7\n",
      "[CV 3/3; 28/50] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.15, max_depth=4, min_child_weight=7;, score=0.896 total time=   0.1s\n",
      "[CV 2/3; 38/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.15, max_depth=6, min_child_weight=1\n",
      "[CV 2/3; 38/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.15, max_depth=6, min_child_weight=1;, score=0.963 total time=   0.1s\n",
      "[CV 3/3; 38/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.15, max_depth=6, min_child_weight=1\n",
      "[CV 3/3; 38/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.15, max_depth=6, min_child_weight=1;, score=0.950 total time=   0.1s\n",
      "[CV 1/3; 39/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.25, max_depth=3, min_child_weight=1\n",
      "[CV 1/3; 39/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.25, max_depth=3, min_child_weight=1;, score=0.975 total time=   0.1s\n",
      "[CV 2/3; 39/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.25, max_depth=3, min_child_weight=1\n",
      "[CV 2/3; 39/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.25, max_depth=3, min_child_weight=1;, score=0.960 total time=   0.0s\n",
      "[CV 3/3; 49/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=7\n",
      "[CV 3/3; 49/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=7;, score=0.913 total time=   0.0s\n",
      "[CV 2/3; 2/50] START colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=3\n",
      "[CV 2/3; 2/50] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=3;, score=0.922 total time=   0.1s\n",
      "[CV 2/3; 4/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=15, min_child_weight=7\n",
      "[CV 2/3; 4/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=15, min_child_weight=7;, score=0.889 total time=   0.1s\n",
      "[CV 2/3; 6/50] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=7\n",
      "[CV 2/3; 6/50] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=7;, score=0.871 total time=   0.1s\n",
      "[CV 3/3; 6/50] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=7\n",
      "[CV 3/3; 6/50] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=7;, score=0.826 total time=   0.0s\n",
      "[CV 2/3; 12/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=3\n",
      "[CV 2/3; 12/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=3;, score=0.919 total time=   0.1s\n",
      "[CV 3/3; 12/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=3\n",
      "[CV 3/3; 12/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=3;, score=0.948 total time=   0.1s\n",
      "[CV 3/3; 19/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=1\n",
      "[CV 3/3; 19/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=1;, score=0.985 total time=   0.1s\n",
      "[CV 1/3; 20/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1\n",
      "[CV 1/3; 20/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1;, score=0.982 total time=   0.1s\n",
      "[CV 2/3; 20/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1\n",
      "[CV 2/3; 20/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1;, score=0.874 total time=   0.1s\n",
      "[CV 3/3; 20/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1\n",
      "[CV 3/3; 20/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1;, score=0.948 total time=   0.0s\n",
      "[CV 2/3; 34/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=8, min_child_weight=3\n",
      "[CV 2/3; 34/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=8, min_child_weight=3;, score=0.924 total time=   0.1s\n",
      "[CV 3/3; 34/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=8, min_child_weight=3\n",
      "[CV 3/3; 34/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=8, min_child_weight=3;, score=0.972 total time=   0.1s\n",
      "[CV 1/3; 35/50] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.2, max_depth=3, min_child_weight=5\n",
      "[CV 1/3; 31/36] START C=0.1, gamma=1, kernel=rbf................................\n",
      "[CV 1/3; 31/36] END .C=0.1, gamma=1, kernel=rbf;, score=0.704 total time=   0.0s\n",
      "[CV 3/3; 33/36] START C=0.1, gamma=2, kernel=rbf................................\n",
      "[CV 3/3; 33/36] END .C=0.1, gamma=2, kernel=rbf;, score=0.854 total time=   0.0s\n",
      "[CV 1/3; 36/36] START C=0.1, gamma=3, kernel=linear.............................\n",
      "[CV 1/3; 36/36] END C=0.1, gamma=3, kernel=linear;, score=0.717 total time=   0.0s\n",
      "[CV 3/3; 2/50] START colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=3\n",
      "[CV 3/3; 2/50] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=3;, score=0.970 total time=   0.1s\n",
      "[CV 1/3; 6/50] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=7\n",
      "[CV 1/3; 6/50] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=7;, score=0.810 total time=   0.1s\n",
      "[CV 1/3; 11/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=12, min_child_weight=5\n",
      "[CV 1/3; 11/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=12, min_child_weight=5;, score=0.904 total time=   0.1s\n",
      "[CV 2/3; 11/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=12, min_child_weight=5\n",
      "[CV 2/3; 11/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=12, min_child_weight=5;, score=0.956 total time=   0.1s\n",
      "[CV 2/3; 14/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1\n",
      "[CV 2/3; 14/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1;, score=0.963 total time=   0.1s\n",
      "[CV 3/3; 14/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1\n",
      "[CV 3/3; 14/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1;, score=0.965 total time=   0.1s\n",
      "[CV 3/3; 23/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.3, max_depth=12, min_child_weight=7\n",
      "[CV 3/3; 23/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.3, max_depth=12, min_child_weight=7;, score=0.924 total time=   0.0s\n",
      "[CV 1/3; 24/50] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=15, min_child_weight=1\n",
      "[CV 1/3; 24/50] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=15, min_child_weight=1;, score=0.964 total time=   0.1s\n",
      "[CV 2/3; 24/50] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=15, min_child_weight=1\n",
      "[CV 2/3; 24/50] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=15, min_child_weight=1;, score=0.962 total time=   0.1s\n",
      "[CV 3/3; 24/50] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=15, min_child_weight=1\n",
      "[CV 3/3; 24/50] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=15, min_child_weight=1;, score=0.953 total time=   0.1s\n",
      "[CV 3/3; 35/50] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.2, max_depth=3, min_child_weight=5\n",
      "[CV 3/3; 35/50] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.2, max_depth=3, min_child_weight=5;, score=0.957 total time=   0.1s\n",
      "[CV 1/3; 36/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.15, max_depth=5, min_child_weight=1\n",
      "[CV 1/3; 36/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.15, max_depth=5, min_child_weight=1;, score=0.978 total time=   0.1s\n",
      "[CV 2/3; 36/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.15, max_depth=5, min_child_weight=1\n",
      "[CV 2/3; 36/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.15, max_depth=5, min_child_weight=1;, score=0.966 total time=   0.1s\n",
      "[CV 3/3; 36/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.15, max_depth=5, min_child_weight=1\n",
      "[CV 3/3; 36/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.15, max_depth=5, min_child_weight=1;, score=0.961 total time=   0.1s\n",
      "[CV 2/3; 46/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=15, min_child_weight=3\n",
      "[CV 2/3; 46/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=15, min_child_weight=3;, score=0.950 total time=   0.1s\n",
      "[CV 3/3; 46/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=15, min_child_weight=3\n",
      "[CV 3/3; 46/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=15, min_child_weight=3;, score=0.970 total time=   0.1s\n",
      "[CV 1/3; 47/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.2, max_depth=4, min_child_weight=3\n",
      "[CV 1/3; 47/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.2, max_depth=4, min_child_weight=3;, score=0.970 total time=   0.1s\n",
      "[CV 2/3; 47/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.2, max_depth=4, min_child_weight=3\n",
      "[CV 2/3; 47/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.2, max_depth=4, min_child_weight=3;, score=0.960 total time=   0.0s\n",
      "[CV 2/3; 1/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=5, min_child_weight=7\n",
      "[CV 2/3; 1/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=5, min_child_weight=7;, score=0.832 total time=   0.1s\n",
      "[CV 2/3; 5/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=7\n",
      "[CV 2/3; 5/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=7;, score=0.842 total time=   0.1s\n",
      "[CV 1/3; 11/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=12, min_child_weight=5\n",
      "[CV 1/3; 11/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=12, min_child_weight=5;, score=0.894 total time=   0.1s\n",
      "[CV 2/3; 11/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=12, min_child_weight=5\n",
      "[CV 2/3; 11/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=12, min_child_weight=5;, score=0.888 total time=   0.1s\n",
      "[CV 2/3; 14/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1\n",
      "[CV 2/3; 14/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1;, score=0.874 total time=   0.0s\n",
      "[CV 3/3; 14/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1\n",
      "[CV 3/3; 14/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1;, score=0.948 total time=   0.1s\n",
      "[CV 2/3; 18/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1\n",
      "[CV 2/3; 18/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1;, score=0.863 total time=   0.1s\n",
      "[CV 3/3; 18/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1\n",
      "[CV 3/3; 18/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1;, score=0.944 total time=   0.1s\n",
      "[CV 1/3; 19/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=1\n",
      "[CV 1/3; 19/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=1;, score=0.982 total time=   0.1s\n",
      "[CV 2/3; 19/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=1\n",
      "[CV 2/3; 19/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=1;, score=0.904 total time=   0.0s\n",
      "[CV 2/3; 30/50] START colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=5\n",
      "[CV 2/3; 30/50] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=5;, score=0.901 total time=   0.1s\n",
      "[CV 3/3; 30/50] START colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=5\n",
      "[CV 3/3; 30/50] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=5;, score=0.867 total time=   0.1s\n",
      "[CV 1/3; 31/50] START colsample_bytree=0.3, gamma=0.2, learning_rate=0.25, max_depth=12, min_child_weight=3\n",
      "[CV 1/3; 31/50] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.25, max_depth=12, min_child_weight=3;, score=0.934 total time=   0.0s\n",
      "[CV 2/3; 31/50] START colsample_bytree=0.3, gamma=0.2, learning_rate=0.25, max_depth=12, min_child_weight=3\n",
      "[CV 1/3; 2/50] START colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=3\n",
      "[CV 1/3; 2/50] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=3;, score=0.969 total time=   0.0s\n",
      "[CV 3/3; 3/50] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.1, max_depth=8, min_child_weight=1\n",
      "[CV 3/3; 3/50] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.1, max_depth=8, min_child_weight=1;, score=0.961 total time=   0.1s\n",
      "[CV 3/3; 7/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=1\n",
      "[CV 3/3; 7/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=1;, score=0.960 total time=   0.1s\n",
      "[CV 1/3; 8/50] START colsample_bytree=0.4, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=3\n",
      "[CV 1/3; 8/50] END colsample_bytree=0.4, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=3;, score=0.949 total time=   0.1s\n",
      "[CV 1/3; 15/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=5\n",
      "[CV 1/3; 15/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=5;, score=0.919 total time=   0.1s\n",
      "[CV 2/3; 15/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=5\n",
      "[CV 2/3; 15/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=5;, score=0.956 total time=   0.1s\n",
      "[CV 2/3; 22/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=5\n",
      "[CV 2/3; 22/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=5;, score=0.949 total time=   0.1s\n",
      "[CV 3/3; 22/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=5\n",
      "[CV 3/3; 22/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=5;, score=0.938 total time=   0.1s\n",
      "[CV 1/3; 23/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.3, max_depth=12, min_child_weight=7\n",
      "[CV 1/3; 23/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.3, max_depth=12, min_child_weight=7;, score=0.763 total time=   0.1s\n",
      "[CV 2/3; 23/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.3, max_depth=12, min_child_weight=7\n",
      "[CV 2/3; 23/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.3, max_depth=12, min_child_weight=7;, score=0.952 total time=   0.1s\n",
      "[CV 1/3; 29/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=3\n",
      "[CV 1/3; 29/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=3;, score=0.970 total time=   0.1s\n",
      "[CV 2/3; 29/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=3\n",
      "[CV 2/3; 29/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=3;, score=0.958 total time=   0.0s\n",
      "[CV 3/3; 29/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=3\n",
      "[CV 3/3; 29/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=3;, score=0.972 total time=   0.1s\n",
      "[CV 1/3; 30/50] START colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=5\n",
      "[CV 1/3; 30/50] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=5;, score=0.898 total time=   0.1s\n",
      "[CV 1/3; 41/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=5\n",
      "[CV 1/3; 41/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=5;, score=0.928 total time=   0.1s\n",
      "[CV 2/3; 41/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=5\n",
      "[CV 2/3; 41/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=5;, score=0.956 total time=   0.0s\n",
      "[CV 3/3; 41/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=5\n",
      "[CV 3/3; 41/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=5;, score=0.969 total time=   0.1s\n",
      "[CV 1/3; 42/50] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=3\n",
      "[CV 1/3; 42/50] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=3;, score=0.970 total time=   0.1s\n",
      "[CV 2/3; 49/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=7\n",
      "[CV 2/3; 49/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=7;, score=0.949 total time=   0.0s\n",
      "[CV 3/3; 50/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.2, max_depth=6, min_child_weight=1\n",
      "[CV 3/3; 50/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.2, max_depth=6, min_child_weight=1;, score=0.966 total time=   0.0s\n",
      "[CV 1/3; 3/50] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.1, max_depth=8, min_child_weight=1\n",
      "[CV 1/3; 3/50] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.1, max_depth=8, min_child_weight=1;, score=0.967 total time=   0.0s\n",
      "[CV 1/3; 5/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=7\n",
      "[CV 1/3; 5/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=7;, score=0.806 total time=   0.1s\n",
      "[CV 2/3; 8/50] START colsample_bytree=0.4, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=3\n",
      "[CV 2/3; 8/50] END colsample_bytree=0.4, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=3;, score=0.912 total time=   0.1s\n",
      "[CV 3/3; 8/50] START colsample_bytree=0.4, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=3\n",
      "[CV 3/3; 8/50] END colsample_bytree=0.4, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=3;, score=0.969 total time=   0.1s\n",
      "[CV 2/3; 16/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.2, max_depth=12, min_child_weight=1\n",
      "[CV 2/3; 16/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.2, max_depth=12, min_child_weight=1;, score=0.862 total time=   0.1s\n",
      "[CV 3/3; 16/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.2, max_depth=12, min_child_weight=1\n",
      "[CV 3/3; 16/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.2, max_depth=12, min_child_weight=1;, score=0.944 total time=   0.1s\n",
      "[CV 3/3; 23/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.3, max_depth=12, min_child_weight=7\n",
      "[CV 3/3; 23/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.3, max_depth=12, min_child_weight=7;, score=0.813 total time=   0.0s\n",
      "[CV 1/3; 24/50] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=15, min_child_weight=1\n",
      "[CV 1/3; 24/50] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=15, min_child_weight=1;, score=0.945 total time=   0.1s\n",
      "[CV 2/3; 24/50] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=15, min_child_weight=1\n",
      "[CV 2/3; 24/50] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=15, min_child_weight=1;, score=0.854 total time=   0.1s\n",
      "[CV 3/3; 24/50] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=15, min_child_weight=1\n",
      "[CV 3/3; 24/50] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=15, min_child_weight=1;, score=0.929 total time=   0.1s\n",
      "[CV 1/3; 37/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=12, min_child_weight=1\n",
      "[CV 1/3; 37/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=12, min_child_weight=1;, score=0.960 total time=   0.0s\n",
      "[CV 2/3; 37/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=12, min_child_weight=1\n",
      "[CV 2/3; 37/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=12, min_child_weight=1;, score=0.890 total time=   0.1s\n",
      "[CV 3/3; 37/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=12, min_child_weight=1\n",
      "[CV 3/3; 37/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=12, min_child_weight=1;, score=0.944 total time=   0.1s\n",
      "[CV 1/3; 38/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.15, max_depth=6, min_child_weight=1\n",
      "[CV 2/3; 30/36] START C=0.05, gamma=3, kernel=linear............................\n",
      "[CV 2/3; 30/36] END C=0.05, gamma=3, kernel=linear;, score=0.561 total time=   0.0s\n",
      "[CV 1/3; 33/36] START C=0.1, gamma=2, kernel=rbf................................\n",
      "[CV 1/3; 33/36] END .C=0.1, gamma=2, kernel=rbf;, score=0.724 total time=   0.0s\n",
      "[CV 1/3; 1/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=5, min_child_weight=7\n",
      "[CV 1/3; 1/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=5, min_child_weight=7;, score=0.802 total time=   0.0s\n",
      "[CV 2/3; 4/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=15, min_child_weight=7\n",
      "[CV 2/3; 4/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=15, min_child_weight=7;, score=0.925 total time=   0.1s\n",
      "[CV 1/3; 7/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=1\n",
      "[CV 1/3; 7/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=1;, score=0.962 total time=   0.1s\n",
      "[CV 2/3; 7/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=1\n",
      "[CV 2/3; 7/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=1;, score=0.963 total time=   0.0s\n",
      "[CV 2/3; 12/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=3\n",
      "[CV 2/3; 12/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=3;, score=0.950 total time=   0.1s\n",
      "[CV 3/3; 12/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=3\n",
      "[CV 3/3; 12/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=3;, score=0.956 total time=   0.1s\n",
      "[CV 2/3; 18/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1\n",
      "[CV 2/3; 18/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1;, score=0.961 total time=   0.1s\n",
      "[CV 3/3; 18/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1\n",
      "[CV 3/3; 18/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1;, score=0.957 total time=   0.1s\n",
      "[CV 1/3; 19/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=1\n",
      "[CV 1/3; 19/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=1;, score=0.970 total time=   0.1s\n",
      "[CV 2/3; 19/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=1\n",
      "[CV 2/3; 19/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=1;, score=0.964 total time=   0.1s\n",
      "[CV 1/3; 33/50] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5\n",
      "[CV 1/3; 33/50] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5;, score=0.898 total time=   0.1s\n",
      "[CV 2/3; 33/50] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5\n",
      "[CV 2/3; 33/50] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5;, score=0.949 total time=   0.0s\n",
      "[CV 3/3; 33/50] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5\n",
      "[CV 3/3; 33/50] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5;, score=0.947 total time=   0.1s\n",
      "[CV 1/3; 34/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=8, min_child_weight=3\n",
      "[CV 1/3; 34/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=8, min_child_weight=3;, score=0.962 total time=   0.1s\n",
      "[CV 2/3; 42/50] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=3\n",
      "[CV 2/3; 42/50] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=3;, score=0.954 total time=   0.1s\n",
      "[CV 3/3; 42/50] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=3\n",
      "[CV 3/3; 42/50] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=3;, score=0.970 total time=   0.1s\n",
      "[CV 1/3; 43/50] START colsample_bytree=0.4, gamma=0.0, learning_rate=0.2, max_depth=12, min_child_weight=1\n",
      "[CV 1/3; 43/50] END colsample_bytree=0.4, gamma=0.0, learning_rate=0.2, max_depth=12, min_child_weight=1;, score=0.969 total time=   0.1s\n",
      "[CV 2/3; 43/50] START colsample_bytree=0.4, gamma=0.0, learning_rate=0.2, max_depth=12, min_child_weight=1\n",
      "[CV 2/3; 43/50] END colsample_bytree=0.4, gamma=0.0, learning_rate=0.2, max_depth=12, min_child_weight=1;, score=0.951 total time=   0.1s\n",
      "[CV 1/3; 1/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=5, min_child_weight=7\n",
      "[CV 1/3; 1/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=5, min_child_weight=7;, score=0.855 total time=   0.1s\n",
      "[CV 3/3; 3/50] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.1, max_depth=8, min_child_weight=1\n",
      "[CV 3/3; 3/50] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.1, max_depth=8, min_child_weight=1;, score=0.975 total time=   0.1s\n",
      "[CV 1/3; 9/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1\n",
      "[CV 1/3; 9/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1;, score=0.974 total time=   0.1s\n",
      "[CV 2/3; 9/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1\n",
      "[CV 2/3; 9/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1;, score=0.882 total time=   0.1s\n",
      "[CV 1/3; 15/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=5\n",
      "[CV 1/3; 15/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=5;, score=0.875 total time=   0.1s\n",
      "[CV 2/3; 15/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=5\n",
      "[CV 2/3; 15/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=5;, score=0.879 total time=   0.0s\n",
      "[CV 2/3; 22/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=5\n",
      "[CV 2/3; 22/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=5;, score=0.897 total time=   0.1s\n",
      "[CV 3/3; 22/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=5\n",
      "[CV 3/3; 22/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=5;, score=0.878 total time=   0.1s\n",
      "[CV 1/3; 23/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.3, max_depth=12, min_child_weight=7\n",
      "[CV 1/3; 23/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.3, max_depth=12, min_child_weight=7;, score=0.806 total time=   0.1s\n",
      "[CV 2/3; 23/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.3, max_depth=12, min_child_weight=7\n",
      "[CV 2/3; 23/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.3, max_depth=12, min_child_weight=7;, score=0.769 total time=   0.0s\n",
      "[CV 3/3; 31/50] START colsample_bytree=0.3, gamma=0.2, learning_rate=0.25, max_depth=12, min_child_weight=3\n",
      "[CV 3/3; 31/50] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.25, max_depth=12, min_child_weight=3;, score=0.969 total time=   0.1s\n",
      "[CV 1/3; 32/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1\n",
      "[CV 1/3; 32/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1;, score=0.949 total time=   0.1s\n",
      "[CV 2/3; 32/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1\n",
      "[CV 2/3; 32/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1;, score=0.857 total time=   0.1s\n",
      "[CV 3/3; 32/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1\n",
      "[CV 3/3; 32/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1;, score=0.929 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3; 6/50] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=7\n",
      "[CV 2/3; 6/50] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=7;, score=0.936 total time=   0.1s\n",
      "[CV 3/3; 6/50] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=7\n",
      "[CV 3/3; 6/50] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=7;, score=0.932 total time=   0.0s\n",
      "[CV 3/3; 11/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=12, min_child_weight=5\n",
      "[CV 3/3; 11/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=12, min_child_weight=5;, score=0.964 total time=   0.1s\n",
      "[CV 1/3; 12/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=3\n",
      "[CV 1/3; 12/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=3;, score=0.953 total time=   0.1s\n",
      "[CV 1/3; 17/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3\n",
      "[CV 1/3; 17/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3;, score=0.962 total time=   0.1s\n",
      "[CV 2/3; 17/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3\n",
      "[CV 2/3; 17/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3;, score=0.952 total time=   0.1s\n",
      "[CV 3/3; 17/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3\n",
      "[CV 3/3; 17/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3;, score=0.965 total time=   0.1s\n",
      "[CV 1/3; 18/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1\n",
      "[CV 1/3; 18/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1;, score=0.936 total time=   0.1s\n",
      "[CV 3/3; 31/50] START colsample_bytree=0.3, gamma=0.2, learning_rate=0.25, max_depth=12, min_child_weight=3\n",
      "[CV 3/3; 31/50] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.25, max_depth=12, min_child_weight=3;, score=0.977 total time=   0.1s\n",
      "[CV 1/3; 32/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1\n",
      "[CV 1/3; 32/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1;, score=0.942 total time=   0.1s\n",
      "[CV 2/3; 32/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1\n",
      "[CV 2/3; 32/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1;, score=0.961 total time=   0.1s\n",
      "[CV 3/3; 32/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1\n",
      "[CV 3/3; 32/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1;, score=0.949 total time=   0.1s\n",
      "[CV 1/3; 45/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.2, max_depth=10, min_child_weight=5\n",
      "[CV 1/3; 45/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.2, max_depth=10, min_child_weight=5;, score=0.906 total time=   0.0s\n",
      "[CV 2/3; 45/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.2, max_depth=10, min_child_weight=5\n",
      "[CV 2/3; 45/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.2, max_depth=10, min_child_weight=5;, score=0.956 total time=   0.1s\n",
      "[CV 3/3; 45/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.2, max_depth=10, min_child_weight=5\n",
      "[CV 3/3; 45/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.2, max_depth=10, min_child_weight=5;, score=0.962 total time=   0.1s\n",
      "[CV 1/3; 46/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=15, min_child_weight=3\n",
      "[CV 1/3; 46/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=15, min_child_weight=3;, score=0.969 total time=   0.0s\n",
      "[CV 3/3; 1/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=5, min_child_weight=7\n",
      "[CV 3/3; 1/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=5, min_child_weight=7;, score=0.819 total time=   0.1s\n",
      "[CV 3/3; 4/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=15, min_child_weight=7\n",
      "[CV 3/3; 4/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=15, min_child_weight=7;, score=0.807 total time=   0.1s\n",
      "[CV 1/3; 7/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=1\n",
      "[CV 1/3; 7/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=1;, score=0.941 total time=   0.1s\n",
      "[CV 2/3; 7/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=1\n",
      "[CV 2/3; 7/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=1;, score=0.899 total time=   0.0s\n",
      "[CV 3/3; 11/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=12, min_child_weight=5\n",
      "[CV 3/3; 11/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=12, min_child_weight=5;, score=0.886 total time=   0.1s\n",
      "[CV 1/3; 12/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=3\n",
      "[CV 1/3; 12/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=3;, score=0.940 total time=   0.1s\n",
      "[CV 1/3; 21/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.15, max_depth=3, min_child_weight=5\n",
      "[CV 1/3; 21/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.15, max_depth=3, min_child_weight=5;, score=0.890 total time=   0.1s\n",
      "[CV 2/3; 21/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.15, max_depth=3, min_child_weight=5\n",
      "[CV 2/3; 21/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.15, max_depth=3, min_child_weight=5;, score=0.899 total time=   0.1s\n",
      "[CV 3/3; 21/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.15, max_depth=3, min_child_weight=5\n",
      "[CV 3/3; 21/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.15, max_depth=3, min_child_weight=5;, score=0.886 total time=   0.0s\n",
      "[CV 1/3; 22/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=5\n",
      "[CV 1/3; 22/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=5;, score=0.890 total time=   0.1s\n",
      "[CV 1/3; 29/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=3\n",
      "[CV 1/3; 29/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=3;, score=0.941 total time=   0.1s\n",
      "[CV 2/3; 29/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=3\n",
      "[CV 2/3; 29/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=3;, score=0.921 total time=   0.1s\n",
      "[CV 3/3; 29/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=3\n",
      "[CV 3/3; 29/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=3;, score=0.954 total time=   0.1s\n",
      "[CV 1/3; 30/50] START colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=5\n",
      "[CV 1/3; 30/50] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=5;, score=0.901 total time=   0.0s\n",
      "[CV 1/3; 41/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=5\n",
      "[CV 1/3; 41/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=5;, score=0.883 total time=   0.1s\n",
      "[CV 2/3; 41/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=5\n",
      "[CV 2/3; 41/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=5;, score=0.875 total time=   0.1s\n",
      "[CV 3/3; 41/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=5\n",
      "[CV 3/3; 41/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=5;, score=0.895 total time=   0.0s\n",
      "[CV 1/3; 42/50] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=3\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV 3/3; 13/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.05, max_depth=8, min_child_weight=3\n",
      "[CV 3/3; 13/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.05, max_depth=8, min_child_weight=3;, score=0.941 total time=   0.0s\n",
      "[CV 1/3; 14/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1\n",
      "[CV 1/3; 14/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1;, score=0.945 total time=   0.1s\n",
      "[CV 1/3; 17/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3\n",
      "[CV 1/3; 17/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3;, score=0.932 total time=   0.1s\n",
      "[CV 2/3; 17/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3\n",
      "[CV 2/3; 17/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3;, score=0.924 total time=   0.1s\n",
      "[CV 3/3; 17/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3\n",
      "[CV 3/3; 17/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3;, score=0.972 total time=   0.0s\n",
      "[CV 1/3; 18/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1\n",
      "[CV 1/3; 18/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1;, score=0.952 total time=   0.1s\n",
      "[CV 3/3; 27/50] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.2, max_depth=5, min_child_weight=7\n",
      "[CV 3/3; 27/50] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.2, max_depth=5, min_child_weight=7;, score=0.869 total time=   0.1s\n",
      "[CV 1/3; 28/50] START colsample_bytree=0.3, gamma=0.1, learning_rate=0.15, max_depth=4, min_child_weight=7\n",
      "[CV 1/3; 28/50] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.15, max_depth=4, min_child_weight=7;, score=0.775 total time=   0.0s\n",
      "[CV 2/3; 28/50] START colsample_bytree=0.3, gamma=0.1, learning_rate=0.15, max_depth=4, min_child_weight=7\n",
      "[CV 2/3; 28/50] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.15, max_depth=4, min_child_weight=7;, score=0.889 total time=   0.1s\n",
      "[CV 3/3; 28/50] START colsample_bytree=0.3, gamma=0.1, learning_rate=0.15, max_depth=4, min_child_weight=7\n",
      "[CV 3/3; 28/50] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.15, max_depth=4, min_child_weight=7;, score=0.869 total time=   0.1s\n",
      "[CV 2/3; 38/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.15, max_depth=6, min_child_weight=1\n",
      "[CV 2/3; 38/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.15, max_depth=6, min_child_weight=1;, score=0.847 total time=   0.1s\n",
      "[CV 3/3; 38/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.15, max_depth=6, min_child_weight=1\n",
      "[CV 3/3; 38/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.15, max_depth=6, min_child_weight=1;, score=0.920 total time=   0.1s\n",
      "[CV 1/3; 39/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.25, max_depth=3, min_child_weight=1\n",
      "[CV 1/3; 39/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.25, max_depth=3, min_child_weight=1;, score=0.963 total time=   0.1s\n",
      "[CV 2/3; 39/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.25, max_depth=3, min_child_weight=1\n",
      "[CV 2/3; 39/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.25, max_depth=3, min_child_weight=1;, score=0.871 total time=   0.0s\n",
      "[CV 2/3; 50/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.2, max_depth=6, min_child_weight=1\n",
      "[CV 2/3; 50/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.2, max_depth=6, min_child_weight=1;, score=0.840 total time=   0.1s\n",
      "[CV 1/3; 3/50] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.1, max_depth=8, min_child_weight=1\n",
      "[CV 1/3; 3/50] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.1, max_depth=8, min_child_weight=1;, score=0.959 total time=   0.1s\n",
      "[CV 3/3; 5/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=7\n",
      "[CV 3/3; 5/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=7;, score=0.715 total time=   0.1s\n",
      "[CV 2/3; 10/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=12, min_child_weight=7\n",
      "[CV 2/3; 10/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=12, min_child_weight=7;, score=0.756 total time=   0.1s\n",
      "[CV 3/3; 10/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=12, min_child_weight=7\n",
      "[CV 3/3; 10/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=12, min_child_weight=7;, score=0.707 total time=   0.1s\n",
      "[CV 1/3; 15/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=5\n",
      "[CV 1/3; 15/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=5;, score=0.932 total time=   0.0s\n",
      "[CV 2/3; 15/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=5\n",
      "[CV 2/3; 15/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=5;, score=0.934 total time=   0.1s\n",
      "[CV 2/3; 22/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=5\n",
      "[CV 2/3; 22/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=5;, score=0.932 total time=   0.1s\n",
      "[CV 3/3; 22/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=5\n",
      "[CV 3/3; 22/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=5;, score=0.904 total time=   0.0s\n",
      "[CV 1/3; 23/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.3, max_depth=12, min_child_weight=7\n",
      "[CV 1/3; 23/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.3, max_depth=12, min_child_weight=7;, score=0.877 total time=   0.1s\n",
      "[CV 2/3; 23/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.3, max_depth=12, min_child_weight=7\n",
      "[CV 2/3; 23/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.3, max_depth=12, min_child_weight=7;, score=0.766 total time=   0.1s\n",
      "[CV 3/3; 31/50] START colsample_bytree=0.3, gamma=0.2, learning_rate=0.25, max_depth=12, min_child_weight=3\n",
      "[CV 3/3; 31/50] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.25, max_depth=12, min_child_weight=3;, score=0.927 total time=   0.0s\n",
      "[CV 1/3; 32/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1\n",
      "[CV 1/3; 32/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1;, score=0.971 total time=   0.1s\n",
      "[CV 2/3; 32/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1\n",
      "[CV 2/3; 32/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1;, score=0.965 total time=   0.1s\n",
      "[CV 3/3; 32/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1\n",
      "[CV 3/3; 32/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1;, score=0.977 total time=   0.1s\n",
      "[CV 2/3; 46/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=15, min_child_weight=3\n",
      "[CV 2/3; 46/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=15, min_child_weight=3;, score=0.956 total time=   0.1s\n",
      "[CV 3/3; 46/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=15, min_child_weight=3\n",
      "[CV 3/3; 46/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=15, min_child_weight=3;, score=0.886 total time=   0.0s\n",
      "[CV 1/3; 47/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.2, max_depth=4, min_child_weight=3\n",
      "[CV 1/3; 47/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.2, max_depth=4, min_child_weight=3;, score=0.974 total time=   0.1s\n",
      "[CV 2/3; 47/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.2, max_depth=4, min_child_weight=3\n",
      "[CV 2/3; 47/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.2, max_depth=4, min_child_weight=3;, score=0.956 total time=   0.1s\n",
      "[CV 1/3; 1/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=5, min_child_weight=7\n",
      "[CV 3/3; 26/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=8, min_child_weight=1;, score=0.938 total time=   0.1s\n",
      "[CV 1/3; 27/50] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.2, max_depth=5, min_child_weight=7\n",
      "[CV 1/3; 27/50] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.2, max_depth=5, min_child_weight=7;, score=0.775 total time=   0.1s\n",
      "[CV 2/3; 27/50] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.2, max_depth=5, min_child_weight=7\n",
      "[CV 2/3; 27/50] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.2, max_depth=5, min_child_weight=7;, score=0.889 total time=   0.0s\n",
      "[CV 3/3; 35/50] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.2, max_depth=3, min_child_weight=5\n",
      "[CV 3/3; 35/50] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.2, max_depth=3, min_child_weight=5;, score=0.892 total time=   0.1s\n",
      "[CV 1/3; 36/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.15, max_depth=5, min_child_weight=1\n",
      "[CV 1/3; 36/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.15, max_depth=5, min_child_weight=1;, score=0.989 total time=   0.1s\n",
      "[CV 2/3; 36/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.15, max_depth=5, min_child_weight=1\n",
      "[CV 2/3; 36/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.15, max_depth=5, min_child_weight=1;, score=0.879 total time=   0.1s\n",
      "[CV 3/3; 36/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.15, max_depth=5, min_child_weight=1\n",
      "[CV 3/3; 36/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.15, max_depth=5, min_child_weight=1;, score=0.975 total time=   0.1s\n",
      "[CV 1/3; 45/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.2, max_depth=10, min_child_weight=5\n",
      "[CV 1/3; 45/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.2, max_depth=10, min_child_weight=5;, score=0.894 total time=   0.0s\n",
      "[CV 2/3; 45/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.2, max_depth=10, min_child_weight=5\n",
      "[CV 2/3; 45/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.2, max_depth=10, min_child_weight=5;, score=0.892 total time=   0.1s\n",
      "[CV 3/3; 45/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.2, max_depth=10, min_child_weight=5\n",
      "[CV 3/3; 45/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.2, max_depth=10, min_child_weight=5;, score=0.886 total time=   0.1s\n",
      "[CV 1/3; 46/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=15, min_child_weight=3\n",
      "[CV 1/3; 46/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=15, min_child_weight=3;, score=0.940 total time=   0.0s\n",
      "[CV 3/3; 49/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=7\n",
      "[CV 3/3; 49/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=7;, score=0.838 total time=   0.1s\n",
      "[CV 2/3; 2/50] START colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=3\n",
      "[CV 2/3; 2/50] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=3;, score=0.960 total time=   0.1s\n",
      "[CV 3/3; 4/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=15, min_child_weight=7\n",
      "[CV 3/3; 4/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=15, min_child_weight=7;, score=0.707 total time=   0.1s\n",
      "[CV 2/3; 8/50] START colsample_bytree=0.4, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=3\n",
      "[CV 2/3; 8/50] END colsample_bytree=0.4, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=3;, score=0.960 total time=   0.1s\n",
      "[CV 3/3; 8/50] START colsample_bytree=0.4, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=3\n",
      "[CV 3/3; 8/50] END colsample_bytree=0.4, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=3;, score=0.867 total time=   0.0s\n",
      "[CV 3/3; 13/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.05, max_depth=8, min_child_weight=3\n",
      "[CV 3/3; 13/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.05, max_depth=8, min_child_weight=3;, score=0.913 total time=   0.1s\n",
      "[CV 1/3; 14/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1\n",
      "[CV 1/3; 14/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1;, score=0.968 total time=   0.1s\n",
      "[CV 3/3; 19/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=1\n",
      "[CV 3/3; 19/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=1;, score=0.960 total time=   0.0s\n",
      "[CV 1/3; 20/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1\n",
      "[CV 1/3; 20/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1;, score=0.979 total time=   0.1s\n",
      "[CV 2/3; 20/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1\n",
      "[CV 2/3; 20/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1;, score=0.971 total time=   0.1s\n",
      "[CV 3/3; 20/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1\n",
      "[CV 3/3; 20/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1;, score=0.970 total time=   0.1s\n",
      "[CV 1/3; 29/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=3\n",
      "[CV 1/3; 29/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=3;, score=0.965 total time=   0.0s\n",
      "[CV 2/3; 29/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=3\n",
      "[CV 2/3; 29/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=3;, score=0.967 total time=   0.1s\n",
      "[CV 3/3; 29/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=3\n",
      "[CV 3/3; 29/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=3;, score=0.936 total time=   0.1s\n",
      "[CV 1/3; 30/50] START colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=5\n",
      "[CV 1/3; 30/50] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=5;, score=0.908 total time=   0.0s\n",
      "[CV 3/3; 39/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.25, max_depth=3, min_child_weight=1\n",
      "[CV 3/3; 39/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.25, max_depth=3, min_child_weight=1;, score=0.965 total time=   0.1s\n",
      "[CV 1/3; 40/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.1, max_depth=15, min_child_weight=5\n",
      "[CV 1/3; 40/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.1, max_depth=15, min_child_weight=5;, score=0.908 total time=   0.1s\n",
      "[CV 2/3; 40/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.1, max_depth=15, min_child_weight=5\n",
      "[CV 2/3; 40/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.1, max_depth=15, min_child_weight=5;, score=0.927 total time=   0.0s\n",
      "[CV 3/3; 40/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.1, max_depth=15, min_child_weight=5\n",
      "[CV 3/3; 40/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.1, max_depth=15, min_child_weight=5;, score=0.800 total time=   0.0s\n",
      "[CV 1/3; 49/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=7\n",
      "[CV 1/3; 49/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=7;, score=0.664 total time=   0.1s\n",
      "[CV 2/3; 1/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=5, min_child_weight=7\n",
      "[CV 2/3; 1/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=5, min_child_weight=7;, score=0.583 total time=   0.1s\n",
      "[CV 2/3; 5/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=7\n",
      "[CV 2/3; 5/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=7;, score=0.619 total time=   0.0s\n",
      "[CV 3/3; 7/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=1\n",
      "[CV 3/3; 7/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=1;, score=0.977 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 35/50] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.2, max_depth=3, min_child_weight=5;, score=0.890 total time=   0.1s\n",
      "[CV 2/3; 35/50] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.2, max_depth=3, min_child_weight=5\n",
      "[CV 2/3; 35/50] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.2, max_depth=3, min_child_weight=5;, score=0.893 total time=   0.0s\n",
      "[CV 2/3; 42/50] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=3\n",
      "[CV 2/3; 42/50] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=3;, score=0.917 total time=   0.1s\n",
      "[CV 3/3; 42/50] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=3\n",
      "[CV 3/3; 42/50] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=3;, score=0.957 total time=   0.1s\n",
      "[CV 1/3; 43/50] START colsample_bytree=0.4, gamma=0.0, learning_rate=0.2, max_depth=12, min_child_weight=1\n",
      "[CV 1/3; 43/50] END colsample_bytree=0.4, gamma=0.0, learning_rate=0.2, max_depth=12, min_child_weight=1;, score=0.982 total time=   0.1s\n",
      "[CV 2/3; 43/50] START colsample_bytree=0.4, gamma=0.0, learning_rate=0.2, max_depth=12, min_child_weight=1\n",
      "[CV 2/3; 43/50] END colsample_bytree=0.4, gamma=0.0, learning_rate=0.2, max_depth=12, min_child_weight=1;, score=0.885 total time=   0.0s\n",
      "[CV 2/3; 49/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=7\n",
      "[CV 2/3; 49/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=7;, score=0.832 total time=   0.1s\n",
      "[CV 1/3; 2/50] START colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=3\n",
      "[CV 1/3; 2/50] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=3;, score=0.974 total time=   0.1s\n",
      "[CV 2/3; 4/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=15, min_child_weight=7\n",
      "[CV 2/3; 4/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=15, min_child_weight=7;, score=0.756 total time=   0.1s\n",
      "[CV 1/3; 7/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=1\n",
      "[CV 1/3; 7/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=1;, score=0.959 total time=   0.0s\n",
      "[CV 2/3; 7/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=1\n",
      "[CV 2/3; 7/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=1;, score=0.971 total time=   0.1s\n",
      "[CV 3/3; 11/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=12, min_child_weight=5\n",
      "[CV 3/3; 11/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=12, min_child_weight=5;, score=0.832 total time=   0.1s\n",
      "[CV 1/3; 12/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=3\n",
      "[CV 1/3; 12/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=3;, score=0.956 total time=   0.0s\n",
      "[CV 1/3; 17/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3\n",
      "[CV 1/3; 17/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3;, score=0.977 total time=   0.1s\n",
      "[CV 2/3; 17/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3\n",
      "[CV 2/3; 17/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3;, score=0.960 total time=   0.1s\n",
      "[CV 3/3; 17/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3\n",
      "[CV 3/3; 17/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3;, score=0.883 total time=   0.1s\n",
      "[CV 1/3; 18/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1\n",
      "[CV 1/3; 18/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1;, score=0.965 total time=   0.0s\n",
      "[CV 3/3; 27/50] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.2, max_depth=5, min_child_weight=7\n",
      "[CV 3/3; 27/50] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.2, max_depth=5, min_child_weight=7;, score=0.799 total time=   0.1s\n",
      "[CV 1/3; 28/50] START colsample_bytree=0.3, gamma=0.1, learning_rate=0.15, max_depth=4, min_child_weight=7\n",
      "[CV 1/3; 28/50] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.15, max_depth=4, min_child_weight=7;, score=0.749 total time=   0.0s\n",
      "[CV 2/3; 28/50] START colsample_bytree=0.3, gamma=0.1, learning_rate=0.15, max_depth=4, min_child_weight=7\n",
      "[CV 2/3; 28/50] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.15, max_depth=4, min_child_weight=7;, score=0.771 total time=   0.1s\n",
      "[CV 3/3; 28/50] START colsample_bytree=0.3, gamma=0.1, learning_rate=0.15, max_depth=4, min_child_weight=7\n",
      "[CV 3/3; 28/50] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.15, max_depth=4, min_child_weight=7;, score=0.785 total time=   0.1s\n",
      "[CV 2/3; 42/50] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=3\n",
      "[CV 2/3; 42/50] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=3;, score=0.967 total time=   0.0s\n",
      "[CV 3/3; 42/50] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=3\n",
      "[CV 3/3; 42/50] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=3;, score=0.934 total time=   0.1s\n",
      "[CV 1/3; 43/50] START colsample_bytree=0.4, gamma=0.0, learning_rate=0.2, max_depth=12, min_child_weight=1\n",
      "[CV 1/3; 43/50] END colsample_bytree=0.4, gamma=0.0, learning_rate=0.2, max_depth=12, min_child_weight=1;, score=0.989 total time=   0.1s\n",
      "[CV 2/3; 43/50] START colsample_bytree=0.4, gamma=0.0, learning_rate=0.2, max_depth=12, min_child_weight=1\n",
      "[CV 2/3; 43/50] END colsample_bytree=0.4, gamma=0.0, learning_rate=0.2, max_depth=12, min_child_weight=1;, score=0.976 total time=   0.1s\n",
      "[CV 1/3; 50/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.2, max_depth=6, min_child_weight=1\n",
      "[CV 1/3; 50/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.2, max_depth=6, min_child_weight=1;, score=0.986 total time=   0.0s\n",
      "[CV 1/3; 3/50] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.1, max_depth=8, min_child_weight=1\n",
      "[CV 1/3; 3/50] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.1, max_depth=8, min_child_weight=1;, score=0.900 total time=   0.1s\n",
      "[CV 1/3; 6/50] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=7\n",
      "[CV 1/3; 6/50] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=7;, score=0.701 total time=   0.0s\n",
      "[CV 2/3; 10/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=12, min_child_weight=7\n",
      "[CV 2/3; 10/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=12, min_child_weight=7;, score=0.564 total time=   0.0s\n",
      "[CV 3/3; 10/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=12, min_child_weight=7\n",
      "[CV 3/3; 10/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=12, min_child_weight=7;, score=0.826 total time=   0.0s\n",
      "[CV 1/3; 15/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=5\n",
      "[CV 1/3; 15/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=5;, score=0.839 total time=   0.0s\n",
      "[CV 2/3; 15/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=5\n",
      "[CV 2/3; 15/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=5;, score=0.829 total time=   0.1s\n",
      "[CV 3/3; 19/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=1\n",
      "[CV 3/3; 19/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=1;, score=0.987 total time=   0.1s\n",
      "[CV 1/3; 20/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1\n",
      "[CV 2/3; 31/50] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.25, max_depth=12, min_child_weight=3;, score=0.933 total time=   0.1s\n",
      "[CV 3/3; 39/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.25, max_depth=3, min_child_weight=1\n",
      "[CV 3/3; 39/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.25, max_depth=3, min_child_weight=1;, score=0.951 total time=   0.1s\n",
      "[CV 1/3; 40/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.1, max_depth=15, min_child_weight=5\n",
      "[CV 1/3; 40/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.1, max_depth=15, min_child_weight=5;, score=0.930 total time=   0.1s\n",
      "[CV 2/3; 40/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.1, max_depth=15, min_child_weight=5\n",
      "[CV 2/3; 40/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.1, max_depth=15, min_child_weight=5;, score=0.901 total time=   0.0s\n",
      "[CV 3/3; 40/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.1, max_depth=15, min_child_weight=5\n",
      "[CV 3/3; 40/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.1, max_depth=15, min_child_weight=5;, score=0.870 total time=   0.1s\n",
      "[CV 1/3; 49/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=7\n",
      "[CV 1/3; 49/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=7;, score=0.819 total time=   0.1s\n",
      "[CV 2/3; 1/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=5, min_child_weight=7\n",
      "[CV 2/3; 1/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=5, min_child_weight=7;, score=0.806 total time=   0.1s\n",
      "[CV 2/3; 5/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=7\n",
      "[CV 2/3; 5/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=7;, score=0.837 total time=   0.1s\n",
      "[CV 3/3; 9/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1\n",
      "[CV 3/3; 9/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1;, score=0.968 total time=   0.1s\n",
      "[CV 1/3; 10/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=12, min_child_weight=7\n",
      "[CV 1/3; 10/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=12, min_child_weight=7;, score=0.772 total time=   0.1s\n",
      "[CV 3/3; 15/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=5\n",
      "[CV 3/3; 15/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=5;, score=0.821 total time=   0.0s\n",
      "[CV 1/3; 16/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.2, max_depth=12, min_child_weight=1\n",
      "[CV 1/3; 16/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.2, max_depth=12, min_child_weight=1;, score=0.968 total time=   0.1s\n",
      "[CV 1/3; 21/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.15, max_depth=3, min_child_weight=5\n",
      "[CV 1/3; 21/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.15, max_depth=3, min_child_weight=5;, score=0.917 total time=   0.1s\n",
      "[CV 2/3; 21/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.15, max_depth=3, min_child_weight=5\n",
      "[CV 2/3; 21/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.15, max_depth=3, min_child_weight=5;, score=0.938 total time=   0.0s\n",
      "[CV 3/3; 21/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.15, max_depth=3, min_child_weight=5\n",
      "[CV 3/3; 21/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.15, max_depth=3, min_child_weight=5;, score=0.772 total time=   0.1s\n",
      "[CV 1/3; 22/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=5\n",
      "[CV 1/3; 22/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=5;, score=0.926 total time=   0.1s\n",
      "[CV 1/3; 33/50] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5\n",
      "[CV 1/3; 33/50] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5;, score=0.908 total time=   0.1s\n",
      "[CV 2/3; 33/50] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5\n",
      "[CV 2/3; 33/50] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5;, score=0.927 total time=   0.1s\n",
      "[CV 3/3; 33/50] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5\n",
      "[CV 3/3; 33/50] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=5;, score=0.812 total time=   0.1s\n",
      "[CV 1/3; 34/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=8, min_child_weight=3\n",
      "[CV 1/3; 34/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=8, min_child_weight=3;, score=0.977 total time=   0.1s\n",
      "[CV 1/3; 41/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=5\n",
      "[CV 1/3; 41/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=5;, score=0.950 total time=   0.0s\n",
      "[CV 2/3; 41/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=5\n",
      "[CV 2/3; 41/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=5;, score=0.938 total time=   0.1s\n",
      "[CV 3/3; 41/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=5\n",
      "[CV 3/3; 41/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=5;, score=0.816 total time=   0.1s\n",
      "[CV 1/3; 42/50] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=3\n",
      "[CV 1/3; 42/50] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=3;, score=0.965 total time=   0.1s\n",
      "[CV 3/3; 49/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=7\n",
      "[CV 3/3; 49/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=7;, score=0.707 total time=   0.0s\n",
      "[CV 2/3; 2/50] START colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=3\n",
      "[CV 2/3; 2/50] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=3;, score=0.878 total time=   0.1s\n",
      "[CV 2/3; 4/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=15, min_child_weight=7\n",
      "[CV 2/3; 4/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=15, min_child_weight=7;, score=0.564 total time=   0.0s\n",
      "[CV 2/3; 6/50] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=7\n",
      "[CV 2/3; 6/50] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=7;, score=0.547 total time=   0.0s\n",
      "[CV 3/3; 6/50] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=7\n",
      "[CV 3/3; 6/50] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=7;, score=0.847 total time=   0.0s\n",
      "[CV 3/3; 13/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.05, max_depth=8, min_child_weight=3\n",
      "[CV 3/3; 13/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.05, max_depth=8, min_child_weight=3;, score=0.974 total time=   0.1s\n",
      "[CV 1/3; 14/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1\n",
      "[CV 1/3; 14/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1;, score=0.913 total time=   0.0s\n",
      "[CV 3/3; 23/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.3, max_depth=12, min_child_weight=7\n",
      "[CV 3/3; 23/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.3, max_depth=12, min_child_weight=7;, score=0.847 total time=   0.1s\n",
      "[CV 1/3; 24/50] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=15, min_child_weight=1\n",
      "[CV 1/3; 24/50] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=15, min_child_weight=1;, score=0.926 total time=   0.1s\n",
      "[CV 2/3; 24/50] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=15, min_child_weight=1\n",
      "[CV 2/3; 24/50] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=15, min_child_weight=1;, score=0.945 total time=   0.1s\n",
      "[CV 1/3; 38/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.15, max_depth=6, min_child_weight=1;, score=0.952 total time=   0.1s\n",
      "[CV 3/3; 47/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.2, max_depth=4, min_child_weight=3\n",
      "[CV 3/3; 47/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.2, max_depth=4, min_child_weight=3;, score=0.969 total time=   0.1s\n",
      "[CV 1/3; 48/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=4, min_child_weight=1\n",
      "[CV 1/3; 48/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=4, min_child_weight=1;, score=0.951 total time=   0.0s\n",
      "[CV 2/3; 48/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=4, min_child_weight=1\n",
      "[CV 2/3; 48/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=4, min_child_weight=1;, score=0.874 total time=   0.1s\n",
      "[CV 3/3; 48/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=4, min_child_weight=1\n",
      "[CV 3/3; 48/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=4, min_child_weight=1;, score=0.948 total time=   0.1s\n",
      "[CV 3/3; 1/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=5, min_child_weight=7\n",
      "[CV 3/3; 1/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=5, min_child_weight=7;, score=0.710 total time=   0.1s\n",
      "[CV 1/3; 4/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=15, min_child_weight=7\n",
      "[CV 1/3; 4/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=15, min_child_weight=7;, score=0.772 total time=   0.0s\n",
      "[CV 2/3; 6/50] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=7\n",
      "[CV 2/3; 6/50] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=7;, score=0.813 total time=   0.0s\n",
      "[CV 3/3; 6/50] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=7\n",
      "[CV 3/3; 6/50] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=7;, score=0.685 total time=   0.1s\n",
      "[CV 2/3; 12/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=3\n",
      "[CV 2/3; 12/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=3;, score=0.956 total time=   0.1s\n",
      "[CV 3/3; 12/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=3\n",
      "[CV 3/3; 12/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=3;, score=0.917 total time=   0.1s\n",
      "[CV 3/3; 23/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.3, max_depth=12, min_child_weight=7\n",
      "[CV 3/3; 23/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.3, max_depth=12, min_child_weight=7;, score=0.782 total time=   0.1s\n",
      "[CV 1/3; 24/50] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=15, min_child_weight=1\n",
      "[CV 1/3; 24/50] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=15, min_child_weight=1;, score=0.971 total time=   0.0s\n",
      "[CV 2/3; 24/50] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=15, min_child_weight=1\n",
      "[CV 2/3; 24/50] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=15, min_child_weight=1;, score=0.963 total time=   0.1s\n",
      "[CV 3/3; 24/50] START colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=15, min_child_weight=1\n",
      "[CV 3/3; 24/50] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=15, min_child_weight=1;, score=0.968 total time=   0.1s\n",
      "[CV 2/3; 34/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=8, min_child_weight=3\n",
      "[CV 2/3; 34/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=8, min_child_weight=3;, score=0.960 total time=   0.1s\n",
      "[CV 3/3; 34/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=8, min_child_weight=3\n",
      "[CV 3/3; 34/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=8, min_child_weight=3;, score=0.883 total time=   0.0s\n",
      "[CV 1/3; 35/50] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.2, max_depth=3, min_child_weight=5\n",
      "[CV 1/3; 35/50] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.2, max_depth=3, min_child_weight=5;, score=0.917 total time=   0.1s\n",
      "[CV 2/3; 35/50] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.2, max_depth=3, min_child_weight=5\n",
      "[CV 2/3; 35/50] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.2, max_depth=3, min_child_weight=5;, score=0.941 total time=   0.1s\n",
      "[CV 3/3; 43/50] START colsample_bytree=0.4, gamma=0.0, learning_rate=0.2, max_depth=12, min_child_weight=1\n",
      "[CV 3/3; 43/50] END colsample_bytree=0.4, gamma=0.0, learning_rate=0.2, max_depth=12, min_child_weight=1;, score=0.963 total time=   0.0s\n",
      "[CV 1/3; 44/50] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.15, max_depth=3, min_child_weight=1\n",
      "[CV 1/3; 44/50] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.15, max_depth=3, min_child_weight=1;, score=0.968 total time=   0.1s\n",
      "[CV 2/3; 44/50] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.15, max_depth=3, min_child_weight=1\n",
      "[CV 2/3; 44/50] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.15, max_depth=3, min_child_weight=1;, score=0.967 total time=   0.1s\n",
      "[CV 3/3; 44/50] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.15, max_depth=3, min_child_weight=1\n",
      "[CV 3/3; 44/50] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.15, max_depth=3, min_child_weight=1;, score=0.970 total time=   0.1s\n",
      "[CV 2/3; 50/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.2, max_depth=6, min_child_weight=1\n",
      "[CV 2/3; 50/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.2, max_depth=6, min_child_weight=1;, score=0.969 total time=   0.0s\n",
      "[CV 3/3; 1/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=5, min_child_weight=7\n",
      "[CV 3/3; 1/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=5, min_child_weight=7;, score=0.832 total time=   0.1s\n",
      "[CV 1/3; 4/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=15, min_child_weight=7\n",
      "[CV 1/3; 4/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=15, min_child_weight=7;, score=0.757 total time=   0.0s\n",
      "[CV 2/3; 8/50] START colsample_bytree=0.4, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=3\n",
      "[CV 2/3; 8/50] END colsample_bytree=0.4, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=3;, score=0.856 total time=   0.0s\n",
      "[CV 3/3; 8/50] START colsample_bytree=0.4, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=3\n",
      "[CV 3/3; 8/50] END colsample_bytree=0.4, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=3;, score=0.987 total time=   0.0s\n",
      "[CV 3/3; 11/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=12, min_child_weight=5\n",
      "[CV 3/3; 11/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=12, min_child_weight=5;, score=0.982 total time=   0.0s\n",
      "[CV 1/3; 12/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=3\n",
      "[CV 1/3; 12/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=8, min_child_weight=3;, score=0.896 total time=   0.1s\n",
      "[CV 1/3; 17/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3\n",
      "[CV 1/3; 17/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3;, score=0.916 total time=   0.1s\n",
      "[CV 2/3; 17/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3\n",
      "[CV 2/3; 17/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3;, score=0.877 total time=   0.0s\n",
      "[CV 3/3; 17/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3\n",
      "[CV 3/3; 17/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3;, score=0.987 total time=   0.1s\n",
      "[CV 1/3; 18/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1\n",
      "[CV 1/3; 34/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=8, min_child_weight=3\n",
      "[CV 1/3; 34/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=8, min_child_weight=3;, score=0.932 total time=   0.0s\n",
      "[CV 3/3; 43/50] START colsample_bytree=0.4, gamma=0.0, learning_rate=0.2, max_depth=12, min_child_weight=1\n",
      "[CV 3/3; 43/50] END colsample_bytree=0.4, gamma=0.0, learning_rate=0.2, max_depth=12, min_child_weight=1;, score=0.981 total time=   0.1s\n",
      "[CV 1/3; 44/50] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.15, max_depth=3, min_child_weight=1\n",
      "[CV 1/3; 44/50] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.15, max_depth=3, min_child_weight=1;, score=0.945 total time=   0.1s\n",
      "[CV 2/3; 44/50] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.15, max_depth=3, min_child_weight=1\n",
      "[CV 2/3; 44/50] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.15, max_depth=3, min_child_weight=1;, score=0.863 total time=   0.1s\n",
      "[CV 3/3; 44/50] START colsample_bytree=0.5, gamma=0.3, learning_rate=0.15, max_depth=3, min_child_weight=1\n",
      "[CV 3/3; 44/50] END colsample_bytree=0.5, gamma=0.3, learning_rate=0.15, max_depth=3, min_child_weight=1;, score=0.944 total time=   0.1s\n",
      "[CV 3/3; 50/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.2, max_depth=6, min_child_weight=1\n",
      "[CV 3/3; 50/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.2, max_depth=6, min_child_weight=1;, score=0.938 total time=   0.0s\n",
      "[CV 2/3; 3/50] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.1, max_depth=8, min_child_weight=1\n",
      "[CV 2/3; 3/50] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.1, max_depth=8, min_child_weight=1;, score=0.974 total time=   0.1s\n",
      "[CV 1/3; 6/50] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=7\n",
      "[CV 1/3; 6/50] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.05, max_depth=12, min_child_weight=7;, score=0.763 total time=   0.1s\n",
      "[CV 1/3; 11/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=12, min_child_weight=5\n",
      "[CV 1/3; 11/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=12, min_child_weight=5;, score=0.956 total time=   0.1s\n",
      "[CV 2/3; 11/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=12, min_child_weight=5\n",
      "[CV 2/3; 11/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=12, min_child_weight=5;, score=0.941 total time=   0.1s\n",
      "[CV 2/3; 16/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.2, max_depth=12, min_child_weight=1\n",
      "[CV 2/3; 16/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.2, max_depth=12, min_child_weight=1;, score=0.967 total time=   0.1s\n",
      "[CV 3/3; 16/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.2, max_depth=12, min_child_weight=1\n",
      "[CV 3/3; 16/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.2, max_depth=12, min_child_weight=1;, score=0.972 total time=   0.1s\n",
      "[CV 2/3; 26/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=8, min_child_weight=1\n",
      "[CV 2/3; 26/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=8, min_child_weight=1;, score=0.971 total time=   0.0s\n",
      "[CV 3/3; 26/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=8, min_child_weight=1\n",
      "[CV 3/3; 26/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=8, min_child_weight=1;, score=0.968 total time=   0.1s\n",
      "[CV 1/3; 27/50] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.2, max_depth=5, min_child_weight=7\n",
      "[CV 1/3; 27/50] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.2, max_depth=5, min_child_weight=7;, score=0.758 total time=   0.1s\n",
      "[CV 2/3; 27/50] START colsample_bytree=0.3, gamma=0.3, learning_rate=0.2, max_depth=5, min_child_weight=7\n",
      "[CV 2/3; 27/50] END colsample_bytree=0.3, gamma=0.3, learning_rate=0.2, max_depth=5, min_child_weight=7;, score=0.806 total time=   0.0s\n",
      "[CV 1/3; 37/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=12, min_child_weight=1\n",
      "[CV 1/3; 37/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=12, min_child_weight=1;, score=0.974 total time=   0.1s\n",
      "[CV 2/3; 37/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=12, min_child_weight=1\n",
      "[CV 2/3; 37/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=12, min_child_weight=1;, score=0.971 total time=   0.1s\n",
      "[CV 3/3; 37/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=12, min_child_weight=1\n",
      "[CV 3/3; 37/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.15, max_depth=12, min_child_weight=1;, score=0.965 total time=   0.1s\n",
      "[CV 1/3; 38/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.15, max_depth=6, min_child_weight=1\n",
      "[CV 1/3; 38/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.15, max_depth=6, min_child_weight=1;, score=0.968 total time=   0.0s\n",
      "[CV 3/3; 47/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.2, max_depth=4, min_child_weight=3\n",
      "[CV 3/3; 47/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.2, max_depth=4, min_child_weight=3;, score=0.864 total time=   0.1s\n",
      "[CV 1/3; 48/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=4, min_child_weight=1\n",
      "[CV 1/3; 48/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=4, min_child_weight=1;, score=0.965 total time=   0.1s\n",
      "[CV 2/3; 48/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=4, min_child_weight=1\n",
      "[CV 2/3; 48/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=4, min_child_weight=1;, score=0.971 total time=   0.1s\n",
      "[CV 3/3; 48/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=4, min_child_weight=1\n",
      "[CV 3/3; 48/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=4, min_child_weight=1;, score=0.977 total time=   0.0s\n",
      "[CV 3/3; 2/50] START colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=3\n",
      "[CV 3/3; 2/50] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=3;, score=0.993 total time=   0.1s\n",
      "[CV 3/3; 5/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=7\n",
      "[CV 3/3; 5/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=7;, score=0.829 total time=   0.0s\n",
      "[CV 3/3; 9/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1\n",
      "[CV 3/3; 9/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1;, score=0.990 total time=   0.0s\n",
      "[CV 1/3; 10/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=12, min_child_weight=7\n",
      "[CV 1/3; 10/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=12, min_child_weight=7;, score=0.757 total time=   0.0s\n",
      "[CV 2/3; 14/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1\n",
      "[CV 2/3; 14/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1;, score=0.930 total time=   0.0s\n",
      "[CV 3/3; 14/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1\n",
      "[CV 3/3; 14/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1;, score=0.974 total time=   0.1s\n",
      "[CV 2/3; 22/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=5\n",
      "[CV 2/3; 22/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=5;, score=0.812 total time=   0.1s\n",
      "[CV 3/3; 22/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=5\n",
      "[CV 3/3; 22/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=5;, score=0.975 total time=   0.1s\n",
      "[CV 1/3; 23/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.3, max_depth=12, min_child_weight=7\n",
      "[CV 1/3; 23/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.3, max_depth=12, min_child_weight=7;, score=0.676 total time=   0.0s\n",
      "[CV 2/3; 23/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.3, max_depth=12, min_child_weight=7\n",
      "[CV 2/3; 46/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=15, min_child_weight=3\n",
      "[CV 2/3; 46/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=15, min_child_weight=3;, score=0.912 total time=   0.1s\n",
      "[CV 3/3; 46/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=15, min_child_weight=3\n",
      "[CV 3/3; 46/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=15, min_child_weight=3;, score=0.951 total time=   0.0s\n",
      "[CV 1/3; 47/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.2, max_depth=4, min_child_weight=3\n",
      "[CV 1/3; 47/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.2, max_depth=4, min_child_weight=3;, score=0.934 total time=   0.1s\n",
      "[CV 2/3; 47/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.2, max_depth=4, min_child_weight=3\n",
      "[CV 2/3; 47/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.2, max_depth=4, min_child_weight=3;, score=0.928 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 1/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=5, min_child_weight=7\n",
      "[CV 1/3; 1/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.05, max_depth=5, min_child_weight=7;, score=0.610 total time=   0.1s\n",
      "[CV 3/3; 3/50] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.1, max_depth=8, min_child_weight=1\n",
      "[CV 3/3; 3/50] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.1, max_depth=8, min_child_weight=1;, score=0.970 total time=   0.1s\n",
      "[CV 3/3; 7/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=1\n",
      "[CV 3/3; 7/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=1;, score=0.975 total time=   0.0s\n",
      "[CV 1/3; 8/50] START colsample_bytree=0.4, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=3\n",
      "[CV 1/3; 8/50] END colsample_bytree=0.4, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=3;, score=0.959 total time=   0.1s\n",
      "[CV 1/3; 13/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.05, max_depth=8, min_child_weight=3\n",
      "[CV 1/3; 13/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.05, max_depth=8, min_child_weight=3;, score=0.950 total time=   0.1s\n",
      "[CV 2/3; 13/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.05, max_depth=8, min_child_weight=3\n",
      "[CV 2/3; 13/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.05, max_depth=8, min_child_weight=3;, score=0.963 total time=   0.1s\n",
      "[CV 2/3; 18/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1\n",
      "[CV 2/3; 18/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1;, score=0.973 total time=   0.1s\n",
      "[CV 3/3; 18/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1\n",
      "[CV 3/3; 18/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1;, score=0.972 total time=   0.1s\n",
      "[CV 1/3; 19/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=1\n",
      "[CV 1/3; 19/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=1;, score=0.974 total time=   0.1s\n",
      "[CV 2/3; 19/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=1\n",
      "[CV 2/3; 19/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=1;, score=0.973 total time=   0.1s\n",
      "[CV 2/3; 30/50] START colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=5\n",
      "[CV 2/3; 30/50] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=5;, score=0.927 total time=   0.0s\n",
      "[CV 3/3; 30/50] START colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=5\n",
      "[CV 3/3; 30/50] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=5;, score=0.812 total time=   0.1s\n",
      "[CV 1/3; 31/50] START colsample_bytree=0.3, gamma=0.2, learning_rate=0.25, max_depth=12, min_child_weight=3\n",
      "[CV 1/3; 31/50] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.25, max_depth=12, min_child_weight=3;, score=0.974 total time=   0.1s\n",
      "[CV 2/3; 31/50] START colsample_bytree=0.3, gamma=0.2, learning_rate=0.25, max_depth=12, min_child_weight=3\n",
      "[CV 2/3; 31/50] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.25, max_depth=12, min_child_weight=3;, score=0.956 total time=   0.0s\n",
      "[CV 2/3; 38/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.15, max_depth=6, min_child_weight=1\n",
      "[CV 2/3; 38/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.15, max_depth=6, min_child_weight=1;, score=0.963 total time=   0.1s\n",
      "[CV 3/3; 38/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.15, max_depth=6, min_child_weight=1\n",
      "[CV 3/3; 38/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.15, max_depth=6, min_child_weight=1;, score=0.971 total time=   0.1s\n",
      "[CV 1/3; 39/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.25, max_depth=3, min_child_weight=1\n",
      "[CV 1/3; 39/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.25, max_depth=3, min_child_weight=1;, score=0.971 total time=   0.1s\n",
      "[CV 2/3; 39/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.25, max_depth=3, min_child_weight=1\n",
      "[CV 2/3; 39/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.25, max_depth=3, min_child_weight=1;, score=0.967 total time=   0.0s\n",
      "[CV 2/3; 49/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=7\n",
      "[CV 2/3; 49/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=7;, score=0.810 total time=   0.1s\n",
      "[CV 1/3; 2/50] START colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=3\n",
      "[CV 1/3; 2/50] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=3;, score=0.910 total time=   0.1s\n",
      "[CV 1/3; 5/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=7\n",
      "[CV 1/3; 5/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=7;, score=0.755 total time=   0.1s\n",
      "[CV 1/3; 11/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=12, min_child_weight=5\n",
      "[CV 1/3; 11/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=12, min_child_weight=5;, score=0.845 total time=   0.1s\n",
      "[CV 2/3; 11/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=12, min_child_weight=5\n",
      "[CV 2/3; 11/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.25, max_depth=12, min_child_weight=5;, score=0.849 total time=   0.0s\n",
      "[CV 3/3; 15/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=5\n",
      "[CV 3/3; 15/50] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.25, max_depth=4, min_child_weight=5;, score=0.979 total time=   0.1s\n",
      "[CV 1/3; 16/50] START colsample_bytree=0.5, gamma=0.4, learning_rate=0.2, max_depth=12, min_child_weight=1\n",
      "[CV 1/3; 16/50] END colsample_bytree=0.5, gamma=0.4, learning_rate=0.2, max_depth=12, min_child_weight=1;, score=0.906 total time=   0.0s\n",
      "[CV 1/3; 25/50] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.3, max_depth=3, min_child_weight=3\n",
      "[CV 1/3; 25/50] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.3, max_depth=3, min_child_weight=3;, score=0.910 total time=   0.1s\n",
      "[CV 2/3; 25/50] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.3, max_depth=3, min_child_weight=3\n",
      "[CV 2/3; 25/50] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.3, max_depth=3, min_child_weight=3;, score=0.869 total time=   0.1s\n",
      "[CV 3/3; 25/50] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.3, max_depth=3, min_child_weight=3\n",
      "[CV 3/3; 25/50] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.3, max_depth=3, min_child_weight=3;, score=0.993 total time=   0.0s\n",
      "[CV 1/3; 26/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=8, min_child_weight=1\n",
      "[CV 1/3; 26/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=8, min_child_weight=1;, score=0.906 total time=   0.1s\n",
      "[CV 2/3; 34/50] START colsample_bytree=0.4, gamma=0.1, learning_rate=0.2, max_depth=8, min_child_weight=3\n",
      "[CV 1/3; 42/50] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=3;, score=0.938 total time=   0.1s\n",
      "[CV 1/3; 50/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.2, max_depth=6, min_child_weight=1\n",
      "[CV 1/3; 50/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.2, max_depth=6, min_child_weight=1;, score=0.982 total time=   0.1s\n",
      "[CV 3/3; 2/50] START colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=3\n",
      "[CV 3/3; 2/50] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.1, max_depth=12, min_child_weight=3;, score=0.929 total time=   0.1s\n",
      "[CV 1/3; 5/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=7\n",
      "[CV 1/3; 5/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.25, max_depth=3, min_child_weight=7;, score=0.752 total time=   0.1s\n",
      "[CV 1/3; 9/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1\n",
      "[CV 1/3; 9/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1;, score=0.977 total time=   0.1s\n",
      "[CV 2/3; 9/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1\n",
      "[CV 2/3; 9/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1;, score=0.967 total time=   0.1s\n",
      "[CV 2/3; 14/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1\n",
      "[CV 2/3; 14/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1;, score=0.967 total time=   0.0s\n",
      "[CV 3/3; 14/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1\n",
      "[CV 3/3; 14/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.1, max_depth=3, min_child_weight=1;, score=0.970 total time=   0.1s\n",
      "[CV 1/3; 25/50] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.3, max_depth=3, min_child_weight=3\n",
      "[CV 1/3; 25/50] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.3, max_depth=3, min_child_weight=3;, score=0.974 total time=   0.1s\n",
      "[CV 2/3; 25/50] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.3, max_depth=3, min_child_weight=3\n",
      "[CV 2/3; 25/50] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.3, max_depth=3, min_child_weight=3;, score=0.963 total time=   0.1s\n",
      "[CV 3/3; 25/50] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.3, max_depth=3, min_child_weight=3\n",
      "[CV 3/3; 25/50] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.3, max_depth=3, min_child_weight=3;, score=0.883 total time=   0.0s\n",
      "[CV 1/3; 26/50] START colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=8, min_child_weight=1\n",
      "[CV 1/3; 26/50] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.3, max_depth=8, min_child_weight=1;, score=0.974 total time=   0.1s\n",
      "[CV 3/3; 35/50] START colsample_bytree=0.4, gamma=0.2, learning_rate=0.2, max_depth=3, min_child_weight=5\n",
      "[CV 3/3; 35/50] END colsample_bytree=0.4, gamma=0.2, learning_rate=0.2, max_depth=3, min_child_weight=5;, score=0.815 total time=   0.1s\n",
      "[CV 1/3; 36/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.15, max_depth=5, min_child_weight=1\n",
      "[CV 1/3; 36/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.15, max_depth=5, min_child_weight=1;, score=0.967 total time=   0.0s\n",
      "[CV 2/3; 36/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.15, max_depth=5, min_child_weight=1\n",
      "[CV 2/3; 36/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.15, max_depth=5, min_child_weight=1;, score=0.976 total time=   0.1s\n",
      "[CV 3/3; 36/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.15, max_depth=5, min_child_weight=1\n",
      "[CV 3/3; 36/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.15, max_depth=5, min_child_weight=1;, score=0.963 total time=   0.1s\n",
      "[CV 1/3; 45/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.2, max_depth=10, min_child_weight=5\n",
      "[CV 1/3; 45/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.2, max_depth=10, min_child_weight=5;, score=0.917 total time=   0.1s\n",
      "[CV 2/3; 45/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.2, max_depth=10, min_child_weight=5\n",
      "[CV 2/3; 45/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.2, max_depth=10, min_child_weight=5;, score=0.941 total time=   0.0s\n",
      "[CV 3/3; 45/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.2, max_depth=10, min_child_weight=5\n",
      "[CV 3/3; 45/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.2, max_depth=10, min_child_weight=5;, score=0.834 total time=   0.1s\n",
      "[CV 1/3; 46/50] START colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=15, min_child_weight=3\n",
      "[CV 1/3; 46/50] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.15, max_depth=15, min_child_weight=3;, score=0.977 total time=   0.1s\n",
      "[CV 3/3; 50/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.2, max_depth=6, min_child_weight=1\n",
      "[CV 3/3; 50/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.2, max_depth=6, min_child_weight=1;, score=0.975 total time=   0.0s\n",
      "[CV 2/3; 3/50] START colsample_bytree=0.3, gamma=0.4, learning_rate=0.1, max_depth=8, min_child_weight=1\n",
      "[CV 2/3; 3/50] END colsample_bytree=0.3, gamma=0.4, learning_rate=0.1, max_depth=8, min_child_weight=1;, score=0.935 total time=   0.0s\n",
      "[CV 3/3; 4/50] START colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=15, min_child_weight=7\n",
      "[CV 3/3; 4/50] END colsample_bytree=0.4, gamma=0.4, learning_rate=0.15, max_depth=15, min_child_weight=7;, score=0.826 total time=   0.0s\n",
      "[CV 1/3; 7/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=1\n",
      "[CV 1/3; 7/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=1;, score=0.893 total time=   0.0s\n",
      "[CV 2/3; 7/50] START colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=1\n",
      "[CV 2/3; 7/50] END colsample_bytree=0.4, gamma=0.3, learning_rate=0.05, max_depth=3, min_child_weight=1;, score=0.940 total time=   0.0s\n",
      "[CV 1/3; 13/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.05, max_depth=8, min_child_weight=3\n",
      "[CV 1/3; 13/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.05, max_depth=8, min_child_weight=3;, score=0.896 total time=   0.0s\n",
      "[CV 2/3; 13/50] START colsample_bytree=0.7, gamma=0.4, learning_rate=0.05, max_depth=8, min_child_weight=3\n",
      "[CV 2/3; 13/50] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.05, max_depth=8, min_child_weight=3;, score=0.865 total time=   0.1s\n",
      "[CV 2/3; 18/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1\n",
      "[CV 2/3; 18/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1;, score=0.930 total time=   0.1s\n",
      "[CV 3/3; 18/50] START colsample_bytree=0.5, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1\n",
      "[CV 3/3; 18/50] END colsample_bytree=0.5, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1;, score=0.980 total time=   0.1s\n",
      "[CV 1/3; 19/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=1\n",
      "[CV 1/3; 19/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=1;, score=0.893 total time=   0.1s\n",
      "[CV 2/3; 19/50] START colsample_bytree=0.3, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=1\n",
      "[CV 2/3; 19/50] END colsample_bytree=0.3, gamma=0.0, learning_rate=0.25, max_depth=6, min_child_weight=1;, score=0.948 total time=   0.1s\n",
      "[CV 3/3; 31/50] START colsample_bytree=0.3, gamma=0.2, learning_rate=0.25, max_depth=12, min_child_weight=3\n",
      "[CV 3/3; 31/50] END colsample_bytree=0.3, gamma=0.2, learning_rate=0.25, max_depth=12, min_child_weight=3;, score=0.997 total time=   0.1s\n",
      "[CV 1/3; 32/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1\n",
      "[CV 1/3; 32/50] END colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1;, score=0.896 total time=   0.1s\n",
      "[CV 2/3; 32/50] START colsample_bytree=0.7, gamma=0.0, learning_rate=0.05, max_depth=12, min_child_weight=1\n"
     ]
    }
   ],
   "source": [
    "xgb_model, xgb_scores = xgb_classifier(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC = 0.888095238095238\n",
      "ACCURACY = 0.9423076923076923\n",
      "F1 = 0.8421052631578948\n"
     ]
    }
   ],
   "source": [
    "validation_classification(xgb_model, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance to detect reactions for knock-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.TreeExplainer(xgb_model, X_test_scaled, feature_names=X_test.columns)\n",
    "shap_values = explainer(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x510 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap.plots.beeswarm(shap_values, max_display=X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = xgb_model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "features = X_train.columns\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='g', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 12:55:48.935623: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-15 12:55:49.088449: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-15 12:55:49.088472: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-15 12:55:49.113952: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-15 12:55:49.654530: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-15 12:55:49.654584: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-15 12:55:49.654591: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 12:55:50.243504: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-11-15 12:55:50.243520: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-15 12:55:50.243534: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (comex-dell): /proc/driver/nvidia/version does not exist\n",
      "2022-11-15 12:55:50.243695: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 861us/step - loss: 0.6267 - accuracy: 0.8010 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 2/25\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.5768 - accuracy: 0.8010 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 3/25\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.5272 - accuracy: 0.8010 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 4/25\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.8010 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 5/25\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.8010 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 6/25\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8010 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 7/25\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3983 - accuracy: 0.8010 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 8/25\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3875 - accuracy: 0.8010 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 9/25\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3786 - accuracy: 0.8010 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 10/25\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8010 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 11/25\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3648 - accuracy: 0.8010 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 12/25\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 0.8010 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 13/25\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3548 - accuracy: 0.8010 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 14/25\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3505 - accuracy: 0.8010 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 15/25\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3454 - accuracy: 0.8010 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 16/25\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3404 - accuracy: 0.8010 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 17/25\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3357 - accuracy: 0.8010 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 18/25\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.8010 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 19/25\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3265 - accuracy: 0.8204 - precision: 1.0000 - recall: 0.0976    \n",
      "Epoch 20/25\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3229 - accuracy: 0.8204 - precision: 1.0000 - recall: 0.0976   \n",
      "Epoch 21/25\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3191 - accuracy: 0.8155 - precision: 0.7143 - recall: 0.1220   \n",
      "Epoch 22/25\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3173 - accuracy: 0.8204 - precision: 0.7000 - recall: 0.1707   \n",
      "Epoch 23/25\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3144 - accuracy: 0.8447 - precision: 0.7368 - recall: 0.3415\n",
      "Epoch 24/25\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3116 - accuracy: 0.8447 - precision: 0.7368 - recall: 0.3415   \n",
      "Epoch 25/25\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3097 - accuracy: 0.8447 - precision: 0.7368 - recall: 0.3415   \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=n_inputs, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics = [\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ])\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, epochs=25, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8077 - precision: 0.5000 - recall: 0.3000\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test_scaled, y_test,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      "ROC-AUC = 0.6142857142857143\n",
      "ACCURACY = 0.8076923076923077\n",
      "F1 = 0.37499999999999994\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "print('ROC-AUC =', roc_auc_score(y_test, y_pred))\n",
    "print('ACCURACY =', accuracy_score(y_test, y_pred))\n",
    "print('F1 =', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 206 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a670b9adae814a55985574d628ad059a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "e = shap.KernelExplainer(model, X_train_scaled)\n",
    "shap_values = e.shap_values(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x510 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap.summary_plot(shap_values[0], X_test_scaled, feature_names=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELI5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0577\n",
       "                \n",
       "                    &plusmn; 0.0421\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                r3\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 83.90%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0423\n",
       "                \n",
       "                    &plusmn; 0.0510\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                InputA\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 84.94%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0385\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                r15\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.07%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0154\n",
       "                \n",
       "                    &plusmn; 0.0288\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                r10\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.07%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0154\n",
       "                \n",
       "                    &plusmn; 0.0154\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                OutputN\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0038\n",
       "                \n",
       "                    &plusmn; 0.0449\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                r4\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0038\n",
       "                \n",
       "                    &plusmn; 0.0288\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                r2\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                InputI\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 95.12%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0077\n",
       "                \n",
       "                    &plusmn; 0.0188\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                r14\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from eli5.permutation_importance import get_score_importances\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "perm = PermutationImportance(xgb_model).fit(X_test_scaled, y_test)\n",
    "eli5.show_weights(perm, feature_names=X_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selected</th>\n",
       "      <th>features_names</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>r3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>r10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>r14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>InputA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   selected features_names  rank\n",
       "0      True             r3     1\n",
       "3      True            r10     1\n",
       "4      True            r14     1\n",
       "6      True         InputA     1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "estimator = xgb_model\n",
    "\n",
    "selector = RFECV(estimator)\n",
    "selector = selector.fit(X_train_scaled, y_train)\n",
    "\n",
    "selected_features = pd.DataFrame()\n",
    "selected_features['selected'] = selector.support_\n",
    "selected_features['features_names'] = X_train.columns\n",
    "selected_features['rank'] = selector.ranking_\n",
    "selected_features[selected_features['selected'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selected</th>\n",
       "      <th>features_names</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>OutputN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>r4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>r2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>r15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>InputI</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   selected features_names  rank\n",
       "8     False        OutputN     2\n",
       "2     False             r4     3\n",
       "1     False             r2     4\n",
       "5     False            r15     5\n",
       "7     False         InputI     6"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features[selected_features['selected'] == False].sort_values(by='rank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.3,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0.2, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.25, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=12, max_leaves=0, min_child_weight=3, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.3,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0.2, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.25, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=12, max_leaves=0, min_child_weight=3, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.3,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0.2, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.25, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=12, max_leaves=0, min_child_weight=3, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BorutaPy(estimator=XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;,\n",
       "                                 callbacks=None, colsample_bylevel=1,\n",
       "                                 colsample_bynode=1, colsample_bytree=0.3,\n",
       "                                 early_stopping_rounds=None,\n",
       "                                 enable_categorical=False, eval_metric=None,\n",
       "                                 feature_types=None, gamma=0.2, gpu_id=-1,\n",
       "                                 grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "                                 interaction_constraints=&#x27;&#x27;, learning_rate=0.25,\n",
       "                                 max_bin=256, max_cat_threshold=64,\n",
       "                                 max_cat_to_onehot=4, max_delta_step=0,\n",
       "                                 max_depth=12, max_leaves=0, min_child_weight=3,\n",
       "                                 missing=nan, monotone_constraints=&#x27;()&#x27;,\n",
       "                                 n_estimators=35, n_jobs=0, num_parallel_tree=1,\n",
       "                                 predictor=&#x27;auto&#x27;, random_state=1648975101, ...),\n",
       "         max_iter=10, n_estimators=&#x27;auto&#x27;,\n",
       "         random_state=RandomState(MT19937) at 0x7FDED00FB440)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BorutaPy</label><div class=\"sk-toggleable__content\"><pre>BorutaPy(estimator=XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;,\n",
       "                                 callbacks=None, colsample_bylevel=1,\n",
       "                                 colsample_bynode=1, colsample_bytree=0.3,\n",
       "                                 early_stopping_rounds=None,\n",
       "                                 enable_categorical=False, eval_metric=None,\n",
       "                                 feature_types=None, gamma=0.2, gpu_id=-1,\n",
       "                                 grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "                                 interaction_constraints=&#x27;&#x27;, learning_rate=0.25,\n",
       "                                 max_bin=256, max_cat_threshold=64,\n",
       "                                 max_cat_to_onehot=4, max_delta_step=0,\n",
       "                                 max_depth=12, max_leaves=0, min_child_weight=3,\n",
       "                                 missing=nan, monotone_constraints=&#x27;()&#x27;,\n",
       "                                 n_estimators=35, n_jobs=0, num_parallel_tree=1,\n",
       "                                 predictor=&#x27;auto&#x27;, random_state=1648975101, ...),\n",
       "         max_iter=10, n_estimators=&#x27;auto&#x27;,\n",
       "         random_state=RandomState(MT19937) at 0x7FDED00FB440)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.3,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0.2, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.25, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=12, max_leaves=0, min_child_weight=3, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=35, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=530097339, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.3,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0.2, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.25, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=12, max_leaves=0, min_child_weight=3, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=35, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=1684391870, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BorutaPy(estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                 callbacks=None, colsample_bylevel=1,\n",
       "                                 colsample_bynode=1, colsample_bytree=0.3,\n",
       "                                 early_stopping_rounds=None,\n",
       "                                 enable_categorical=False, eval_metric=None,\n",
       "                                 feature_types=None, gamma=0.2, gpu_id=-1,\n",
       "                                 grow_policy='depthwise', importance_type=None,\n",
       "                                 interaction_constraints='', learning_rate=0.25,\n",
       "                                 max_bin=256, max_cat_threshold=64,\n",
       "                                 max_cat_to_onehot=4, max_delta_step=0,\n",
       "                                 max_depth=12, max_leaves=0, min_child_weight=3,\n",
       "                                 missing=nan, monotone_constraints='()',\n",
       "                                 n_estimators=35, n_jobs=0, num_parallel_tree=1,\n",
       "                                 predictor='auto', random_state=304561939, ...),\n",
       "         max_iter=10, n_estimators='auto',\n",
       "         random_state=RandomState(MT19937) at 0x7FDED00FB440)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from boruta import BorutaPy\n",
    "\n",
    "# model = xgb.XGBClassifier()\n",
    "model = xgb_model\n",
    "\n",
    "# let's initialize Boruta\n",
    "feat_selector = BorutaPy(\n",
    "    verbose=0,\n",
    "    estimator=model,\n",
    "    n_estimators='auto',\n",
    "    max_iter=10  # number of iterations to perform\n",
    ")\n",
    "\n",
    "feat_selector.fit(np.array(X_train_scaled), np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------Support and Ranking for each feature------\n",
      "Doesn't pass the test:  r3  - Ranking:  2\n",
      "Doesn't pass the test:  r2  - Ranking:  2\n",
      "Doesn't pass the test:  r4  - Ranking:  2\n",
      "Doesn't pass the test:  r10  - Ranking:  2\n",
      "Doesn't pass the test:  r14  - Ranking:  2\n",
      "Doesn't pass the test:  r15  - Ranking:  2\n",
      "Passes the test:  InputA  - Ranking:  1\n",
      "Doesn't pass the test:  InputI  - Ranking:  4\n",
      "Doesn't pass the test:  OutputN  - Ranking:  3\n"
     ]
    }
   ],
   "source": [
    "# print support and ranking for each feature\n",
    "print(\"\\n------Support and Ranking for each feature------\")\n",
    "for i in range(len(feat_selector.support_)):\n",
    "    if feat_selector.support_[i]:\n",
    "        print(\"Passes the test: \", X_train.columns[i],\n",
    "              \" - Ranking: \", feat_selector.ranking_[i])\n",
    "    else:\n",
    "        print(\"Doesn't pass the test: \",\n",
    "              X_train.columns[i], \" - Ranking: \", feat_selector.ranking_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selected</th>\n",
       "      <th>features_names</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>r3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>r2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>r4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>r10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>r14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>r15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>InputI</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>OutputN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>InputA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   selected features_names  rank\n",
       "0     False             r3     2\n",
       "1     False             r2     2\n",
       "2     False             r4     2\n",
       "3     False            r10     2\n",
       "4     False            r14     2\n",
       "5     False            r15     2\n",
       "7     False         InputI     4\n",
       "8     False        OutputN     3\n",
       "6      True         InputA     1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features = pd.DataFrame()\n",
    "selected_features['selected'] = feat_selector.support_\n",
    "selected_features['features_names'] = X_train.columns\n",
    "selected_features['rank'] = feat_selector.ranking_\n",
    "selected_features.sort_values(by='selected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Deletions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling...\n",
      " A: min|aij| =  1.000e+00  max|aij| =  1.000e+00  ratio =  1.000e+00\n",
      "Problem data seem to be well scaled\n"
     ]
    }
   ],
   "source": [
    "from cobra.io import load_model\n",
    "from cobra.io.json import load_json_model\n",
    "\n",
    "from main import *\n",
    "\n",
    "# cobra_model = load_model(\"textbook\")\n",
    "\n",
    "# Load toy models created by Stefanos\n",
    "cobra_model_1 = load_json_model('toy_1.json')\n",
    "cobra_model_2 = load_json_model('toy_2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n",
      "optimal\n",
      "6.000000000000001\n",
      "optimal\n"
     ]
    }
   ],
   "source": [
    "ann = ['r10', 'r4', 'r14', 'r15']\n",
    "\n",
    "with cobra_model_1:\n",
    "    for rxn in ann:\n",
    "        cobra_model_1.reactions.get_by_id(rxn).knock_out()\n",
    "    solution =  cobra_model_1.optimize()    \n",
    "    print(solution.objective_value)\n",
    "    print(solution.status)\n",
    "\n",
    "with cobra_model_2:\n",
    "    for rxn in ann:\n",
    "        cobra_model_2.reactions.get_by_id(rxn).knock_out()\n",
    "    solution =  cobra_model_2.optimize()    \n",
    "    print(solution.objective_value)\n",
    "    print(solution.status)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "c6c04a7e252f45ffc2f7191e380805b6a5dd99aa68793d835f69a35c16ce4a30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
